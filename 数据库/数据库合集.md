# undo log和redo log
## redo log
redo log是InnoDB存储引擎层的日志，又称重做日志文件，用于记录事务操作的变化，记录的是数据修改之后的值，不管事务是否提交都会记录下来。在实例和介质失败（media failure）时，redo log文件就能派上用场，如数据库掉电，InnoDB存储引擎会使用redo log恢复到掉电前的时刻，以此来保证数据的完整性。==有了redo log，当数据库发生宕机重启后，可通过redo log将未落盘的数据恢复，即保证已经提交的事务记录不会丢失。==

==因为磁盘是有缓存的，只有当缓存被淘汰，或者通过操作系统的系统调用才会被落盘，那么在落盘前，数据库的数据是有可能会丢失的==

在一条更新语句进行执行的时候，InnoDB引擎会把更新记录写到redo log日志中，然后更新内存，此时算是语句执行完了，然后在空闲的时候或者是按照设定的更新策略将redo log中的内容更新到磁盘中，这里涉及到WAL即Write Ahead logging技术，他的关键点是先写日志，再写磁盘。

有了redo log日志，那么在数据库进行异常重启的时候，可以根据redo log日志进行恢复，也就达到了crash-safe。

==redo log是循环写，可以配置为1组4个文件，每个文件的大小是1GB==

**redo log通常是物理日志，记录的是数据页的物理修改，而不是某一行或某几行修改成怎样怎样，它用来恢复提交后的物理数据页(恢复数据页，且只能恢复到最后一次提交的位置)。**
## undo log
undo log用于回滚用，当进行操作是，undo log会写反操作。比如mysql进行insert，则undo log记录delete

**undo用来回滚行记录到某个版本。undo log一般是逻辑日志，根据每行记录进行记录。记录操作**

## binlog
binlog是属于MySQL Server层面的，又称为归档日志，属于逻辑日志，是以二进制的形式记录的是这个语句的原始逻辑，依靠binlog是没有crash-safe能力的

### redo log和binlog区别
redo log是属于innoDB层面，binlog属于MySQL Server层面的，这样在数据库用别的存储引擎时可以达到一致性的要求。

==**redo log是物理日志，记录该数据页更新的内容；binlog是逻辑日志，记录的是这个更新语句的原始逻辑
redo log是循环写，日志空间大小固定；binlog是追加写，是指一份写到一定大小的时候会更换下一个文件，不会覆盖。**== 

==binlog可以作为恢复数据使用，主从复制搭建，redo log作为异常宕机或者介质故障后的数据恢复使用。==

> undo log为何要持久化，如何持久化

undo log是存储更新前的旧值的，也是逻辑log。为了防止断电，而事务的数据已经插入的情况，需要回滚。

一有更新语句，直接写入磁盘。

> redolog和binlog的两阶段提交说一下

先redo log进入prepare阶段，然后binlog落盘，然后redo log提交commit

1.prepare阶段，redo log落盘前，mysqld crash，回滚

2.prepare阶段，redo log落盘后，binlog落盘前，mysqld crash，回滚

3.commit阶段，binlog落盘后，mysqld crash，提交redo log

当MySQL写完redolog并将它标记为prepare状态时，并且会在redolog中记录一个XID，它全局唯一的标识着这个事务。只要这个XID和binlog中记录的XID是一致的，MySQL就会认为binlog和redolog逻辑上一致，就会commit。而如果仅仅是rodolog中记录了XID，binlog中没有，MySQL就会RollBack

> redo log什么时候落盘？

redo log会先写到redo log buffer中，落盘时机如下：

（1）如果写入redo log buffer的日志已经占据了redo log buffer总容量的一半了，也就是超过了8MB的redo log在缓冲里了，此时就会把他们刷入到磁盘文件里去

（2）一个事务提交的时候，必须把他的那些redo log所在的redo log block都刷入到磁盘文件里去，只有这样，当事务提交之后，他修改的数据绝对不会丢失，因为redo log里有重做日志，随时可以恢复事务做的修改
（PS：当然，之前最早最早的时候，我们讲过，这个redo log哪怕事务提交的时候写入磁盘文件，也是先进入os cache的，进入os的文件缓冲区里，所以是否提交事务就强行把redo log刷入物理磁盘文件中，这个需要设置对应的参数)

（3）后台线程定时刷新，有一个后台线程每隔1秒就会把redo log buffer里的redo log block刷到磁盘文件里去

（4）MySQL关闭的时候，redo log block都会刷入到磁盘里去

> 主从复制有几种模式

基于语句(Statement-based replication)和基于行(Row-based replication)(以下简称SBR，RBR)

**基于语句：**

实现方式：当leader收到客户端的请求，也就是执行语句，然后将每一个insert，update,delete语句发送给slave节点；

优点：因为直接发送执行语句，所以会产生比较少的日志数量；并且当机器因为故障停机需要备份时，可以很快的完成数据的恢复；

缺点：sql语句含有不确定的函数时，比如Now()或者Rand(),会使每一个slave节点产生不同的值，造成主从不一致；

sql表定义中auto_incrementde列或者依赖已存在的数据的语句，比如update ...where ..condition...，需要每个slave角色节点与master节点的执行顺序抑制，否则也会造成主从不一致的现象。

**基于行：**

实现方式：

插入：对于插入，日志中会包含表定义所有列的值。

删除：删除会包含足够的信息标识需要删除的行，通常情况下是表中的主键；如果表中没有主键，日志会记录需要删除行的旧值；

更新：更新操作会包含信息标识需要删除的行，并包含更新列的新值；

优点：因为日志中记录的是表数据修改的逻辑日志，对于主从复制模式没有数据不一致的现象出现；

相比SBR模式的复制模式，对于insert，udpate 和update语句会减少锁住行的数量，相应地提高数据库的并发。

缺点：RBR模式相比SBR模式会产生更多的日志文件；对于数据修改语句(DML)比如update、delete会把每一行的数据修改都会产生一条日志；

在日志中，不能看到用户执行的sql语句，只能看到每一行数据列的变化；

对于BLOB等类型大的数据类型，会产生较大的主从复制延迟

# sql优化
## SQL语句优化
### 慢查询日志发现有问题的SQL
通过MySQL慢查询日志对有效率问题的SQL进行监控

MySQL的慢查询日志是MySQL提供的一种日志记录，它用来记录在MySQL中响应时间超过阀值的语句，具体指运行时间超过long_query_time值的SQL，则会被记录到慢查询日志中。long_query_time的默认值为10，意思是运行10s以上的语句。通过MySQL的慢查询日志，我们可以查询出执行的次数多占用的时间长的SQL

### 通过explain查询和分析SQL的执行计划
使用 EXPLAIN 关键字可以知道MySQL是如何处理你的SQL语句的，以便分析查询语句或是表结构的性能瓶颈。通过explain命令可以得到表的读取顺序、数据读取操作的操作类型、哪些索引可以使用、哪些索引被实际使用、表之间的引用以及每张表有多少行被优化器查询等问题。当扩展列extra出现Using filesort和Using temporay，则往往表示SQL需要优化了。

> explain怎么用？输出什么字段？

`explain select .. from ...`

![image-20210319193742715](https://gitee.com/super-jimwang/img/raw/master/img/20210319193742.png)

比较重要的字段：
- type访问类型。比如唯一索引，非唯一索引，全表匹配之类的。
- extra除了前几列之外的重要信息。比如using index，using where提示可以使用的优化。
- key_len使用了索引的长度，越短越好。

### SQL语句的优化
⒈优化insert语句：一次插入多值；

⒉应尽量避免在 where 子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描；

⒊应尽量避免在 where 子句中对字段进行null值判断，否则将导致引擎放弃使用索引而进行全表扫描；

⒋优化嵌套查询：子查询可以被更有效率的连接(Join)替代；

⒌很多时候用 exists 代替 in 是一个好的选择。

⒍选择最有效率的表名顺序：数据库的解析器按照从右到左的顺序处理FROM子句中的表名，FROM子句中写在最后的表将被最先处理
- 在FROM子句中包含多个表的情况下：
  - 如果三个表是完全无关系的话，将记录和列名最少的表，写在最后，然后依次类推。也就是说：选择记录条数最少的表放在最后。
  - 如果有3个以上的表连接查询：如果三个表是有关系的话，将引用最多的表，放在最后，然后依次类推。也就是说：被其他表所引用的表放在最后。


⒎用IN代替OR：
```sql
select * from emp where sal = 1500 or sal = 3000 or sal = 800;
select * from emp where sal in (1500,3000,800);
```
⒏SELECT子句中避免使用*号：
我们最开始接触 SQL 的时候，“\*” 号是可以获取表中全部的字段数据的，但是它要通过查询数据字典完成，这意味着将消耗更多的时间，而且使用 “\*” 号写出来的 SQL 语句也不够直观。

## 索引优化
建议在经常作查询选择的字段、经常作表连接的字段以及经常出现在 order by、group by、distinct 后面的字段中建立索引。

但是有些情况索引会失效
### 索引失效的情况
1. like 以%开头，索引无效；当like前缀没有%，后缀有%时，索引有效。
2. or语句前后没有同时使用索引。当or左右查询字段只有一个是索引，该索引失效，只有当or左右查询字段均为索引时，才会生效
3. 组合索引的情况下，必须满足最左匹配原则(eg：多列索引col1、col2和col3，则索引生效的情形包括col1或col1，col2或col1，col2，col3)。
4. 数据类型出现隐式转化。如varchar不加单引号的话可能会自动转换为int型，使索引无效，产生全表扫描。
5. 在索引字段上使用not，<>，!=。不等于操作符是永远不会用到索引的，因此对它的处理只会产生全表扫描。 优化方法： key<>0 改为 key>0 or key<0。
6. 当全表扫描速度比索引速度快时，mysql会使用全表扫描，此时索引失效。
7. 对索引字段进行计算操作、字段上使用函数。（索引为 emp(ename,empno,sal)）

## 表结构优化
1. 选择合适数据类型
2. 遵守三大范式
3. 表的垂直拆分
   - 把不常用的字段单独放在同一个表中；
   - 把大字段独立放入一个表中；
   - 把经常使用的字段放在一起； 
4. 表的水平拆分
    - 表的水平拆分用于解决数据表中数据过大的问题，水平拆分每一个表的结构都是完全一致的
    - 对ID进行hash运算，如果要拆分成5个表，mod(id,5)取出0~4个值；
   - 针对不同的hashID将数据存入不同的表中；

---
部分转载自：https://www.yuque.com/fanzhengxu/tba6b8/dx0hvw#QHAdi


> 大表查询如何优化

- 限定数据的范围。查询的时候带where，比如限定时间等
- 读写分离。主库负责写，从库负责读
- 垂直分区。把一张表多列拆分
  - 优点：可以使得列数据变小，在查询时减少读取的Block数，减少IO次数
  - 缺点：主键冗余，需要使用join操作
- 水平分区。把数据分成多张表

> 如何实现读写分离，如何保证同步

主库写，然后通过传递binlog，从库重新执行binlog的命令。

同步
- 当发出写请求，等从库完全同步了再返回。
- 缓存标记。当发起写请求，在缓存中标记，并给出可能的主从库延迟时间。当读操作进来，如果有标记，就去访问主库。

> join的时候哪个是驱动表，哪个是被驱动的

驱动表选小表，比如left join的时候，左表是驱动表。因为需要遍历左表索引失效，然后去右表匹配，右表可以使用索引。exists和in同理

> mysql中exists和in的区别

对B查询涉及id，使用索引，故B表效率高，可用大表 -->外小内大

`select * from A where exists (select * from B where A.id=B.id);`

对A查询涉及id，使用索引，故A表效率高，可用大表 -->外大内小

`select * from A where A.id in (select id from B);`


**区别**

1、exists是对外表做loop循环，每次loop循环再对内表（子查询）进行查询，那么因
为对内表的查询使用的索引（内表效率高，故可用大表），而外表有多大都需要遍
历，不可避免（尽量用小表），故内表大的使用exists，可加快效率；
以上面为例，也就是A.id一个一个遍历，如果有A.id=B.id的就筛选出来
2、in是把外表和内表做hash连接，先查询内表，再把内表结果与外表匹配，对外表
使用索引（外表效率高，可用大表），而内表多大都需要查询，不可避免，故外表
大的使用in，可加快效率。
先查询B，然后去A中通过索引查询是否有id一致的

# sql 查询语句
> 增删改查语句

```sql
insert into TABLENAME values(....)
select ... from TABLENAME where ...
update TABLENAME set name=".." where ...
delete from TABLENAME where ...
```

> 编写一个 SQL 查询来实现分数排名。
如果两个分数相同，则两个分数排名（Rank）相同。请注意，平分后的下一个名次应该是下一个连续的整数值。换句话说，名次之间不应该有“间隔”。
```
+----+-------+
| Id | Score |
+----+-------+
| 1  | 3.50  |
| 2  | 3.65  |
| 3  | 4.00  |
| 4  | 3.85  |
| 5  | 4.00  |
| 6  | 3.65  |
+----+-------+
```
例如，根据上述给定的 Scores 表，你的查询应该返回（按分数从高到低排列）：
```
+-------+------+
| Score | Rank |
+-------+------+
| 4.00  | 1    |
| 4.00  | 1    |
| 3.85  | 2    |
| 3.65  | 3    |
| 3.65  | 3    |
| 3.50  | 4    |
+-------+------+
```

```sql
select s1.score,count(distinct s2.score) as "rank"
from scores as s1,scores as s2
where s1.score<=s2.score
group by s1.id
order by s1.score desc;
```

> 表：Logs
```
+-------------+---------+
| Column Name | Type    |
+-------------+---------+
| id          | int     |
| num         | varchar |
+-------------+---------+
```
id 是这个表的主键。
编写一个 SQL 查询，查找所有至少连续出现三次的数字。
返回的结果表中的数据可以按 任意顺序 排列。
查询结果格式如下面的例子所示：
Logs 表：
```
+----+-----+
| Id | Num |
+----+-----+
| 1  | 1   |
| 2  | 1   |
| 3  | 1   |
| 4  | 2   |
| 5  | 1   |
| 6  | 2   |
| 7  | 2   |
+----+-----+
Result 表：
+-----------------+
| ConsecutiveNums |
+-----------------+
| 1               |
+-----------------+
```
1 是唯一连续出现至少三次的数字。

```sql
select distinct a.Num as "ConsecutiveNums"
from Logs as a, Logs as b, Logs as c
where a.Num=b.Num and b.Num=c.Num and a.id=b.id-1 and b.id=c.id-1;
```

>某网站包含两个表，Customers 表和 Orders 表。编写一个 SQL 查询，找出所有从不订购任何东西的客户。
```
Customers 表：
+----+-------+
| Id | Name  |
+----+-------+
| 1  | Joe   |
| 2  | Henry |
| 3  | Sam   |
| 4  | Max   |
+----+-------+
Orders 表：
+----+------------+
| Id | CustomerId |
+----+------------+
| 1  | 3          |
| 2  | 1          |
+----+------------+
例如给定上述表格，你的查询应返回：
+-----------+
| Customers |
+-----------+
| Henry     |
| Max       |
+-----------+
```
```sql
select Customers.Name as "Customers" from Customers
where Customers.Id not in (select CustomerId from Orders);
```

>Employee 表包含所有员工信息，每个员工有其对应的 Id, salary 和 department Id。
```
+----+-------+--------+--------------+
| Id | Name  | Salary | DepartmentId |
+----+-------+--------+--------------+
| 1  | Joe   | 70000  | 1            |
| 2  | Jim   | 90000  | 1            |
| 3  | Henry | 80000  | 2            |
| 4  | Sam   | 60000  | 2            |
| 5  | Max   | 90000  | 1            |
+----+-------+--------+--------------+
Department 表包含公司所有部门的信息。
+----+----------+
| Id | Name     |
+----+----------+
| 1  | IT       |
| 2  | Sales    |
+----+----------+
编写一个 SQL 查询，找出每个部门工资最高的员工。对于上述表，您的 SQL 查询应返回以下行（行的顺序无关紧要）。
+------------+----------+--------+
| Department | Employee | Salary |
+------------+----------+--------+
| IT         | Max      | 90000  |
| IT         | Jim      | 90000  |
| Sales      | Henry    | 80000  |
+------------+----------+--------+
```

```sql
select d.Name Department,e.Name Employee,Salary
from  Employee e
join Department d 
on e.DepartmentId=d.Id
where(e.DepartmentId , Salary) IN(
    select DepartmentId, max(salary)
    from Employee
    group by DepartmentId
);
```

> Employee 表包含所有员工信息，每个员工有其对应的工号 Id，姓名 Name，工资 Salary 和部门编号 DepartmentId 。
```
+----+-------+--------+--------------+
| Id | Name  | Salary | DepartmentId |
+----+-------+--------+--------------+
| 1  | Joe   | 85000  | 1            |
| 2  | Henry | 80000  | 2            |
| 3  | Sam   | 60000  | 2            |
| 4  | Max   | 90000  | 1            |
| 5  | Janet | 69000  | 1            |
| 6  | Randy | 85000  | 1            |
| 7  | Will  | 70000  | 1            |
+----+-------+--------+--------------+
Department 表包含公司所有部门的信息。
+----+----------+
| Id | Name     |
+----+----------+
| 1  | IT       |
| 2  | Sales    |
+----+----------+
编写一个 SQL 查询，找出每个部门获得前三高工资的所有员工。例如，根据上述给定的表，查询结果应返回：
+------------+----------+--------+
| Department | Employee | Salary |
+------------+----------+--------+
| IT         | Max      | 90000  |
| IT         | Randy    | 85000  |
| IT         | Joe      | 85000  |
| IT         | Will     | 70000  |
| Sales      | Henry    | 80000  |
| Sales      | Sam      | 60000  |
+------------+----------+--------+
```
```sql
select d.name Department, a.name Employee, a.salary Salary from employee a 
left join employee b on a.departmentId = b.departmentId and a.salary < b.salary 
left join department d on a.departmentId = d.id
where a.departmentId = d.id
GROUP BY a.id HAVING COUNT(distinct b.salary) <=2
order by a.departmentId,a.salary desc
```

> 编写一个 SQL 查询，来查找与之前（昨天的）日期相比温度更高的所有日期的 id 。
返回结果 不要求顺序 。
查询结果格式如下例：
```
Weather
+----+------------+-------------+
| id | recordDate | Temperature |
+----+------------+-------------+
| 1  | 2015-01-01 | 10          |
| 2  | 2015-01-02 | 25          |
| 3  | 2015-01-03 | 20          |
| 4  | 2015-01-04 | 30          |
+----+------------+-------------+
Result table:
+----+
| id |
+----+
| 2  |
| 4  |
+----+
2015-01-02 的温度比前一天高（10 -> 25）
2015-01-04 的温度比前一天高（20 -> 30）
```
```sql
select a.id from Weather a, Weather b where a.Temperature > b.Temperature and dateDiff(a.recordDate,b.recordDate)=1;
```

> 有一个courses 表 ，有: student (学生) 和 class (课程)。
请列出所有超过或等于5名学生的课。
例如，表：
```
+---------+------------+
| student | class      |
+---------+------------+
| A       | Math       |
| B       | English    |
| C       | Math       |
| D       | Biology    |
| E       | Math       |
| F       | Computer   |
| G       | Math       |
| H       | Math       |
| I       | Math       |
+---------+------------+
应该输出:
+---------+
| class   |
+---------+
| Math    |
+---------+
```
```sql
select class from courses group by class having count(distinct student)>=5;
```

>小美是一所中学的信息科技老师，她有一张 seat 座位表，平时用来储存学生名字和与他们相对应的座位 id。
其中纵列的 id 是连续递增的
小美想改变相邻俩学生的座位。
你能不能帮她写一个 SQL query 来输出小美想要的结果呢？
示例：
```
+---------+---------+
|    id   | student |
+---------+---------+
|    1    | Abbot   |
|    2    | Doris   |
|    3    | Emerson |
|    4    | Green   |
|    5    | Jeames  |
+---------+---------+
假如数据输入的是上表，则输出结果如下：
+---------+---------+
|    id   | student |
+---------+---------+
|    1    | Doris   |
|    2    | Abbot   |
|    3    | Green   |
|    4    | Emerson |
|    5    | Jeames  |
+---------+---------+
```
```sql
select(
    case
    when mod(id,2)=1 and id=(select count(*) from seat) then id
    when mod(id,2)=1 then id+1
    else id-1
    end
) as id, student from seat order by id;
```

>给定一个 salary 表，如下所示，有 m = 男性 和 f = 女性 的值。交换所有的 f 和 m 值（例如，将所有 f 值更改为 m，反之亦然）。要求只使用一个更新（Update）语句，并且没有中间的临时表。
注意，您必只能写一个 Update 语句，请不要编写任何 Select 语句。
例如：
```
| id | name | sex | salary |
|----|------|-----|--------|
| 1  | A    | m   | 2500   |
| 2  | B    | f   | 1500   |
| 3  | C    | m   | 5500   |
| 4  | D    | f   | 500    |
运行你所编写的更新语句之后，将会得到以下表:
| id | name | sex | salary |
|----|------|-----|--------|
| 1  | A    | f   | 2500   |
| 2  | B    | m   | 1500   |
| 3  | C    | f   | 5500   |
| 4  | D    | m   | 500    |
```
```sql
update salary set sex=if(sex="m","f","m");
```

> 查询每个班成绩排名前三的学生信息. 注意并列情况

```sql
select 
    * 
from t_student t
where 
    (select count(1) from t_student where class_id=t.class_id and score>t.score)
    < 3
```

# mysql架构
[文章](https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247485097&idx=1&sn=84c89da477b1338bdf3e9fcd65514ac1&chksm=cea24962f9d5c074d8d3ff1ab04ee8f0d6486e3d015cfd783503685986485c11738ccb542ba7&token=79317275&lang=zh_CN%23rd)
> 讲一下mysql的架构

分为Server层和存储引擎。

Server层有：
- 连接器： 身份认证和权限相关(登录 MySQL 的时候)。
- 查询缓存:  执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。
- 分析器:  没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。
- 优化器： 按照 MySQL 认为最优的方案去执行。
- 执行器:  执行语句，然后从存储引擎返回数据。

存储引擎就是负责数据的存储和读取的，支持innodb和myisam，Memory等多个引擎

## 连接器

连接器主要和身份认证和权限相关的功能相关，就好比一个级别很高的门卫一样。

主要负责用户登录数据库，进行用户的身份认证，包括校验账户密码，权限等操作，如果用户账户密码已通过，连接器会到权限表中查询该用户的所有权限，之后在这个连接里的权限逻辑判断都是会依赖此时读取到的权限数据，也就是说，==后续只要这个连接不断开，即时管理员修改了该用户的权限，该用户也是不受影响的。==

## 查询缓存(MySQL 8.0 版本后移除)
连接建立后，执行查询语句的时候，会先查询缓存，MySQL 会先校验这个 sql 是否执行过，以 Key-Value 的形式缓存在内存中，Key 是查询预计，Value 是结果集。如果缓存 key 被命中，就会直接返回给客户端，如果没有命中，就会执行后续的操作，完成后也会把结果缓存起来，方便下一次调用。当然在真正执行缓存查询的时候还是会校验用户的权限，是否有该表的查询条件。

==MySQL 查询不建议使用缓存，因为查询缓存失效在实际业务场景中可能会非常频繁，假如你对一个表更新的话，这个表上的所有的查询缓存都会被清空。对于不经常更新的数据来说，使用缓存还是可以的。==

## 分析器
MySQL 没有命中缓存，那么就会进入分析器，分析器主要是用来分析 SQL 语句是来干嘛的，分析器也会分为几步：

第一步，词法分析，一条 SQL 语句有多个字符串组成，首先要提取关键字，比如 select，提出查询的表，提出字段名，提出查询条件等等。做完这些操作后，就会进入第二步。

第二步，语法分析，主要就是判断你输入的 sql 是否正确，是否符合 MySQL 的语法。

完成这 2 步之后，MySQL 就准备开始执行了，但是如何执行，怎么执行是最好的结果呢？这个时候就需要优化器上场了。

## 优化器

优化器的作用就是它认为的最优的执行方案去执行，比如多个索引的时候该如何选择索引，多表查询的时候如何选择关联顺序等。

可以说，经过了优化器之后可以说这个语句具体该如何执行就已经定下来。

## 执行器

当选择了执行方案后，MySQL 就准备开始执行了，==首先执行前会校验该用户有没有权限，如果没有权限，就会返回错误信息==，如果有权限，就会去调用引擎的接口，返回接口执行的结果。

> sql如何执行一条指令

- 查询
  - 连接器（权限校验）-》查询缓存 -》分析器（分析语法）-》优化器-》执行器-》引擎
- 更新
  - 连接器-》分析器-》优化器-》执行器-》引擎-》redo log prepare -》binlog -》 redo log commit


> 讲一下redo log和binlog怎么保持一致性

先写redo log，然后redo log进入prepare状态并通知执行器，然后执行器写binlog，写完后，标志着事务成功了，然后将redo log commit。


> mysql的事务执行成功的标志是什么

binlog成功写入就代表事务成功了。

> redo log和binlog的作用

redo log是innodb提供的，为了确保事务的持久性。防止在发生故障后，有数据还未写入磁盘。

binlog是sql server提供的，为了主从复制。

# InnoDB和MyISAM索引
![](https://gitee.com/super-jimwang/img/raw/master/img/20210221154039.png)

## InnoDB和MyISAM所使用的索引
两种引擎都是使用B+树。

MyISAM引擎，B+树的数据结构中存储的内容实际上是实际数据的地址值。也就是说它的索引和实际数据是分开的，只不过使用索引指向了实际数据。这种索引的模式被称为非聚集索引。

Innodb引擎的索引的数据结构也是B+树，只不过数据结构中存储的都是实际的数据，这种索引有被称为聚集索引。

### MyISAM的索引实现原理
![](https://gitee.com/super-jimwang/img/raw/master/img/20210221165602.png)
![](https://gitee.com/super-jimwang/img/raw/master/img/20210221165528.png)
==**对于非聚簇索引，不管是主索引还是辅助索引，都只需要检索一遍就行了**==

MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。 


### InnoDB的索引实现原理
![](https://gitee.com/super-jimwang/img/raw/master/img/20210221165234.png)
虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。

第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，==**表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录**==。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。

上图是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。

第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，==**InnoDB的所有辅助索引都引用主键作为data域**==。例如，下图为定义在Col3上的一个辅助索引：

![](https://gitee.com/super-jimwang/img/raw/master/img/20210221165350.png)

聚集索引这种实现方式使得按主键的搜索十分高效，但是 ==**辅助索引（也就是非主键建立的索引）搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。**==


==**为什么辅助索引记录的是主键，而不是一整行的数据，或者指向主键的指针？**==
- 不记录一整行数据是为了节省空间。
- 而不使用指针是因为当行移动时，不用维护辅助索引。


### 相关问题
> 为什么innodb不建议使用过长的字段作为主键？

因为主键会作为辅助索引的存储叶子节点，所以太长会导致占用空间大

> 为什么innodb建议使用单调的主键

因为索引是一颗B+树，非单调的在插入记录时会发生频繁的调整

# innodb和myisam存储引擎的区别
在MySQL 5.5之前，MyISAM是mysql的默认数据库引擎，其由早期的ISAM（Indexed Sequential Access Method：有索引的顺序访问方法）所改良。虽然MyISAM性能极佳，但却有一个显著的缺点：不支持事务处理。不过，MySQL也导入了另一种数据库引擎InnoDB，以强化参考完整性与并发违规处理机制，后来就逐渐取代MyISAM。

## 区别
**存储结构：**
- MyISAM表是独立于操作系统的，这说明可以轻松地将其从Windows服务器移植到Linux服务器；每当我们建立一个MyISAM引擎的表时，就会在本地磁盘上建立三个文件，文件名就是表明。例如，我建立了一个MyISAM引擎的test表，那么就会生成以下三个文件：
  - test.frm，存储表定义；
  - test.MYD，存储数据；
  - test.MYI，存储索引。==**索引文件中的索引指向数据文件中的数据**==
- InnoDB ==**使用表空间存储数据和索引。**== 可以选择使用共享表空间还是独占表空间，默认是共享表。除了表空间，InnoDB也会生成.frm存储表定义。
  - 共享表空间以及独占表空间都是针对数据的从物理意义上来讲
  - 共享表空间:  会把表集中存储在一个系统表空间里。即每一个数据库的所有表的数据，索引文件全部放在一个文件中。该文件目录默认的是服务器的数据目录。 默认的文件名为:ibdata1  初始化为10M。
  - 独占表空间:  每一个表分别创建一个表空间，这时。在对应的数据库目录里每一个表都有.ibd文件(这个文件包括了单独一个表的数据内容以及索引内容)。
  - 总共生产2个文件：
    - test.frm
    - test.ibd

**存储空间：**
- MyISAM可被压缩，占据的存储空间较小，支持静态表、动态表、压缩表三种不同的存储格式。
  - 静态表：比如char(20)，那么就会实打实的存20个字符，如果不足20个字符，用空格填充满。查询速度快因为知道下一个字段一定从21个字符开始。但是需要更多的存储空间。
  - 动态表：比如char(20)，实际有多少存多少。用更少的存储空间，但是难以维护。
  - 压缩表：只读表，每条记录分开压缩，所以不能同时访问
- InnoDB需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引。（使用LRU最近最少使用的置换算法）

**可移植性、备份及恢复：**
- MyISAM的数据是以文件的形式存储 ==**是独立于操作系统的**== ，所以在跨平台的数据转移中会很方便，同时在备份和恢复时也可单独针对某个表进行操作。
- InnoDB备份的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了。

**事务支持：**
- MyISAM强调的是性能，每次查询具有原子性，其执行数度比InnoDB类型更快，但是不提供事务支持。
- InnoDB提供事务、外键等高级数据库功能，具有事务提交、回滚和崩溃修复能力。

**AUTO_INCREMENT：**
- InnoDB的auto_increment字段必须是索引。如果是组合索引，必须为组合索引的第一列。
  - ```sql
    create table autoincrement_demo_inno(
    id1 int not null auto_increment,
    id2 int not null,
    name varchar(10),
    index(id1, id2)
    ) engine=InnoDB
    ```
  - 这里插入几条数据，id1就会增加多少

- 在MyISAM中，auto_increment字段也必须是索引，但如果是组合索引，可以不是组合索引的第一列
  - ```sql
    create table autoincrement_demo_inno(
    id1 int not null auto_increment,
    id2 int not null,
    name varchar(10),
    index(id2, id1)
    ) engine=MyISAM
    ```
  - 这里自增的是id1，但是索引第一个是id2.结果如下
  - ![](https://gitee.com/super-jimwang/img/raw/master/img/20210221152113.png)
  - id1的自增在id2相同的情况下才会进行。

**表锁差异：**
- MyISAM只支持表级锁，用户在操作MyISAM表时，select、update、delete和insert语句都会给表自动加锁，如果加锁以后的表满足insert并发的情况下，可以在表的尾部插入新的数据。
- InnoDB支持事务和行级锁。行锁大幅度提高了多用户并发操作的新能，但是==**InnoDB的行锁，只是在唯一索引是有效的**==，非唯一索引的WHERE都会锁全表的。

表主键：
- MyISAM允许没有任何索引和主键的表存在，==**索引保存的是行的地址，不含数据**==。
- 对于InnoDB，如果没有设定主键或者非空唯一索引，就会自动生成一个6字节的主键(用户不可见)，==**InnoDB数据库中的数据和主键节点保存在一起，所有其他索引节点中保存的是主键索引的值。**==

**表的具体行数：**
- MyISAM保存表的总行数，select count() from table;会直接取出出该值；
- 而InnoDB没有保存表的总行数，如果使用select count() from table；就会遍历整个表，消耗相当大，但是在加了wehre条件后，myisam和innodb处理的方式都一样。

**CURD操作：**
- 在MyISAM中，如果执行大量的SELECT，MyISAM是更好的选择。
  - ==**为什么MyISAM查询更快？**== 看myisam与innodb的索引细节
    - 查询的时候，由于innodb支持事务，所以会有mvvc的一个比较。这个过程会损耗性能。
    - 查询的时候，如果走了索引，由于innodb是聚簇索引，会有一个回表的过程，即：先去非聚簇索引树中查询数据，找到数据对应的key之后，再通过key回表到聚簇索引树，最后找到需要的数据。而myisam直接就是非簇集索引，查询的时候查到的最后结果不是聚簇索引树的key，而是磁盘地址，所以会直接去查询磁盘。
    - 锁的一个损耗，innodb锁支持行锁，在检查锁的时候不仅检查表锁，还要看行锁。
- 对于InnoDB，如果你的数据执行大量的INSERT或UPDATE，出于性能方面的考虑，应该使用InnoDB表（并发的时候，myisam是表锁，而innodb可以做到行锁，所以innodb更快）。DELETE从性能上InnoDB更优，但DELETE FROM table时，InnoDB不会重新建立表，而是一行一行的删除，在innodb上如果要清空保存有大量数据的表，最好使用truncate table这个命令。

**外键：**
MyISAM不支持外键，而InnoDB支持外键。

## 总结
MyISAM更适合读多，并发少的场景。

> 如何通过索引找到记录

通过索引遍历树，到达叶子节点的页。叶子结点的关键字多的话会导致一页装不下。

遍历这一页，如果该页没有，就接着去下一页找，前一页有指向后一页的指针。

# drop、truncate、delete区别
- drop 直接删除表；
- truncate 删除表中数据，再插入时自增长id又从1开始 ；
- delete 删除表中数据，可以加where字句。
 
drop table：
- 属于DDL（Data Definition Language，数据库定义语言）
- 不可回滚
- 不可带 where
- 删除表内容和结构
- 删除速度快


truncate table：
- 属于DDL（Data Definition Language，数据库定义语言）
- 不可回滚
- 不可带 where
- 删除表内容
- 删除速度快
 
delete from：
- 属于DML
- 可回滚
- 可带where
- 表结构在，表内容要看where执行的情况
- 删除速度慢,需要逐行删除
 
使用简要说明：
- 不再需要一张表的时候，用drop
- 想删除部分数据行时候，用delete，并且带上where子句
- 保留表而删除所有数据的时候用truncate


---
部分转载自：https://www.yuque.com/fanzhengxu/tba6b8/dx0hvw#oWBVa

# B树、B+树区别，索引为何使用B+树
## B树
描述一颗B树时需要指定它的阶数，阶数表示了一个结点最多有多少个孩子结点，一般用字母m表示阶数。当m取2时，就是我们常见的二叉搜索树。

一颗m阶的B树定义如下：
1）每个结点最多有m-1个关键字。
2）根结点最少可以只有1个关键字。
3）非根结点至少有Math.ceil(m/2)-1个关键字。
4）每个结点中的关键字都按照从小到大的顺序排列，**每个关键字的左子树中的所有关键字都小于它，而右子树中的所有关键字都大于它。**
5）所有叶子结点都位于同一层，或者说根结点到每个叶子结点的长度都相同。

下图为**4阶B树**：
![](https://gitee.com/super-jimwang/img/raw/master/img/20210221172547.png)

一个节点可以最多保存3个(4-1)数据.并且非根节点，每个节点至少要有3/2向上取整-1个数据。

## B+树
1. 有n个子节点的非叶子结点中**含有n个关键字（b树是n-1个），这里不同地方的说法不同，也可能是n-1个。与B树保持一致**，这些关键字不保存数据，只用来索引，所有数据都保存在叶子节点（b树是每个关键字都保存数据）;
2. 所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接;
3. 所有的非叶子结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字;
4. **通常在b+树上有两个头指针，一个指向根结点，一个指向关键字最小的叶子结点;**
5. 同一个数字会在不同节点中重复出现，根节点的最大元素就是b+树的最大元素。

![](https://gitee.com/super-jimwang/img/raw/master/img/20210221173550.png)

## 索引为什么用B+树，而不是B树
B+树的非叶子结点只包含导航信息，不包含实际的值，所有的叶子结点和相连的节点使用链表相连，便于区间查找和遍历。

**B+ 树的优点在于：**

**IO次数更少**：由于B+树在内部节点上不包含数据信息，因此在内存页中能够存放更多的key。 数据存放的更加紧密，具有更好的空间局部性。因此**访问叶子节点上关联的数据也具有更好的缓存命中率。**

遍历更加方便：B+树的叶子结点都是相链的，因此对整棵树的遍历只需要一次线性遍历叶子结点即可。而且由于数据顺序排列并且相连，所以便于区间查找和搜索。而B树则需要进行每一层的递归遍历。相邻的元素可能在内存中不相邻，所以缓存命中性没有B+树好。


**B树的优点**
- 由于节点就存了数据，所以不需要访问到叶子节点，访问更迅速。

### 原因
1、 ==**B+树的磁盘读写代价更低**==：B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B树更小，如果把所有同一内部节点的关键字存放在同一盘块中，==那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对IO读写次数就降低了。==

2、==**B+树的查询效率更加稳定**==：由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。==所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。==

3、==**B+树更便于遍历**==：由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在区间查询的情况，所以通常B+树用于数据库索引。==**数据都在叶子节点，叶子节点又有额外的指针相连，所以区间查询以及遍历更容易**==

4、==B+树更适合基于范围的查询==：B树在提高了IO性能的同时并没有解决元素遍历的我效率低下的问题，正是为了解决这个问题，B+树应用而生。B+树只需要去遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作或者说效率太低。

> 如何根据索引找到一个记录

通过根节点开始遍历一个索引的B+树，通过各层非叶子节点达到底层的叶子节点的数据页（Page），这个Page内部存放的都是叶子节点
在Page内部从“Infimum”节点开始遍历单链表（遍历一般会被优化），如果找到键则返回。如果遍历到了“Supremum”，说明当前Page里没有合适的键，这时借助Page页内部的next page指针，跳转到下一个page继续从“Infmum”开始逐个查找

# 死锁判定原理和具体场景
## 什么是死锁
数据库是一个多用户使用的共享资源，当多个用户 并发地存取数据的时候，在数据库中就会发生多个事务同时存取同一个数据的情况，加锁是进行数据库并发控制的一种非常重要的技术。在实际应用中，如果两个事务需要一组有冲突的锁，而不能继续进行下去，这时便发生了死锁。

## 死锁的原因
**1.事务之间对资源访问顺序的交替**

==此类常见于两个用户分别首先访问A表和B表，并锁住当前表，但是双方都需要访问对方锁住的表，都在等待对方释放锁，==
也就是经典的刀叉问题。像这样的死锁，基本上就是程序员的编程逻辑出现了问题，需要调整程序的逻辑。

**2.并发修改同一记录**

此类常见于用户A查询一条纪录，然后修改该条纪录；这时用户B修改该条纪录，这时用户A的事务里锁的性质由查询的共享锁企图上升到独占锁，而==用户B里的独占锁由于A有共享锁存在所以必须等A释放掉共享锁，而A由于B的独占锁而无法上升的独占锁也就不可能释放共享锁，于是出现了死锁。== 这种死锁由于比较隐蔽，但在稍大点的项目中经常发生。像这样的解决办法就是使用乐观锁，在表的字段中增加version字段，更新时进行查询version是否为当前取到version。乐观锁可以避免长事务中的数据库加锁开销。最不推荐的是采用悲观锁进行控制，悲观锁会使排队等待的时间相当漫长，会发生灾难性的后果。
- ==独占锁获取了同步状态之后，其他独占和共享访问都会阻塞。 共享锁获取了同步状态之后，共享访问不会被阻塞，独占访问会被阻塞。==

**3.索引不当导致全表扫描**

此类常见于在事务中执行了一条不满足的语句，执行全表扫描，把行级锁上升为表级锁，多个这样的事务执行之后，就很容易产生死锁和阻塞。类似的情况还有当表中的数据量非常庞大而索引建的过少或不合适的时候，使得经常发生全表扫描，最终应用系统会越来越慢，最终发生阻塞或死锁。解决其办法有，SQL语句中不要使用太复杂的关联多表的查询；使用“执行计划”对SQL语句进行分析，对于有全表扫描的SQL语句，建立相应的索引进行优化。

**4.事务封锁范围大且相互等待**
保持事务简短并在一个批处理中
在同一数据库中并发执行多个需要长时间运行的事务时通常发生死锁。事务运行时间越长，其持有排它锁或更新锁的时间也就越长，从而堵塞了其它活动并可能导致死锁。保持事务在一个批处理中，可以最小化事务的网络通信往返量，减少完成事务可能的延迟并释放锁。

使用低隔离级别
确定事务是否能在更低的隔离级别上运行。执行提交读允许事务读取另一个事务已读取（未修改）的数据，而不必等待第一个事务完成。使用较低的隔离级别（例如提交读）而不使用较高的隔离级别（例如可串行读）可以缩短持有共享锁的时间，从而降低了锁定争夺（比如这次的S NK和X IK 是InnoDB引擎Repeatable Read级别才有的）。

## 如何解决死锁问题
- 查出死锁的线程杀死
- 设置锁的超时时间
- 指定获取锁的顺序

# 数据库三范式
## 第一范式
**列不可分**

1NF（第一范式）是对属性具有**原子性**的要求，不可再分。
比如：

| 学号 | 姓名 | 性别 | 出生年月日 |
| ---- | ---- | ---- | ---------- |
|      |      |      |            |
如果认为年月日可以分为年、月、日。那么这就不满足1NF

## 第二范式
**消除非主属性对码对部分函数依赖**

2NF（第二范式）是对记录有唯一性的要求，即实体的唯一性，不存在部分依赖，每一列与主键都相关

比如：

| 学号 | 课程号 | 姓名 | 学分 |
| ---- | ------ | ---- | ---- |
|      |        |      |      |
该表明显说明了：学生信息和课程信息。正常的依赖应该是：学分依赖课程号，姓名依赖学号。但是这里非主键字段对码的部分依赖，即与主键不相关，不满足第二范式的要求。

==**这里的主键是学号和课程号，姓名部分依赖，只依赖学号，而学分也是部分依赖，只依赖课程号**==

可能存在的问题：
- 数据冗余：每条记录都含有相同信息；
- 删除异常：删除所有学生成绩，就把课程信息全删除了；
- 插入异常：学生未选课，无法记录进数据库；
- 更新异常：调整课程学分，所有行都调整。

正确的做法：

| 课程号 | 学分 |
| ------ | ---- |
|        |      |



| 学号 | 姓名 |
| ---- | ---- |
|      |      |

| 学号 | 课程号 |
| ---- | ------ |
|      |        |



## 第三范式
**消除非主属性对码的传递函数依赖**

3NF对字段有冗余性对要求，任何字段不能由其他字段派生出来，它要求字段没有冗余，即不存在传递依赖。

比如：

| 学号 | 姓名 | 年龄 | 学院 | 学院电话 |
| ---- | ---- | ---- | ---- | -------- |
|      |      |      |      |          |



明显，学院电话是冗余，存在依赖传递关系学号->姓名->学院->学院电话

==**这里学院电话是直接依赖于学院，通过传递关系，间接的依赖于主键学号**==

可能会存在的问题：
- 数据冗余：有重复值；
- 更新异常：有重复的冗余信息，修改时需要同时修改多条记录，否则会出现数据不一致的情况 。
正确的做法：

| 学号 | 姓名 | 年龄 | 学院 |
| ---- | ---- | ---- | ---- |
|      |      |      |      |

| 学院 | 学院电话 |
| ---- | -------- |
|      |          |



## 区分第二范式和第三范式
第二范式是非主键对主键的部分依赖。也就是说主键有多个属性，但是非主键只依赖以其中的一部分，而不是全部。

第三范式是在第二范式的基础上，强调非主键必须直接依赖于主键，不能是传递关系。

---

部分转载自：https://www.yuque.com/fanzhengxu/tba6b8/dx0hvw

# 事务的ACID和隔离级别
## 什么是事务以及ACID

事务简单来说：一个Session中所进行的所有操作，要么同时成功，要么同时失败；作为单个逻辑工作单元执行的一系列操作，满足四大特性：
- 原子性（Atomicity）：事务作为一个整体被执行 ，要么全部执行，要么全部不执行
- 一致性（Consistency）：保证数据库状态从一个一致状态转变为另一个一致状态
- 隔离性（Isolation）：多个事务并发执行时，一个事务的执行不应影响其他事务的执行
- 持久性（Durability）：一个事务一旦提交，对数据库的修改应该永久保存

## 事务的并发问题
- 丢失更新：一个事务的更新覆盖了另一个事务的更新；
- 脏读：一个事务读取了另一个事务未提交的数据；
  - ==**其实就是读到了别的事务回滚前的脏数据。比如事务B执行过程中修改了数据X，在未提交前，事务A读取了X，而事务B却回滚了，这样事务A就形成了脏读。**==
- 不可重复读：不可重复读的重点是修改，同样条件下两次读取结果不同，也就是说，被读取的数据可以被其它事务修改；
  - ==**事务A首先读取了一条数据，然后执行逻辑的时候，事务B将这条数据改变了，然后事务A再次读取的时候，发现数据不匹配了，就是所谓的不可重复读了。**==
  - ==**也就是说，当前事务先进行了一次数据读取，然后再次读取到的数据是别的事务修改成功的数据，导致两次读取到的数据不匹配，也就照应了不可重复读的语义。**==
- 幻读：幻读的重点在于新增或者删除，同样条件下两次读出来的记录数不一样。
  - ==**事务A首先根据条件索引得到N条数据，然后事务B改变了这N条数据之外的M条或者增添了M条符合事务A搜索条件的数据，导致事务A再次搜索发现有N+M条数据了，就产生了幻读。**==

## 隔离级别
==⚠注意：innodb的隔离级别的定义与sql标准稍有区别==
隔离级别决定了一个session中的事务可能对另一个session中的事务的影响。

- 读未提交（READ UNCOMMITTED）：最低级别的隔离，通常又称为dirty read，它 ==**允许一个事务读取另一个事务还没 commit 的数据，这样可能会提高性能**==，但是会导致**脏读问题**；
- 读已提交（READ COMMITTED）：在一个事务中只允许对其它事务已经 commit 的记录可见，该隔离级别**不能避免不可重复读问题**；
  - 一个事务执行的过程中，其他事务修改了数据，从而导致该事务多次读取数据不匹配。
- 可重复读（REPEATABLE READ,MySQL默认的隔离级别）：==**在一个事务开始后，其他事务对数据库的修改在本事务中不可见，直到本事务 commit 或 rollback。**== 但是，其他事务的 insert/delete 操作对该事务是可见的，也就是说，该隔离级别并不能避免幻读问题。在一个事务中重复 select 的结果一样，除非本事务中 update 数据库。
  - ==**可以解决不可重复读，事务过程中，其他事务对数据的修改不再可见。但是其他事务还能增删，所以还有幻读问题。**==
- 可串行化（SERIALIZABLE）：最高级别的隔离，只允许事务串行执行。
  - 事物a 执行读写操作时，会锁定检索的数据行范围（范围锁），这种锁会阻止其他事物在本范围内的一切操作，只有事物a执行完毕，提交事物后，才会释放范围锁，这样就避免了幻读。


MySQL的事务支持不是绑定在MySQL服务器本身，而是与存储引擎相关：
- MyISAM：不支持事务，用于只读程序提高性能；
- InnoDB：支持ACID事务、行级锁、并发；

## 解决方案
### MVCC
mvcc多版本并发控制（Multi-Version Conncurrency Control）是mysql中基于乐观锁原理实现的隔离级别的方式。==**用于实现读已提交和可重复读取隔离级别。**==

InnoDB的MVCC，是 ==**通过在每行记录后面保存两个隐藏的列来实现的。这两个列，一个保存了行的创建时间，一个保存行的过期时间（或删除时间），当然存储的并不是实际的时间值，而是系统版本号（system version number）.**== ==每开始一个新的事务，系统版本号== 都会自动递增，事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。下面看一下在repeatable Read 隔离级别下，MVCC具体是如何操作的。
- SELECT
  - （1）InnoDB只查找版本遭遇当前事务版本的数据行（行的系统版本号小于或等于事务的系统版本号），这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的。
  - （2）行的删除版本要么未定义，要么大于当前事务版本号，这可以确保事务读取到的行，在事务开始之前没有被删除。
		只有符合上述两个条件的记录，才能作为查询结果。
- INSERT
  - innoDB为新插入的每一行保存当前系统版本作为行版本号。
- DELETE
  - innoDB为删除的每一行保存当前系统版本号作为行删除标识。
- UPDATE
	- InnoDB为==插入一行新记录，保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为行删除标识==


#### MVCC使用快照读和当前读解决可重复读
**select 快照读**
当执行select操作， ==innodb默认会执行快照读，会记录下这个select后的结果，之后select的时候就会返回这次快照的数据，即使其他事务提交了不会影响当前select的数据，这就实现了可重复读了。== 快照的生成当在第一次执行select的时候，也就是说假设当A开启了事务，然后没有执行任何操作，这个时候B insert了一条数据然后commit，这时候A执行select，满额返回的数据中心就会有B添加的那条数据，之后无论再有其他事务commit都没有关系，因为快照已经生成了，后面的select都是根据快照来的。

**当前读**
对于会对数据修改的操作（update,insert,delete）都是采用当前读的模式。在执行这几个操作时会读取最新的版本号记录，写操作后把版本号改为了当前事务的版本号，所以即使是被其他的事务提交的数据也可以查询到。==假设要update一条数据，但是在另一个事务中已经delete掉这条数据并且commit了，如果update就会产生冲突，所以在update的时候需要知道最新的数据，也正是因为这样才导致幻读。==

### next-key锁解决幻读
InnoDB有三种行锁的算法：

1，Record Lock：单个行记录上的锁。在唯一索引查询的时候才会用行锁，其他情况都是next-key锁

2，Gap Lock：间隙锁，锁定一个范围，但不包括记录本身。GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况。

3，Next-Key Lock：1+2，锁定一个范围，并且锁定记录本身。对于行的查询，都是采用该方法，主要目的是解决幻读的问题。


当我们用范围条件而不是相等条件索引数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP）”。

根据检索条件向下寻找最靠近检索条件的记录值A作为左区间，向上寻找最靠近检索条件的记录值B作为右区间
![](https://gitee.com/super-jimwang/img/raw/master/img/20210222172613.png)
对于以上这个数据，
```sql
# session A
SELECT * FROM z WHERE b = 6 FOR UPDATE;

# session B
INSERT INTO z VALUES (2, 4);/*success*/
INSERT INTO z VALUES (2, 8);/*blocked*/
INSERT INTO z VALUES (4, 4);/*blocked*/
INSERT INTO z VALUES (4, 8);/*blocked*/
INSERT INTO z VALUES (8, 4);/*blocked*/
INSERT INTO z VALUES (8, 8);/*success*/
INSERT INTO z VALUES (0, 4);/*blocked*/
INSERT INTO z VALUES (-1, 4);/*success*/
```

索引 b 上的 next-key lock(间隙锁+行锁) 的范围是(b=4,id=3)到(b=6,id=5)这个左开右闭区间和(b=6,id=5)到(b=8,id=7)这个开区间。

![](https://gitee.com/super-jimwang/img/raw/master/img/20210222172731.png)
索引会根据 b 和 id 的值进行排序，插入不同的值，锁的范围是不一样的；分别插入 (b=4,id=2) 和(b=4,id=4)以及其他数时，插入的位置如图所示：
![](https://gitee.com/super-jimwang/img/raw/master/img/20210222172834.png)

因此，通过next-key锁锁住了范围内的间隙，就不会在出现幻读的现象了

### RR和RC下MVCC有什么区别

- 在RR中，只要事务开始之后读了一次数据，那么就会生产快照，只会读都会直接读这个快照，因此不论别的事务怎么改动，都是可重复读的。
- 而RC中，每次读都会生成一次快照，所以不可重复读。

> innodb的默认隔离级别以及使用的技术

默认隔离级别是可重复读RR，但是用到了MVCC的快照读和当前读技术以及next-key锁，所以可以解决幻读问题。对标SQL标准的可串行化。

> innodb行查询用了什么锁？有别的情况吗

用了next-key锁（gap锁+行锁）。当查询的索引含有唯一属性的时候，将next-key锁降级为行锁（record lock）。

> sql语句锁情况

1、SELECT ... FROM 是一个快照读，通过读取数据库的一个快照，不会加任何锁，除非将隔离级别设置成了 SERIALIZABLE 。在 SERIALIZABLE 隔离级别下，如果索引是非唯一索引，那么将在相应的记录上加上一个共享的next key锁。如果是唯一索引，只需要在相应记录上加index record lock。

2、SELECT ... FROM ... LOCK IN SHARE MODE 语句在所有索引扫描范围的索引记录上加上共享的next key锁。如果是唯一索引，只需要在相应记录上加index record lock。

3、 SELECT ... FROM ... FOR UPDATE 语句在所有索引扫描范围的索引记录上加上排他的next key锁。如果是唯一索引，只需要在相应记录上加index record lock。这将堵塞其他会话利用SELECT ... FROM ... LOCK IN SHARE MODE 读取相同的记录，但是快照读将忽略记录上的锁。

4.、UPDATE ... WHERE ...语句在所有索引扫描范围的索引记录上加上排他的next key锁。如果是唯一索引，只需要在相应记录上加index record lock。

当UPDATE 操作修改主键记录的时候，将在相应的二级索引上加上隐式的锁。当进行重复键检测的时候，将会在插入新的二级索引记录之前，在其二级索引上加上一把共享锁。

5、DELETE FROM ... WHERE ... 语句在所有索引扫描范围的索引记录上加上排他的next key锁。如果是唯一索引，只需要在相应记录上加index record lock。

6、INSERT 语句将在插入的记录上加一把排他锁，这个锁是一个index-record lock，并不是next-key 锁，因此就没有gap 锁，他将不会阻止其他会话在该条记录之前的gap插入记录。

> 如何解决脏读

通过排他锁和共享锁完成。事务A加排他锁进行修改，事务结束前不会释放锁。事务B想要读取，要共享锁，但是由于有了排他锁，因此共享锁阻塞。等事务A结束，才能读取得到。

> 既然innodb的可重复读已经解决了幻读问题，那么和串行化的实现区别是什么

可重复读通过next-key锁解决了当前读下的幻读问题。而串行化是通过加表锁来解决的。

# 数据库的锁
锁分为乐观锁和悲观锁。
其中悲观锁按照类型可以划分为：
- 共享锁（读锁）
- 排他锁（写锁）

也可以按照锁的范围分为：
- 行锁
- 表锁

## 乐观锁
假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。

乐观锁是一种不会阻塞其他线程并发的控制，它不会使用数据库的锁进行实现，它的设计里面由于不阻塞其他线程，所以并不会引起线程频繁挂起和恢复，这样便能够提高并发能力，所以也有人把它称为非阻塞锁。
一般的实现乐观锁的方式就是记录数据版本。（数据版本：为数据增加的一个版本标识。）

当读取数据时，将版本标识的值一同读出，数据每更新一次，同时对版本标识进行更新。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的版本标识进行比对，如果数据库表当前版本号与第一次取出来的版本标识值相等，则予以更新，否则认为是过期数据。

实现数据版本有两种方式，第一种是使用版本号，第二种是使用时间戳。

**使用版本号实现乐观锁：**

使用版本号时，可以在数据初始化时指定一个版本号，每次对数据的更新操作都对版本号执行+1操作。并判断当前版本号是不是该数据的最新的版本号。
```sql
1.查询出商品信息
select (status,status,version) from t_goods where id = #{id}
2.根据商品信息生成订单
3.修改商品status为2
update t_goods 
set status = 2,version = version + 1
where id = #{id} and version = #{version};
```

## 悲观锁
假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。

悲观锁是一种利用数据库内部机制提供的锁的方式，也就是对更新的数据加锁，这样在并发期间一旦有一个事务持有了数据库记录的锁，其他的线程将不能再对数据进行更新了，这就是悲观锁的实现方式。

### 行锁
MySQL 5.6 以后Engine db 默认是行锁，当然Engine也支持表锁，mysql InnoDB引擎默认的修改数据语句，update,delete,insert都会自动给涉及到的数据加上排他锁，==**select语句默认不会加任何锁类型**==。但是innodb的RR是对标了sql标准的串行化，需要MVCC和next-key锁。

### 表锁
MySQL  的MyISAM 的默认锁为表锁，当数据库表设置为MyISAM后，操作该数据库都会加表锁，其中 ==**查询数据会加读锁（共享锁），修改、增加、删除数据会加写锁（排他锁）**==

```sql
# 由于InnoDB预设是Row-Level Lock，所以只有「明确」的指定主键，MySQL才会执行Row lock (只锁住被选取的资料例) ，否则MySQL将会执行Table Lock (将整个资料表单给锁住)：
# (明确指定主键，并且有此笔资料，row lock)
SELECT * FROM products WHERE id='3' FOR UPDATE;
SELECT * FROM products WHERE id='3' and type=1 FOR UPDATE;
# (明确指定主键，若查无此笔资料，无lock)
SELECT * FROM products WHERE id='-1' FOR UPDATE;
# (无主键，table lock)
SELECT * FROM products WHERE name='Mouse' FOR UPDATE;
# (主键不明确，table lock)
SELECT * FROM products WHERE id<>'3' FOR UPDATE;
# (主键不明确，table lock)
SELECT * FROM products WHERE id LIKE '3' FOR UPDATE;
```

### 排他锁（写锁）
sql语句：`select ...for update`

如果一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行共享锁和排他锁只有获取到排它锁的事务支持对数据行的修改。

### 共享锁（读锁）
sql语句：`select ... lock in share mode`

共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改。

### 举例

**举例，使用排他锁**
```sql
//0.开始事务
begin;/begin work;/start transaction; (三者选一)
//1.查询出商品信息
select status from t_goods where id = 1 for update;
//2.根据商品信息生成订单
insert into t_orders (id,goods_id) values (null,1);
//3.修改商品status为2
update t_goods set status=2;
//4.提交事务
commit;/commit work;

上面的查询语句中，我们使用了 select…for update 的方式，这样就通过开启排他锁的方式实现了悲观锁。
此时在t_goods表中，id为1的那条数据就被我们锁定了，其它的事务必须等本次事务提交之后才能执行。
这样我们可以保证当前的数据不会被其它事务修改。
```

需要注意，innodb默认的锁级别是行锁

---

部分转载自：https://www.yuque.com/fanzhengxu/tba6b8/dx0hvw#eDkqD

> InnerDB行级锁是基于什么样的机制实现的

共享锁和独占锁。

> InnerDB在什么情况下启动这个行级锁

InnoDB行锁是通过给索引项加锁来实现的，InnoDB这种行级锁决定，只有通过索引条件来检索数据，才能使用行级锁，否则，直接使用表级锁。特别注意:使用行级锁一定要使用索引



# 什么是索引以及索引的分类
## 什么是索引
索引是对数据库表中一个或多个列的值进行**排序**的数据结构，以协助快速查询、更新数据库表中数据。

## 索引的底层结构
底层数据结构是B+树。

在数据结构中，我们最为常见的搜索结构就是二叉搜索树和AVL树(高度平衡的二叉搜索树，为了提高二叉搜索树的效率，减少树的平均搜索长度)了。然而，无论二叉搜索树还是AVL树，当数据量比较大时，都会由于树的深度过大而造成I/O读写过于频繁，进而导致查询效率低下，因此对于索引而言，多叉树结构成为不二选择。特别地，B-Tree的各种操作能使B树保持较低的高度，从而保证高效的查找效率。

## 索引的分类
唯一索引：唯一索引不允许两行具有相同的索引值。

主键索引：为表定义一个主键将自动创建主键索引，主键索引是唯一索引的特殊类型。主键索引要求主键中的每个值是唯一的，并且不能为空。

聚集索引(Clustered)：表中各行的物理顺序与键值的逻辑（索引）顺序相同，每个表只能有一个。**innodb中的b+树就是，将索引和数据保存在同一个b+树中**

非聚集索引(Non-clustered)：非聚集索引指定表的逻辑顺序。数据存储在一个位置，索引存储在另一个位置，索引中包含指向数据存储位置的指针。可以有多个，小于249个。**在innodb中的b+树就是索引和数据不保存在一起**

## 索引的优缺点
（1）优点：
- 大大加快数据的检索速度，这也是创建索引的最主要的原因；
- 加速表和表之间的连接；
- 在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间；
- 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性；

（2）缺点：
- 时间方面：创建索引和维护索引要耗费时间，具体地，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度；
- 空间方面：索引需要占物理空间。

## 什么样的字段适合创建索引
- 经常作查询选择的字段
- 经常作表连接的字段
- 经常出现在order by, group by, distinct后面的字段

## 索引那么好用为什么不每列都加索引

第一，创建索引和维护索引要耗费时间，这种时间随着数据 量的增加而增加。

第二，索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。

第三，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。

> 什么是索引覆盖和回表操作，如何避免回表

比如说你建立了一个A，B联合索引，你的sql语句是 select A，B from table where A=xxx你会发现你想要搜索的A，B从索引数据中已经存在了，压根不用拿到id到表数据中去查找，此时便不会回表，这种现象就叫做索引覆盖。 ==因为A，B就存在了innodb的辅助索引中，直接用就行了，不必根据主键再去主索引的B+树找==

现在你把语句改为了 select A，B，C from table where A=xxx, B=xxx，C毕竟不在索引数据中，拿不到，那只能先拿到id再去主键索引中找，此时就是回表。

避免回表：

用主键搜索
只查询被联合索引覆盖的字段

> 什么是mysql的哈希索引，讲一下缺点

哈希索引只包含哈希值和行指针，而不存储字段值

哈希索引数据并不是按照索引列的值顺序存储的，所以也就无法用于排序

哈希索引也不支持部分索引列匹配查找，因为哈希索引始终是使用索引的全部列值内容来计算哈希值的。如：数据列（a,b）上建立哈希索引，如果只查询数据列a，则无法使用该索引。

哈希索引只支持等值比较查询，如：=,in(),<=>(注意，<>和<=>是不同的操作)，不支持任何范围查询（必须给定具体的where条件值来计算hash值，所以不支持范围查询）

> 什么是mysql缓存，什么时候会失效

查询前会先去缓存看看有没有，没有再去查数据库，并且更新缓存。

缓存建立之后，mysql的查询缓存系统会跟踪查询中涉及的每张表，如果表发生变化，那么和这张表相关的缓存将失效

> b+索引树一般多高，高度怎么计算？

一般来说b+树的高度维持在3左右。logB(N)。B为b+树的阶数，也就是一个节点可以存多少索引。

# 超键、候选键、主键、外键以及sql约束
## 键
### 定义
超键(super key): 在关系中能唯一标识元组的属性集称为关系模式的超键

候选键(candidate key): 不含有多余属性的超键称为候选键。也就是在候选键中，若再删除属性，就不是键了！

主键(primary key): 用户选作元组标识的一个候选键程序主键

外键(foreign key)：如果关系模式R中属性K是其它模式的主键，那么k在模式R中称为外键。

### 举例
学生信息（学号 身份证号 性别 年龄 身高 体重 宿舍号）和 宿舍信息（宿舍号 楼号）

超键：==**只要含有“学号”或者“身份证号”两个属性的集合就叫超键，例如R1（学号 性别）、R2（身份证号 身高）、R3（学号 身份证号）等等都可以称为超键！**==

候选键：==**不含有多余的属性的超键，比如（学号）、（身份证号）都是候选键**==，又比如R1中学号这一个属性就可以唯一标识元组了，而有没有性别这一属性对是否唯一标识元组没有任何的影响！

主键：==**就是用户从很多候选键选出来的一个键就是主键**==，比如你要求学号是主键，那么身份证号就不可以是主键了！

外键：宿舍号就是学生信息表的外键

## 约束
- NOT NULL: 用于控制字段的内容一定不能为空（NULL）。
- UNIQUE: 控制字段内容不能重复，一个表允许有多个 Unique 约束。
- PRIMARY KEY: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个。
- FOREIGN KEY: 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。
- CHECK: 用于控制字段的值范围。

---
转载自：

https://blog.csdn.net/jerry11112/article/details/78160771

https://www.yuque.com/fanzhengxu/tba6b8/dx0hvw#4MqAL


# 查询语句的元素
## view
> 什么是视图？用途

视图是一个虚拟表。如果一个查询结果要被重用很多次，那么就可以把这个查询结果保存为一个视图。下次要重用的时候，直接去这个视图查询即可。
```sql
-- 1.创建视图
create view tb1 as  select * from student where gender='男';
 
-- 使用视图进行查询。
 
select * from tb1 where class_id>1;
```

## union
```sql
SELECT column,... FROM table1  UNION [ALL] SELECT column,... FROM table2 ... 
```
![](https://gitee.com/super-jimwang/img/raw/master/img/20210324091855.png)
查询两张表中的文章 id 号及标题，并去掉重复记录：

`SELECT aid,title FROM article UNION SELECT bid,title FROM blog `
![](https://gitee.com/super-jimwang/img/raw/master/img/20210324091927.png)

- 重复记录是指查询中各个字段完全重复的记录，如上例，若 title 一样但 id 号不一样算作不同记录。
- 第一个 SELECT 语句中被使用的字段名称也被用于结果的字段名称，如上例的 aid。
- 各SELECT 语句字段名称可以不同，但字段属性必须一致。

### union all
`SELECT aid,title FROM article UNION ALL SELECT bid,title FROM blog `
![](https://gitee.com/super-jimwang/img/raw/master/img/20210324092033.png)

- 显然，使用 UNION ALL 的时候，只是单纯的把各个查询组合到一起而不会去判断数据是否重复。因此，当确定查询结果中不会有重复数据或者不需要去掉重复数据的时候，应当使用 UNION ALL 以提高查询效率。

## join

原理：
Nested Loop Join 实际上就是通过驱动表的结果集作为循环基础数据，然后一条一条的通过该结果集中的数据作为过滤条件到下一个表中查询数据，然后合并结果。

### inner join
两张表重合的部分匹配连接到一起
```sql
mysql> use RUNOOB;
Database changed
mysql> SELECT * FROM tcount_tbl;
+---------------+--------------+
| runoob_author | runoob_count |
+---------------+--------------+
| 菜鸟教程  | 10           |
| RUNOOB.COM    | 20           |
| Google        | 22           |
+---------------+--------------+
3 rows in set (0.01 sec)
 
mysql> SELECT * from runoob_tbl;
+-----------+---------------+---------------+-----------------+
| runoob_id | runoob_title  | runoob_author | submission_date |
+-----------+---------------+---------------+-----------------+
| 1         | 学习 PHP    | 菜鸟教程  | 2017-04-12      |
| 2         | 学习 MySQL  | 菜鸟教程  | 2017-04-12      |
| 3         | 学习 Java   | RUNOOB.COM    | 2015-05-01      |
| 4         | 学习 Python | RUNOOB.COM    | 2016-03-06      |
| 5         | 学习 C      | FK            | 2017-04-05      |
+-----------+---------------+---------------+-----------------+
5 rows in set (0.01 sec)

mysql> SELECT a.runoob_id, a.runoob_author, b.runoob_count FROM runoob_tbl a INNER JOIN tcount_tbl b ON a.runoob_author = b.runoob_author;
+-------------+-----------------+----------------+
| a.runoob_id | a.runoob_author | b.runoob_count |
+-------------+-----------------+----------------+
| 1           | 菜鸟教程    | 10             |
| 2           | 菜鸟教程    | 10             |
| 3           | RUNOOB.COM      | 20             |
| 4           | RUNOOB.COM      | 20             |
+-------------+-----------------+----------------+
4 rows in set (0.00 sec)
```
![](https://gitee.com/super-jimwang/img/raw/master/img/20210223163421.png)
### left join
左边表的全部以及和右边表重合的部分

```sql
mysql> SELECT a.runoob_id, a.runoob_author, b.runoob_count FROM runoob_tbl a LEFT JOIN tcount_tbl b ON a.runoob_author = b.runoob_author;
+-------------+-----------------+----------------+
| a.runoob_id | a.runoob_author | b.runoob_count |
+-------------+-----------------+----------------+
| 1           | 菜鸟教程    | 10             |
| 2           | 菜鸟教程    | 10             |
| 3           | RUNOOB.COM      | 20             |
| 4           | RUNOOB.COM      | 20             |
| 5           | FK              | NULL           |
+-------------+-----------------+----------------+
5 rows in set (0.01 sec)
```
![](https://gitee.com/super-jimwang/img/raw/master/img/20210223163522.png)
### right join
右边表的全部以及和左边表重合的部分
```sql
mysql> SELECT a.runoob_id, a.runoob_author, b.runoob_count FROM runoob_tbl a RIGHT JOIN tcount_tbl b ON a.runoob_author = b.runoob_author;
+-------------+-----------------+----------------+
| a.runoob_id | a.runoob_author | b.runoob_count |
+-------------+-----------------+----------------+
| 1           | 菜鸟教程    | 10             |
| 2           | 菜鸟教程    | 10             |
| 3           | RUNOOB.COM      | 20             |
| 4           | RUNOOB.COM      | 20             |
| NULL        | NULL            | 22             |
+-------------+-----------------+----------------+
5 rows in set (0.01 sec)
```
![](https://gitee.com/super-jimwang/img/raw/master/img/20210223163713.png)

## exists 和 in
```sql
#对B查询涉及id，使用索引，故B表效率高，可用大表 -->外小内大

select * from A where exists (select * from B where A.id=B.id);

#对A查询涉及id，使用索引，故A表效率高，可用大表 -->外大内小

select * from A where A.id in (select id from B);
```
**区别**
1、exists是对外表做loop循环，每次loop循环再对内表（子查询）进行查询，那么因为对内表的查询使用的索引（内表效率高，故可用大表），而外表有多大都需要遍历，不可避免（尽量用小表），故内表大的使用exists，可加快效率；
- 以上面为例，也就是A.id一个一个遍历，如果有A.id=B.id的就筛选出来

2、in是把外表和内表做hash连接，先查询内表，再把内表结果与外表匹配，对外表使用索引（外表效率高，可用大表），而内表多大都需要查询，不可避免，故外表大的使用in，可加快效率。
- 先查询B，然后去A中通过索引查询是否有id一致的


## having
having字句可以让我们筛选成组后的各种数据

当用到了聚合函数后，就不能通过where来筛选了，因为表中并没有这样的数据。

举例：
```sql
SELECT region, SUM(population), SUM(area)
FROM bbc
GROUP BY region
HAVING SUM(area)>1000000
```

## 执行顺序
(1) from
(2) on（跟join一起用，用来筛选右表，比如on right.id = 10。那么在join的时候 只有id=10的右表信息会合并过来）
(3) join
(4) where
(5) group by(开始使用select中的别名，后面的语句中都可以使用)
(6) avg,sum....
(7) having
(8) select
(9) distinct
(10) order by

所有的查询语句都是从from开始执行的，在执行过程中，每个步骤都会为下一个步骤生成一个虚拟表，这个虚拟表将作为下一个执行步骤的输入。

> join的时候大小表怎么选。

left join的时候左边小表。因为是遍历左边的表，然后去右边表中找相同的。

而right join的时候，右边为小表。

## 创建索引
两种方式
```sql
CREATE INDEX index_name ON table_name (column_list)
```

```sql
CREATE TABLE t(
   c1 INT PRIMARY KEY,
   c2 INT NOT NULL,
   c3 INT NOT NULL,
   c4 VARCHAR(10),
   INDEX (c2,c3) 
);
```

# 数据库与缓存同步
![](https://gitee.com/super-jimwang/img/raw/master/img/20210331160510.png)

https://blog.csdn.net/qq_33347239/article/details/103895518

# update

这里简单把update针对不同情况的处理方案列举出来：

- 不更新主键
  - 就地更新
  - 删除再插入
- 更新主键
  - 先delete再insert

注意！"删除再插入"和"先delete再insert"是两个不同的概念。
之后会给delete和insert单独写博客，简单介绍一下流程，对于锁问题不在此系列作过多解释，有空会单独开出关于锁问题有关的篇章。

## 就地更新

就地更新的前提：

- 不更新主键。
- 更新前的列和更新后的列所占用的存储空间一样大。

请重点关注"存储空间一样大"
这也是为什么我特地要说col的字段类型是varchar，而不是char和varchar都可以。
关于varchar和char的区别大家可自行百度，在这里不在赘述。
在这里你只需知道char占用的长度和空间都是固定的就可以了。

其实就地更新的流程很好理解，就是我们在前言中所说的流程，直接修改原来的记录值，更新统计信息，不会有更多特别的操作。

但对于：UPDATE demo SET col=‘你好啊’ WHERE id=2;
情况可就不一样了，因为更新前后列占用的存储空间不一样的，也就是下面要讲的"删除再插入"。

## 删除再插入

删除再插入前提：

- 不更新主键。
- 更新前的列和更新后的列所占用的存储空间不同。
  是不是感到有些意外？但事实就是如此。

除此之外，如果你熟悉delete的流程，那你可能会认为这个"删除再插入"是指先经过 delete_mask 的中间状态，然后再被 purge 的回收，之后再是insert流程balabala~的。

但是实际上，此处的"删除再插入"并没有那么复杂，就是简单粗暴的将记录原地删除并回收至垃圾链表，之后再重新插入一条新的记录，并更新统计信息。（此过程也是原子性操作，也就是不会出现删除后查询为空的情况，或者删除后断电导致记录消失的情况）

接下来就是最后一种情况了。

## 先delete再insert

触发这种情况的前提：

- 更新主键

没错，触发这种情况并没有什么很复杂的条件，只要更新主键，就会触发。

比如: UPDATE demo SET id=2 where id=1;

至于delete和insert的简单流程，这里就不细说了，后期会单独开篇章讲（与锁无关，与锁有关的也会单独开篇章）。

那么为什么在更新主键的情况下，就要走一遍delete和insert的流程呢？
给个小提示= =，和聚簇索引的数据保持有序有关~
我相信熟悉MYSQL底层B+数存储结构的小伙伴已经知道答案了。

其实就是为了让主键索引列保持有序。
借用一下小册子中的一张图。

![树结构简图](https://gitee.com/super-jimwang/img/raw/master/img/20210409173802)

其中橙色单元格表示的就是主键，可以看到聚簇索引（二级索引）的数据都是根据主键（索引列）排序的。

回到上面的问题，如果主键更新了，数据只是就地更新或者就地删除再插入，那么整颗索引树可能就废掉了~，因为如果数据是有序的，我们很容易就想到二分查找，而如果数据都变无序了，二分查找就没有意义了。
