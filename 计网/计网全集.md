https://blog.csdn.net/baidu_32045201/article/details/78305586
# 交换机与路由器
## 区别

路由器工作在OSI的第三层（网络层），而交换机在第二层工作（链路层）
![](https://gitee.com/super-jimwang/img/raw/master/img/20210330095126.png)

它们的主要工作如下：
- 路由器：寻址，转发（依靠 ==IP== 地址）
- 交换机：过滤，转发（依靠 ==MAC== 地址）

路由器内有一份路由表，里面有它的寻址信息（就像是一张地图），它收到网络层的数据报后，会根据路由表和选路算法将数据报转发到下一站（可能是路由器、交换机、目的主机）

交换机内有一张MAC表，里面存放着和它相连的所有设备的MAC地址，它会根据收到的数据帧的首部信息内的目的MAC地址在自己的表中查找，如果有就转发，如果没有就放弃

![](https://gitee.com/super-jimwang/img/raw/master/img/20210330095239.png)

通过拓扑图我们应该知道：

每一个路由器与其之下连接的设备，其实构成一个局域网

交换机工作在路由器之下，就是也就是交换机工作在局域网内

交换机用于局域网内网的数据转发

路由器用于连接局域网和外网

举个例子：
- 我们每个人相当于主机，路由器相当于快递员，宿管大爷相当于交换机，学校是一个局域网
快递员根据学校地址（IP）把包裹送到学校，再根据公寓号（子网IP）把快递交给这个公寓的宿管大爷，宿管大爷根据你的名字（MAC）交给你

## 实际网络数据转发的过程

![](https://gitee.com/super-jimwang/img/raw/master/img/20210330095338.png)

你的电脑先在应用层打包一个 HTTP报文，然后在传输层在打包成 TCP报文，然后再根据 DNS 查到的 IP 在网络层打包成 IP数据报，然后在通过链路层打包成以太网数据帧，发送给你的交换机：

![](https://gitee.com/super-jimwang/img/raw/master/img/20210330095351.png)

你的交换机收到后，重新包装数据帧，再发送给你的路由器：

![](https://gitee.com/super-jimwang/img/raw/master/img/20210330095435.png)

==注意，这里的数据帧的目的地和源地址都变了==

你的路由器利用 NAT(Network Address Translation)，将你的主机IP（局域网IP）转换为外网IP，还会修改端口号，对外完全隐藏你的主机，再根据路由表选择一条合适的路径进行转发：

![](https://gitee.com/super-jimwang/img/raw/master/img/20210330095529.png)

在接下来的过程中，==每个节点都只改变 MAC 地址==，然后在网络中一路向着目的地发送,之后都是通过MAC地址进行寻址了。

> 什么是外网ip和内网IP？

公网ip具有世界范围的唯一性，而内网ip只在局域网内部具有唯一性。

在局域网中，每台电脑都可以自己分配自己的IP，但是这个IP只在局域网中有效。而如果你将电脑连接到互联网，你的网络提供商的服务器会为你分配一个IP地址，这个IP地址才是你在外网的IP。两个IP同时存在，一个对内，一个对外。

即互联网，局域网通过一台服务器或是一个路由器对外连接的网络，这个IP地址是惟一的。也就是说内网里所有的计算机都是连接到这一个外网IP上，通过这一个外网IP对外进行交换数据的。==一个外网IP对应了一个路由器的NAT分配方法，路由器可能有多个外部IP可供内网IP映射==

> 讲一下NAT

NAT（Network Address Translation，网络地址转换）不仅能解决IP地址不足的问题，而且还能够有效地避免来自网络外部的攻击，隐藏并保护网络内部的计算机。

NAT的实现方式有三种，即静态转换Static Nat、动态转换Dynamic Nat和端口多路复用OverLoad。
- 静态转换是指将内部网络的私有IP地址转换为公有IP地址，IP地址对是一对一的，是一成不变的，某个私有IP地址只转换为某个公有IP地址。
- 动态转换是指将内部网络的私有IP地址转换为公用IP地址时，IP地址是不确定的，是随机的，所有被授权访问上Internet的私有IP地址可随机转换为任何指定的合法IP地址。
- 端口多路复用（Port address Translation,PAT）是指改变外出数据包的源端口并进行端口转换，即端口地址转换（PAT，Port Address Translation).采用端口多路复用方式。内部网络的所有主机均可共享一个合法外部IP地址实现对Internet的访问，从而可以最大限度地节约IP地址资源。==多台电脑共用一个外网IP，用端口号来进行区分==

# 如何让UDP可靠

> 有哪些办法可以让UDP变得可靠

- 重传机制。在一个RTO时间到达时未收到这个数据包的ACK应答，那么发送端就考虑重传
- 请求重传。接收端在发送 ACK 的时候携带自己丢失报文的信息反馈，发送端接收到 ACK 信息时根据丢包反馈进行报文重传。
- 拥塞控制（让网络尽量不拥塞）
- ACK应答机制
  - 是一个一个回复还是跟TCP一样累计确认？
  - 可以累计确认，通过seq和ack方式

# DNS解析的过程

1. 浏览器先检查自身缓存中有没有被解析过的这个域名对应的ip地址，如果有，解析结束。同时域名被缓存的时间也可通过TTL属性来设置。

2. 如果浏览器缓存中没有（专业点叫还没命中），浏览器会检查操作系统缓存中有没有对应的已解析过的结果。而操作系统也有一个域名解析的过程。在windows中可通过c盘里一个叫hosts的文件来设置，如果你在这里指定了一个域名对应的ip地址，那浏览器会首先使用这个ip地址。

3. 如果至此还没有命中域名，才会真正的请求==**本地域名服务器（LDNS）**==来解析这个域名，这台服务器一般在你的城市的某个角落，距离你不会很远，并且这台服务器的性能都很好，一般都会缓存域名解析结果，大约80%的域名解析到这里就完成了。

4. 如果LDNS仍然没有命中，就直接跳到Root Server 域名服务器请求解析

5. 根域名服务器返回给LDNS一个所查询域的主域名服务器（gTLD Server，国际顶尖域名服务器，如.com .cn .org等）地址

6. 此时LDNS再发送请求给上一步返回的gTLD

7. 接受请求的gTLD查找并返回这个域名对应的Name Server的地址，这个Name Server就是网站注册的域名服务器

8. Name Server根据映射关系表找到目标ip，返回给LDNS

9. LDNS缓存这个域名和对应的ip

10. LDNS把解析的结果返回给用户，用户根据TTL值缓存到本地系统缓存中，域名解析过程至此结束

> ping是基于什么协议的

ICMP协议

# DNS为什么使用UDP，又与TCP又什么关系
## 为什么用UDP
DNS请求数据时，整个数据包除了DNS协议相关的内容之外，还包含以太网、IP和UDP的协议头。虽然包含了这么多信息，但是一个DNS请求只有几十个字节。是非常小的数据包。

UDP 和 TCP 的通信机制非常不同，作为可靠的传输协议，TCP 协议需要通信的双方通过 三次握手 建立 TCP 连接后才可以通信，但是在 30 年前的 DNS 查询的场景中我们其实并不需要稳定的连接（或者以为不需要），每一次 DNS 查询都会直接向命名服务器发送 UDP 数据报，与此同时常见 DNS 查询的数据包都非常小，TCP 建立连接会带来以下的额外开销：

TCP 建立连接需要进行三次网络通信；
TCP 建立连接需要传输 ~130 字节的数据；
TCP 销毁连接需要进行四次网络通信；
TCP 销毁连接需要传输 ~160 字节的数据；

## 跟TCP的关系
今天的网络状况其实没有几十年前设计的那么简单，我们不仅遇到了 IPv4 即将无法分配的状况，而且还需要引入 DNSSEC 等机制来保证 DNS 查询和请求的完整性以及传输安全，总而言之，DNS 协议需要处理的数据包越来越大、数据也越来越多，但是『为什么当需要传输的数据较多时我们就必须使用 TCP 协议呢？』

从理论上来说，一个 UDP 数据包的大小最多可以达到 64KB，这对于一个常见的 DNS 查询其实是一个非常大的数值；但是在实际生产中，一旦数据包中的数据超过了传送链路的最大传输单元（MTU，也就是单个数据包大小的上限，一般为 1500 字节），当前数据包就可能会被分片传输、丢弃，部分的网络设备甚至会直接拒绝处理包含 EDNS(0) 选项的请求，这就会导致使用 UDP 协议的 DNS 不稳定。

TCP 作为可靠的传输协议，可以非常好的解决这个问题，通过序列号、重传等机制能够保证消息的不重不漏，消息接受方的 TCP 栈会对分片的数据重新进行拼装，DNS 等应用层协议可以直接使用处理好的完整数据。同时，当数据包足够大的时候，TCP 三次握手带来的额外开销比例就会越来越小，与整个包的大小相比就会趋近于 0。

## 总结
DNS 查询选择 UDP 或者 TCP 两种不同协议时的主要原因：

- UDP 协议
    - DNS 查询的数据包较小、机制简单；
    - UDP 协议的额外开销小、有着更好的性能表现；
- TCP 协议
  - DNS 查询由于 DNSSEC 和 IPv6 的引入迅速膨胀，导致 DNS 响应经常超过 MTU 造成数据的分片和丢失，我们需要依靠更加可靠的 TCP 协议完成数据的传输；
  - 随着 DNS 查询中包含的数据不断增加，TCP 协议头以及三次握手带来的额外开销比例逐渐降低，不再是占据总传输数据大小的主要部分；


无论是选择 UDP 还是 TCP，最核心的矛盾就在于需要传输的数据包大小，如果数据包小到一定程度，UDP 协议绝对最佳的选择，但是当数据包逐渐增大直到突破 512 字节以及 MTU 1500 字节的限制时，我们也只能选择使用更可靠的 TCP 协议来传输 DNS 查询和相应。

转载自：https://draveness.me/whys-the-design-dns-udp-tcp/

# HTTP缓存机制

## 服务器缓存和客户端缓存
服务端缓存又分为 代理服务器缓存 和 反向代理服务器缓存（也叫网关缓存，比如 Nginx反向代理、Squid等），其实广泛使用的 CDN 也是一种服务端缓存，目的都是让用户的请求走”捷径“，并且都是缓存图片、文件等静态资源。

客户端侧缓存一般指的是浏览器缓存，目的就是加速各种静态资源的访问，想想现在的大型网站，随便一个页面都是一两百个请求，每天 pv 都是亿级别，如果没有缓存，用户体验会急剧下降、同时服务器压力和网络带宽都面临严重的考验。

## 服务器缓存和客户端缓存

服务端缓存又分为 代理服务器缓存 和 反向代理服务器缓存（也叫网关缓存，比如 Nginx反向代理、Squid等），其实广泛使用的 CDN 也是一种服务端缓存，目的都是让用户的请求走”捷径“，并且都是缓存图片、文件等静态资源。

客户端侧缓存一般指的是浏览器缓存，目的就是加速各种静态资源的访问，想想现在的大型网站，随便一个页面都是一两百个请求，每天 pv 都是亿级别，如果没有缓存，用户体验会急剧下降、同时服务器压力和网络带宽都面临严重的考验。

## 缓存机制

有两种缓存机制，**强制缓存**和**对比缓存**

## 强制缓存

对于强制缓存来说，响应header中会有两个字段来标明失效规则（Expires/Cache-Control）

**Expires**
　　Expires的值为服务端返回的到期时间，即下一次请求时，请求时间小于服务端返回的到期时间，直接使用缓存数据。
不过Expires 是HTTP 1.0的东西，现在默认浏览器均默认使用HTTP 1.1，所以它的作用基本忽略。
另一个问题是，到期时间是由服务端生成的，但是客户端时间可能跟服务端时间有误差，这就会导致缓存命中的误差。
所以HTTP 1.1 的版本，使用Cache-Control替代。

**Cache-Control**
Cache-Control 是最重要的规则。常见的取值有private、public、no-cache、max-age，no-store，默认为private。
private:        客户端可以缓存
public:         客户端和代理服务器都可缓存（前端的同学，可以认为public和private是一样的）
max-age=xxx:  缓存的内容将在 xxx 秒后失效
no-cache:      需要使用对比缓存来验证缓存数据（后面介绍）
no-store:       所有内容都不会缓存，强制缓存，对比缓存都不会触发（对于前端开发来说，缓存越多越好，so...基本上和它说886）

## 对比缓存

对比缓存，顾名思义，需要进行比较判断是否可以使用缓存。
浏览器第一次请求数据时，服务器会将缓存标识与数据一起返回给客户端，客户端将二者备份至缓存数据库中。
再次请求数据时，客户端将备份的缓存标识发送给服务器，服务器根据缓存标识进行判断，判断成功后，返回304状态码，通知客户端比较成功，可以使用缓存数据。

**Last-Modified / If-Modified-Since**
**Last-Modified：**
服务器在响应请求时，告诉浏览器资源的最后修改时间。
![img](https://gitee.com/super-jimwang/img/raw/master/img/20210214223329.png)
**If-Modified-Since：**
再次请求服务器时，通过此字段通知服务器上次请求时，服务器返回的资源最后修改时间。
服务器收到请求后发现有头If-Modified-Since 则与被请求资源的最后修改时间进行比对。
若资源的最后修改时间大于If-Modified-Since，说明资源又被改动过，则响应整片资源内容，返回状态码200；
若资源的最后修改时间小于或等于If-Modified-Since，说明资源无新修改，则响应HTTP 304，告知浏览器继续使用所保存的cache。

![img](https://gitee.com/super-jimwang/img/raw/master/img/20210214223355.png)

**Etag / If-None-Match**（优先级高于Last-Modified / If-Modified-Since）
**Etag：**
服务器响应请求时，告诉浏览器当前资源在服务器的唯一标识（生成规则由服务器决定）。

![img](https://gitee.com/super-jimwang/img/raw/master/img/20210214223400.png)
**If-None-Match：**
再次请求服务器时，通过此字段通知服务器客户段缓存数据的唯一标识。
服务器收到请求后发现有头If-None-Match 则与被请求资源的唯一标识进行比对，
不同，说明资源又被改动过，则响应整片资源内容，返回状态码200；
相同，说明资源无新修改，则响应HTTP 304，告知浏览器继续使用所保存的cache。

![img](https://gitee.com/super-jimwang/img/raw/master/img/20210214223403.png)

## 缓存与用户行为的关系

浏览器缓存过程还和用户行为有关。譬如先打开一个主页有个jquery的请求（假设访问后会缓存下来）。

接着如果直接在地址栏输入 jquery 地址，然后回车，响应HTTP200（from cache），因为有效期还没过直接读取的缓存；如果`ctrl+r`进行刷新，则会相应HTTP304（Not Modified），虽然还是读取的本地缓存，但是多了一次服务端的请求；而如果是ctrl+shift+r强刷，则会直接从服务器下载新的文件，响应HTTP200。



==**注意：POST请求无法被缓存**==


## HTTP1.0和HTTP1.1中的缓存处理

在HTTP/1.0协议中，Last-Modified（对比缓存）是控制缓存的一个非常重要的HTTP头。如果需要控制浏览器的缓存，服务器首先必须发送一个 以UTC时间为值的Last-Modifeid头，当第二次访问这个页面时，浏览器会发送一个If-Modified-Since头给服务器，让服务器判 断是否有必要更新内容，这个If-Modified-Since头的值就是上次访问页面时，浏览器发送的Last-Modifeid头的值。

Expires（强制缓存）是HTTP/1.0中另外一个很重要的HTTP头，它表示缓存的存在时间，告诉客户端浏览器在这个时间之前不对服务器发送请求，而直接使用浏览器的缓存。

在HTTP1.1中，通过`cache-control:`来控制缓存策略

# HTTP请求方法与状态码，以及访问网页的过程

## 请求方法

HTTP1.0中定义了三种：GET，POST和HEAD

HTTP1.1中定义了五种：OPTIONS，PUT，DELETE，TRACE和CONNECT

| 方法    | 描述                                                         |
| ------- | ------------------------------------------------------------ |
| GET     | 请求指定的页面信息，并返回实体主体                           |
| HEAD    | 类似于get请求，用于获取报头                                  |
| POST    | 向指定资源提交数据请求处理                                   |
| PUT     | 从客户端向服务端传送的数据取代指定的文档的内容               |
| DELETE  | 删除指定内容                                                 |
| CONNECT | HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。     |
| TRACE   | 回显服务器收到的请求，用于测试和诊断                         |
| OPTIONS | 返回服务器针对特定资源所支持的HTTP请求方法，也可以利用向web服务器发送‘*’的请求来测试服务器的功能性 |



## 状态码

- 100：请求者应当继续提出请求。 服务器返回此代码表示已收到请求的第一部分，正在等待其余部分。
- 200：表示成功正常请求
- 302：redirect，请求转发
- 304：http缓存命中
- 400：语义有误，一般是请求格式不对
- 401：需求用户验证权限，一般是证书token没通过认证
- 403：拒绝提供服务
- 404：资源不存在
- 500：服务器错误
- 503：服务器临时维护，过载；可恢复



## 一次HTTP请求的步骤

1）通过DNS解析域名（应用层） -> 2) HTTP生成对应的请求报文（应用层）-> 3)建立TCP连接三次握手-> 4)TCP协议将HTTP请求报文分割成多个报文段，按序发送 -> 5)IP协议通过搜索IP进行中转和传送 -> 6) 送达目标主机，重组收到的TCP报文 -> 7) 给到应用层，HTTP给出响应， 然后再以TCP回复回去。

![image-20210210164651363](https://gitee.com/super-jimwang/img/raw/master/img/20210210164651.png)

> get请求和post请求分别与服务器交互几次

1次和2次。

有跨域的情况下，post会先发一个option，测试服务器是否可用。

# HTTPS

HTTPS（SSL/TLS）的加密机制虽然是个前端后端等都应了解的基本问题，但网上的很多HTTPS相关文章也总会忽略一些内容，我学习它的时候也废了挺大功夫。
对称加密、非对称加密、数字签名、数字证书等等，在学习过程中，除了了解“它是什么”，你是否有想过“为什么是它”？我认为理解了后者才真正理解了HTTPS的加密机制。


本文以问题的形式逐步展开，一步步解开HTTPS的面纱，希望能帮助你彻底搞懂HTTPS。特别是对于了解过HTTPS却在有些地方有所卡壳的人，希望本文能帮助你理清思路。

## **为什么需要加密？**

因为http的内容是明文传输的，明文数据会经过中间代理服务器、路由器、wifi热点、通信服务运营商等多个物理节点，如果信息在传输过程中被劫持，传输的内容就完全暴露了，他还可以篡改传输的信息且不被双方察觉，这就是`中间人攻击`。所以我们才需要对信息进行加密。最简单容易理解的就是`对称加密` 。

## **什么是对称加密？**

就是有一个密钥，它可以对一段内容加密，加密后只能用它才能解密看到原本的内容，和我们日常生活中用的钥匙作用差不多。

## **用对称加密可行吗？**

**如果通信双方都各自持有同一个密钥，且没有别人知道，这两方的通信安全当然是可以被保证的（除非密钥被破解）。**
然而最大的问题就是**这个密钥怎么让传输的双方知晓，同时不被别人知道**。如果由服务器生成一个密钥并传输给浏览器，那这个传输过程中密钥被别人劫持弄到手了怎么办？之后他就能用密钥解开双方传输的任何内容了，所以这么做当然不行。
换种思路？试想一下，如果浏览器内部就预存了网站A的密钥，且可以确保除了浏览器和网站A，不会有任何外人知道该密钥，那理论上用对称加密是可以的，这样浏览器只要预存好世界上所有HTTPS网站的密钥就行啦！这么做显然不现实。
怎么办？所以我们就需要神奇的`非对称加密`

## **什么是非对称加密？**

有两把密钥，通常一把叫做公钥、一把叫做私钥，用公钥加密的内容必须用私钥才能解开，同样，私钥加密的内容只有公钥能解开。
用非对称加密可行吗？
鉴于非对称加密的机制，我们可能会有这种思路：服务器先把公钥直接明文传输给浏览器，之后浏览器向服务器传数据前都先用这个公钥加密好再传，这条数据的安全似乎可以保障了！**因为只有服务器有相应的私钥能解开这条数据**。
然而**由服务器到浏览器的这条路怎么保障安全？**如果服务器用它的的私钥加密数据传给浏览器，那么浏览器用公钥可以解密它，而这个公钥是一开始通过明文传输给浏览器的，这个公钥被谁劫持到的话，他也能用该公钥解密服务器传来的信息了。所以**目前似乎只能保证由浏览器向服务器传输数据时的安全性**（其实仍有漏洞，下文会说），那利用这点你能想到什么解决方案吗？

## **改良的非对称加密方案，似乎可以？**

我们已经理解通过一组公钥私钥，已经可以保证单个方向传输的安全性，那用两组公钥私钥，是不是就能保证双向传输都安全了？请看下面的过程：

1. 某网站拥有用于非对称加密的公钥A、私钥A’；浏览器拥有用于非对称加密的公钥B、私钥B’。
2. 浏览器像网站服务器请求，服务器把公钥A明文给传输浏览器。
3. 浏览器把公钥B明文传输给服务器。
4. 之后浏览器向服务器传输的所有东西都用公钥A加密，服务器收到后用私钥A’解密。由于只有服务器拥有这个私钥A’可以解密，所以能保证这条数据的安全。
5. 服务器向浏览器传输的所有东西都用公钥B加密，浏览器收到后用私钥B’解密。同上也可以保证这条数据的安全。

的确可以！抛开这里面仍有的漏洞不谈（下文会讲），HTTPS的加密却没使用这种方案，为什么？最主要的原因是非对称加密算法非常耗时，特别是加密解密一些较大数据的时候有些力不从心，而对称加密快很多，看来必须得用对称加密，那我们能不能运用非对称加密的特性解决前面提到的对称加密的问题？

## **非对称加密+对称加密？**

既然非对称加密耗时，非对称加密+对称加密结合可以吗？而且得尽量减少非对称加密的次数。当然是可以的，而且非对称加密、解密各只需用一次即可。
请看一下这个过程：

1. 某网站拥有用于非对称加密的公钥A、私钥A’。
2. 浏览器像网站服务器请求，服务器把公钥A明文给传输浏览器。
3. 浏览器随机生成一个用于对称加密的密钥X，用公钥A加密后传给服务器。
4. 服务器拿到后用私钥A’解密得到密钥X。
5. 这样双方就都拥有密钥X了，且别人无法知道它。之后双方所有数据都用密钥X加密解密。

完美！HTTPS基本就是采用了这种方案。完美？还是有漏洞的。

## **中间人攻击**

中间人的确无法得到浏览器生成的密钥B，这个密钥本身被公钥A加密了，只有服务器才有私钥A’解开拿到它呀！然而中间人却完全不需要拿到密钥A’就能干坏事了。请看：

1. 某网站拥有用于非对称加密的公钥A、私钥A’。
2. 浏览器向网站服务器请求，服务器把公钥A明文给传输浏览器。
3. **中间人劫持到公钥A，保存下来，把数据包中的公钥A替换成自己伪造的公钥B（它当然也拥有公钥B对应的私钥B’）**。
4. 浏览器随机生成一个用于对称加密的密钥X，用**公钥B**（浏览器不知道公钥被替换了）加密后传给服务器。
5. **中间人劫持后用私钥B’解密得到密钥X，再用公钥A加密后传给服务器**。
6. 服务器拿到后用私钥A’解密得到密钥X。

这样在双方都不会发现异常的情况下，中间人得到了密钥B。**根本原因是浏览器无法确认自己收到的公钥是不是网站自己的**。那么下一步就是解决下面这个问题：

## **如何证明浏览器收到的公钥一定是该网站的公钥？**

现实生活中，如果想证明某身份证号一定是小明的，怎么办？看身份证。这里政府机构起到了“公信”的作用，身份证是由它颁发的，它本身的权威可以对一个人的身份信息作出证明。互联网中能不能搞这么个公信机构呢？给网站颁发一个“身份证”？

## **数字证书**

网站在使用HTTPS前，需要向“**CA机构**”申请颁发一份**数字证书**，数字证书里有证书持有者、证书持有者的公钥等信息，服务器把证书传输给浏览器，浏览器从证书里取公钥就行了，证书就如身份证一样，可以证明“该公钥对应该网站”。然而这里又有一个显而易见的问题了，证书本身的传输过程中，如何防止被篡改？即如何证明证书本身的真实性？身份证有一些防伪技术，数字证书怎么防伪呢？解决这个问题我们就基本接近胜利了！

## **如何放防止数字证书被篡改？**

我们把证书内容生成一份“签名”，比对证书内容和签名是否一致就能察觉是否被篡改。这种技术就叫`数字签名`：

## **数字签名**

这部分内容建议看下图并结合后面的文字理解，图中左侧是数字签名的制作过程，右侧是验证过程（原图出处找不到了，可以看出来这图已经被转载了无数次了。。。）

![img](https://gitee.com/super-jimwang/img/raw/master/img/20210213215702.jpg)


数字签名的制作过程：

1. CA拥有非对称加密的私钥和公钥。
2. CA对证书明文信息进行hash。
3. 对hash后的值用私钥加密，得到数字签名。

明文和数字签名共同组成了数字证书，这样一份数字证书就可以颁发给网站了。
那浏览器拿到服务器传来的数字证书后，如何验证它是不是真的？（有没有被篡改、掉包）

浏览器验证过程：

1. 拿到证书，得到明文T，数字签名S。
2. 用CA机构的公钥对S解密（由于是浏览器信任的机构，所以浏览器保有它的公钥。详情见下文），得到S’。
3. 用证书里说明的hash算法对明文T进行hash得到T’。
4. 比较S’是否等于T’，等于则表明证书可信。

为什么这样可以证明证书可信呢？我们来仔细想一下。

## **中间人有可能篡改该证书吗？**

假设中间人篡改了证书的原文，由于他没有CA机构的私钥，所以无法得到此时加密后签名，无法相应地篡改签名。浏览器收到该证书后会发现原文和签名解密后的值不一致，则说明证书已被篡改，证书不可信，从而终止向服务器传输信息，防止信息泄露给中间人。
既然不可能篡改，那整个证书被掉包呢？

## **中间人有可能把证书掉包吗？**

假设有另一个网站B也拿到了CA机构认证的证书，它想搞垮网站A，想劫持网站A的信息。于是它成为中间人拦截到了A传给浏览器的证书，然后替换成自己的证书，传给浏览器，之后浏览器就会错误地拿到B的证书里的公钥了，会导致上文提到的漏洞。
其实这并不会发生，因为证书里包含了网站A的信息，包括域名，浏览器把证书里的域名与自己请求的域名比对一下就知道有没有被掉包了。

## **为什么制作数字签名时需要hash一次？**

我初学HTTPS的时候就有这个问题，似乎以上过程中hash有点多余，把hash过程去掉也能保证证书没有被篡改。
最显然的是性能问题，前面我们已经说了非对称加密效率较差，证书信息一般较长，比较耗时。而hash后得到的是固定长度的信息（比如用md5算法hash后可以得到固定的128位的值），这样加密解密就会快很多。
当然还有安全上的原因，这部分内容相对深一些，感兴趣的可以看这篇解答：[crypto.stackexchange.com/a/12780](https://link.zhihu.com/?target=https%3A//link.juejin.im/%3Ftarget%3Dhttps%3A%2F%2Fcrypto.stackexchange.com%2Fa%2F12780)

## **怎么证明CA机构的公钥是可信的？**

你们可能会发现上文中说到CA机构的公钥，我几乎一笔带过，“浏览器保有它的公钥”，这是个什么保有法？怎么证明这个公钥是否可信？
让我们回想一下数字证书到底是干啥的？没错，为了证明某公钥是可信的，即“该公钥是否对应该网站/机构等”，那这个CA机构的公钥是不是也可以用数字证书来证明？没错，操作系统、浏览器本身会预装一些它们信任的根证书，如果其中有该CA机构的根证书，那就可以拿到它对应的可信公钥了。
实际上证书之间的认证也可以不止一层，可以A信任B，B信任C，以此类推，我们把它叫做`信任链`或`数字证书链`，也就是一连串的数字证书，由根证书为起点，透过层层信任，使终端实体证书的持有者可以获得转授的信任，以证明身份。
另外，不知你们是否遇到过网站访问不了、提示要安装证书的情况？这里安装的就是跟证书。说明浏览器不认给这个网站颁发证书的机构，那么没有该机构的根证书，你就得手动下载安装（风险自己承担XD）。安装该机构的根证书后，你就有了它的公钥，就可以用它验证服务器发来的证书是否可信了。

## **HTTPS必须在每次请求中都要先在SSL/TLS层进行握手传输密钥吗？**

这也是我当时的困惑之一，显然每次请求都经历一次密钥传输过程非常耗时，那怎么达到只传输一次呢？用session就行。
服务器会为每个浏览器（或客户端软件）维护一个session ID，在TSL握手阶段传给浏览器，浏览器生成好密钥传给服务器后，服务器会把该密钥存到相应的session ID下，之后浏览器每次请求都会携带session ID，服务器会根据session ID找到相应的密钥并进行解密加密操作，这样就不必要每次重新制作、传输密钥了！



## 握手过程

握手过程的简单描述如下：



1. 客户端->服务端：先给服务端发送一个消息，消息内容包括：客户端支持的加密方式，支持的Hash计算方法，SSL的版本号，客户端生成的**随机数1**等；
2. 服务端->客户端：服务端接收到消息后，选择 **加密方式和hash方法**，服务端生成的**随机数2**，服务端的SSL版本号等信息，将这些发送给客户端；
3. 服务端->客户端：给客户端发送一个Certificate报文，报文中包含服务端的**公钥证书**；证书里面包含了网站地址，加密公钥，以及证书的颁发机构等信息；
4. 紧接着服务端给客户端发送Server Hello Done, 表示最初的协商握手过程结束；
5. 客户端：获得网站证书并收到Done消息后，**验证证书的合法性**（颁发证书的机构是否合法，证书中包含的网站地址是否与正在访问的地址一致等），后面详细讲。如果证书受信任，则浏览器栏里面会显示一个小锁头；否则会给出证书不受信的提示，用户可以选择接受信任该证书。
6. 客户端：**生成预主密钥（Premaster secret）****，**使用约定好的Hash()计算前面交互过程的hash值，`Hash(步骤1+步骤2)=hash1`**，**最后将hash1和**用公钥证书加密的预主密钥（重点，保证随机密码不被泄露的关键）**发给服务端。
7. 服务端：收到hash1和加密后的**预主密钥**。验证`hash1 == Hash(步骤1+步骤2)`**；**验证成功，用私钥解密出**预主密钥**，用特殊算法PRF函数把 **PRF(随机数1+随机数2+预主密钥)** 生成 **会话秘钥（Session Key用作以后数据交互的对称加密key）****。**使用约定好的Hash()计算前面交互过程的hash值，`Hash(步骤1+步骤2+步骤6)=hash2`，发送hash2，使用随机密码加密一段握手消息，然后把 hash2+握手消息 发送给服客户端（存在）。
8. 客户端：收到hash2。验证`hash2 == Hash(步骤1+步骤2+步骤6)`**；**验证成功，也用PRF函数 计算会话秘钥。使用随机密码解密握手消息（存在）。
9. 此时握手过程结束，之后所有的通信数据将由之前 生成的会话秘钥利用对称加密算法进行加密。



简单的说法：

1. https是基于tcp协议的，客户端先会和服务端发起链接建立

2. 接着服务端会把它的证书返回给客户端，证书里面包括非对成加密密钥公钥S.pub、颁发机构和有效期等信息

3. 拿到的证书可以通过浏览器内置的根证书（内含C.pub）验证其合法性

4. 客户端生成随机的对称加密秘钥Z，通过服务端的公钥S.pub加密这个对称加密密钥Z，然后发给服务端

5. 之后，客户端和服务端通过对称秘钥Z加密数据来进行http通信

所以这里同时用到了对成加密密钥和非对成加密密钥。

-----------

==**重要**==

服务端给出了非对称的公钥S.pub，然后客户端用这个公钥S.pub加密对称密钥C.key成了S.pub(C.key)，所以即使中间被攻击了，黑客也无法破解，因为这个只能由服务端的非对称密钥S.pri来解密。

所以，服务端和客户都这样都能由对成加密密钥了，第三方无法知道。

而CA证书是用来防止第一步，服务端给出公钥S.pub时，被攻击。如果黑客在这里攻击，把公钥替换成自己的，那么他也就能通过自己的密钥来解密客户端给出的对称密钥了。所以为了防止第一步的公钥被替换，服务器需要同时给出证书。CA则会使用私钥CA.pri对服务器发来的公钥S.pub进行加密CA.pri(S.pub)。==如何防，因为CA的公钥黑客也是有的，那么如果它破解了，然后把内容改成自己的，但是它没有CA的密钥，因此无法重新加密回去，发送给客户端无法通过CA的检验==

CA的公钥是浏览器内置的，称为根证书。客户端接收到之后，先通过浏览器的根证书进行解密，验证合法性CA.pub(CA.pri(S.pub))。就算中间有人攻击了，解码了，但是由于没有私钥，不能重新加密发回去，所以还是无法攻击的。

认证完CA无误后，才会使用服务端的公钥对对称加密密钥进行加密S.pub(C.key)，然后发回去给服务端。

之后两个人的通信都用C.key来加密解密了，这是一个对称加密。

> htttps链接过程

使用HTTPS是需要保证服务端配置正确了对应的安全证书
1. Client Hello 客户端发起HTTPS请求
- TLS层协议包含了一个客户端生成的随机数 Random1，客户端支持的加密套件（Support Ciphers）和 SSL Version （客户端可用的版本号）等信息
2. Server Hello 服务端向客户端发送 Server Hello 消息，这个消息会从 Client Hello 传过来的 Support Ciphers 里确定一份加密套件，这个套件决定了后续加密和生成摘要时具体使用哪些算法，另外还会生成一份随机数 Random2。
- 注意，至此客户端和服务端都拥有了两个随机数（Random1+ Random2），这两个随机数会在后续生成对称秘钥时用到。
3. Certificate 服务端返回公钥和CA证书（数字证书）到客户端
- 该证书通常有两个目的：1. 身份验证；2. 证书中包含服务器的公钥，该公钥结合密码套件的密钥协商算法协商出预备主密钥
4. Server Key Exchange 该消息是有条件才发，例如，如果是DH算法，这里发送服务器使用的DH参数。RSA算法不需要这一步。它发送的条件是，如果证书包含的信息不足以进行密钥交换，那么必须发送该信息。
5. Server Hello Done ，服务器发送完上述信息之后，会立刻发送该信息，然后等到客户端的响应。该信息的主要作用有：
- 服务端发送了足够的信息，接下来可以和客户端一起协商出预备主密钥
- 客户端接收到该信息后，可以进行证书校验、协商密钥等步骤
6. Certificate Verify，客户端解析证书，客户端接收后会验证证书的安全性，验证通过后取出证书中的服务端公钥，再生成一个随机数 Random3，再用服务端公钥非对称加密 Random3 生成 PreMaster Key
7. Client Key Exchange ，上面客户端根据服务器传来的公钥生成了 PreMaster Key，Client Key Exchange 就是将这个 key 传给服务端，服务端再用自己的私钥解出这个 PreMaster Key 得到客户端生成的 Random3。至此，客户端和服务端都拥有 Random1 + Random2 + Random3，两边再根据同样的算法就可以生成一份秘钥，握手结束后的应用层数据都是使用这个秘钥进行对称加密。
- Q：为什么要使用三个随机数呢？
- 这是因为 SSL/TLS 握手过程的数据都是明文传输的，并且多个随机数种子来生成秘钥不容易被暴力破解出来。
8. Change Cipher Spec(Client)，这一步是客户端通知服务端后面再发送的消息都会使用前面协商出来的秘钥加密了
该信息用于告诉对方，我已经计算好需要使用的对称密钥了，我们接下来的通信都需要使用该密钥进行加密之后再发送。
需要注意的是，发送该信息的一方并不知道对方是否已经计算出密钥。一般由客户端先行发送该信息
9. Finished 该信息是第一个由TLS记录层协议进行加密保护的信息，双方需要验证对方发送的Finished信息，保证协商的密钥是可用的，保证协商过程中，没有被篡改。验证该verify Data的内容，包括三部分的内容：
- 主密钥
- 标签，客户端的标签是client finished，服务端的标签是server finished
- handshake_messages，包括了所有的握手协议信息
10. SSL加密建立

# OSI七层协议、TCP/IP四层协议

| OSI七层网络模型         | TCP/IP四层概念模型 | 对应网络协议                                     |
| ----------------------- | ------------------ | ------------------------------------------------ |
| 应用层（Application）   | 应用层             | ==HTTP==、TFTP, ==FTP==, NFS, WAIS、SMTP         |
| 表示层（Presentation）  | 应用层             | Telnet, Rlogin, SNMP, Gopher                     |
| 会话层（Session）       | 应用层             | SMTP, ==DNS==                                    |
| 传输层（Transport）     | 传输层             | ==TCP, UDP==                                     |
| 网络层（Network）       | 网络层             | ==IP==, ICMP, RARP, AKP, UUCP                    |
| 数据链路层（Data Link） | 数据链路层         | FDDI, Ethernet, Arpanet, PDN, SLIP, PPP，==ARP== |
| 物理层（Physical）      | 数据链路层         | IEEE 802.1A, IEEE 802.2到IEEE 802.11             |

## OSI七层协议各层的作用

- 物理层
  - 定义物理设备标准，如网线的接口类型、光纤的接口类型、传输介质的传输率等
  - 在这一层数据单位是比特
- 数据链路层
  - 建立相邻节点之间的数据链路。该层的作用包括：物理地址寻址、数据的成帧、流量控制、数据的检错、重发等。
  - 在这一层数据单位是帧
- 网络层
  - 在 计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是选择合适的网间路由和交换结点， 确保数据及时传送。
  - ==**将数据链路层提供的帧组成数据包，包中封装有网络层包头，其中含有逻辑地址信息- -源站点和目的站点地址的网络地址**==
  - ==**IP是第3层问题的一部分，此外还有一些路由协议和地 址解析协议（ARP）。有关路由的一切事情都在这第3层处理。地址解析和路由是3层的重要目的。**==
  - 在这一层数据单位为数据包
- 传输层
  - 负责获取所有信息，为上层提供端到端的透明、可靠的数据传输服务
  - 这一层的数据单位也叫数据包，但是如果谈论TCP时，又称数据为段，在UDP时，又称为数据报
- 会话层
  - 通过传输层建立数据传输的通路，在系统之间发起会话
  - 从这层开始，数据统称为报文
- 表示层
  - 将欲交换的数据从适合于某一用户的抽象语法，转换为适合于OSI系统内部使用的传送语法
- 应用层
  - 为操作系统提供访问网络服务的接口



## TCP/IP协议

TPC/IP协议共有四层：应用层、传输层、网络层、数据链路层。

每一层都会在首部加上信息。而在接收方会拆包。

![image-20210208213636503](https://gitee.com/super-jimwang/img/raw/master/img/20210208213636.png)

- 数据链路层
  - 实现网卡接口的网络驱动，以处理数据在以太网等物理媒介上的传输
  - 协议：ARP和RARP地址解析协议。实现了IP地址和物理地址（MAC地址）之间的转换。也就是查IP-MAC地址映射表，当查不到的时候，就发送ARP协议广播报，如果收到广播报的就是这个ip，则会返回自己的mac地址。
- 网络层
  - 网络有局域网LAN和广域网WAN。后者通常需要使用众多分级的路由器连接分散的主机或者LAN，即通信的两台主机不是直接链接的，需要通过多个路由器才能抵达
  - 协议：
    - IP协议，根据数据包的目的IP地址来决定如何投递数据包，如果不能直接给目标主机，则选择一个合适的下一跳路由器
    - ICMP协议：是IP协议的补充，用于检测网络的连接状态。因为IP协议是不可靠的，不保证数据被送达。当传送IP数据包发生错误，比如不可达等，ICMP协议就会把错误信息封包，传送给主机
- 传输层
  - 提供程序间的通信。功能包括：格式化数据流、提供可靠传输。
  - 协议：
    - TCP，可靠的、面对连接的、基于流的服务。
    - UDP，不可靠的、无连接的基于数据报的服务
- 应用层
  - 向用户提供应用

### TCP和UDP的区别

|          | **TCP**                                          | **UDP**                        |
| -------- | ------------------------------------------------ | ------------------------------ |
| 可靠性   | 可靠                                             | 不可靠                         |
| 连接性   | 面向连接                                         | 无连接                         |
| 报文     | 面向字节流                                       | 面向报文                       |
| 效率     | 传输效率低                                       | 传输效率高                     |
| 双工性   | 全双工                                           | 一对一、一对多、多对一、多对多 |
| 流量控制 | 滑动窗口                                         | 无                             |
| 拥塞控制 | 慢开始、拥塞避免、快重传、快恢复                 | 无                             |
| 传输速度 | 慢                                               | 快                             |
| 应用场景 | 对效率要求低，对准确性要求高或者要求有连接的场景 | 对效率要求高，对准确率要求低   |

```
1、TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接
2、TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付

3、TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流;UDP是面向报文的

UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）

4、每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信

5、TCP首部开销20字节;UDP的首部开销小，只有8个字节
6、TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道
```

浏览网页使用的是TCP协议

> 数据链路层的最大包长、ip协议的最大包长、tcp协议的最大包长和udp协议的最大包长

在链路层，由以太网的物理特性决定了数据帧的长度为(46＋18)－(1500＋18)，其中的18是数据帧的头和尾，也就是说数据帧的内容最大为1500(不包括帧头和帧尾)，即MTU(Maximum Transmission Unit)为1500； 

在网络层，因为IP包的首部要占用20字节，所以这的MTU为1500－20＝1480；　

在传输层，对于UDP包的首部要占用8字节，所以这的MTU为1480－8＝1472；

TCP的最大包长为1480-20=1460

数据帧头部14，尾部4，ip协议头部20，udp头部8，tcp头部20

> 数据帧的格式

目的mac地址6 + 源mac地址6 + 类型2（IP，ARP，RARP） + 数据（46～1500） + CRC校验4

> IP协议的格式

总共20字节头部，26-1480的数据
版本1 + 首部长度1 + 服务类型1+ 总长度2 + 标示2（是否分片，后面还有几片） + 标示和片偏移2 + 生存时间TTL1（剩余转发次数，为0丢弃） +  协议类型1（ICMP，UDP，TCP等） + 头部校验和2 + 源IP地址4 + 目标IP地址4

> UDP头部为什么记录长度数据

冗余，其实ip协议头部也记录了长度

# session和cookie

## Cookie

**给客户端们颁发一个通行证吧，每人一个，无论谁访问都必须携带自己通行证。这样服务器就能从通行证上确认客户身份了。这就是Cookie的工作原理**。

客户端请求服务器，如果服务器需要记录该用户状态，就使用response向客户端浏览器颁发一个Cookie。客户端浏览器会把Cookie保存起来。当浏览器再请求该网站时，浏览器把请求的网址连同该Cookie一同提交给服务器。服务器检查该Cookie，以此来辨认用户状态。服务器还可以根据需要修改Cookie的内容。

==**cookie具有不可跨域名性**==Google只会携带Google的Cookie，并不会携带Baidu的，也不能操作Baidu的Cookie。

**如果不设置有效期，默认关闭窗口，cookie消失**

### 跨域

正常情况下，同一个一级域名下的两个二级域名如www.helloweenvsfei.com和images.helloweenvsfei.com也不能交互使用Cookie，因为二者的域名并不严格相同。如果想所有helloweenvsfei.com名下的二级域名都可以使用该Cookie，需要设置Cookie的domain参数，例如：

```
Cookie cookie = new Cookie("time","20080808"); // 新建Cookie
cookie.setDomain(".helloweenvsfei.com");           // 设置域名
cookie.setPath("/");                              // 设置路径
cookie.setMaxAge(Integer.MAX_VALUE);               // 设置有效期
response.addCookie(cookie);                       // 输出到客户端
```

## Session

客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上。这就是Session。客户端浏览器再次访问时只需要从该Session中查找该客户的状态就可以了。

==**Session是存在内存中的**==

由于会有越来越多的用户访问服务器，因此Session也会越来越多。**为防止内存溢出，服务器会把长时间内没有活跃的Session从内存删除。这个时间就是Session的超时时间。如果超过了超时时间没访问过服务器，Session就自动失效了。**

虽然Session保存在服务器，对客户端是透明的，它的正常运行仍然需要客户端浏览器的支持。这是因为Session需要使用Cookie作为识别标志。HTTP协议是无状态的，Session不能依据HTTP连接来判断是否为同一客户，因此服务器向客户端浏览器发送一个名为JSESSIONID的Cookie，它的值为该Session的id（也就是HttpSession.getId()的返回值）。Session依据该Cookie来识别是否为同一用户。

## 不同

1）存储位置不同，cookie是保存在客户端的数据；session的数据存放在服务器上

2）存储容量不同，单个cookie保存的数据小，一个站点最多保存20个Cookie；对于session来说并没有上限

3）存储方式不同，cookie中只能保管ASCII字符串；session中能够存储任何类型的数据

4）隐私策略不同，cookie对客户端是可见的；session存储在服务器上，对客户端是透明对

5）有效期上不同，cookie可以长期有效存在；session依赖于名为JSESSIONID的cookie，过期时间默认为-1，只需关闭窗口该session就会失效

不清楚：6）跨域支持上不同，cookie支持跨域名访问；session不支持跨域名访问

## 禁用cookie了怎么办

1）URL重写，就是把sessionId直接附加在URL路径的后面。

2）表单隐藏字段。就是服务器会自动修改表单，添加一个隐藏字段，以便在表单提交时能够把session id传递回服务器。

# TCP 

![](https://gitee.com/super-jimwang/img/raw/master/img/20210315155434.png)
seq只是个序号 指我这个包的第一个字节是几号

ack是我希望下一个包的第一个字节是几号

==上图中，726丢包，服务端一直想要726的数据，每次都回复ack=726，表示希望要726.==

注意：
客户端：seq=726, ack=1449
服务端: seq=1449, ack=726
客户端: seq=726, ack=2897

==表明：客户端发给服务端的丢表了，服务端一直想要726开始的数据，而服务端给客户端发的没有丢包，客户端想要从1449开始的，服务端就给1449开始的。2897-1449这个长度就是服务端一次发送的数据长度。==

seq是数据包本身的序列号；ack是期望对方继续发送的那个数据包的序列号。

> TCP的头部

![](https://gitee.com/super-jimwang/img/raw/master/img/20210315212127.png)

> udp的头部

![](https://gitee.com/super-jimwang/img/raw/master/img/20210319212616.png)

> 为什么tcp头部没有长度，而udp有

因为tcp面向数据流，有一个窗口大小和序列号，所以不需要长度。而udp头部的长度其实是可以通过ip协议的头部长度信息计算获得的，这里属于冗余信息，主要为了凑齐32位。

> TCP的有序性标识是什么

==序号：包编号能解决乱序问题，表明先后顺序。也就是seq==
==确认序号：发出去的包应该有确认，如果没有收到就应该重新发送，直到送达。ack==

> TCP头部的紧急指针什么用

URG表明有紧急信息

然后通过这个可以计算出紧急字节号：
紧急数据字节号(urgSeq)=TCP报文序号(seq)+紧急指针(urgpoint)−1

# TCP流量控制和拥塞控制

## 什么是拥塞控制和流量控制

流量控制：==**如果发送方把数据发送得过快，接收方可能会来不及接收，这就会造成数据的丢失。**==

TCP的流量控制是利用滑动窗口机制实现的，接收方在返回的数据中会包含自己的接收窗口的大小，以控制发送方的数据发送。

拥塞控制：==**拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。**==

两者的区别：==**流量控制是为了预防拥塞**==。如：在马路上行车，交警跟红绿灯是流量控制，==**当发生拥塞时，如何进行疏散，是拥塞控制**==

## 拥塞控制

### 方式一：慢启动和拥塞避免

1）慢启动，TCP发送端会维护一个拥塞窗口（congestionwindow）==是发送端的滑动窗口，限制了发送端可以发送的数据量==,简称为cwnd。拥塞窗口初始为1个报文段，每经过一次RTT（数据完全发送完到确认的时间），窗口大小翻倍（指数增长，只是前期慢）

- RTT(Round-Trip Time)：往返时延。是指数据从网络一端传到另一端所需的时间。通常，时延由发送时延、传播时延、排队时延、处理时延四个部分组成。

2）拥塞避免，它思路是让拥塞窗口cwnd缓慢增大，发送方的cwnd达到阀值ssthresh(初始值由系统决定的)之后，每经过一个RTT就把拥塞窗口加一，而不是加倍（收到两个或四个确认，都是cwnd+1），cwnd呈线性增加（加法增大）

==**如果遇到网络拥塞，拥塞窗口阀值ssthresh变为网络拥挤时cwnd的一半，cwnd设置为1，重新进入慢启动阶段**==

![image-20210210151606186](https://gitee.com/super-jimwang/img/raw/master/img/20210210151606.png)

### 方式二：快重传和快恢复

1）快重传是当接收方收到了一个失序的报文，则立马报告给发送方，赶紧重传。假如接收方M1收到了，M2没有收到，之后的M3、M4、M5又发送了，此时接收方一共连续给发送方反馈了3个M1确认报文。==**那么快重传规定，发送方只要连续收到3个重复确认，立即重传对方发来的M2（重复确认报文的后一个报文）**==

![image-20210210152010845](https://gitee.com/super-jimwang/img/raw/master/img/20210210152010.png)



2）快恢复：当发送方连续收到三个重复确认，ssthresh减为当前cwnd的一半；由于发送方可能认为网络现在没有拥塞，因此与慢启动不同，把cwnd值设置为ssthresh减半之后的值，然后执行拥塞避免算法，cwnd线性增大

![image-20210210152058896](https://gitee.com/super-jimwang/img/raw/master/img/20210210152058.png)

## 流量控制

### 滑动窗口

发送窗口中有四个概念：：已发送并收到确认的数据（不在发送窗口和发送缓冲区之内）、已发送但未收到确认的数据（位于发送窗口之内）、允许发送但尚未发送的数据（位于发送窗口之内）、发送窗口之外的缓冲区内暂时不允许发送的数据。

接收窗口中也有四个概念：已发送确认并交付主机的数据（不在接收窗口和接收缓冲区之内）、未按序收到的数据（位于接收窗口之内）、允许的数据（位于接收窗口之内）、不允许接收的数据（位于发送窗口之内）。

![image-20210210161026238](https://gitee.com/super-jimwang/img/raw/master/img/20210210161026.png)



#### 滑动窗口做流量控制用

- 接收端将自己可以接收的缓冲区大小放入TCP首部中的“窗口大小”字段，通过ACK报文来通知发送端，滑动窗口是接收端用来控制发送端发送数据的大小，从而达到流量控制
- 其实发送方的窗口上限，是取值拥塞窗口和滑动窗口两者的最小值

![image-20210210152602749](https://gitee.com/super-jimwang/img/raw/master/img/20210210152602.png)

## 滑动窗口和拥塞窗口的相同与不同

相同点

- 都是控制丢包现象，实现机制都是让发送方发得慢一点

不同点在于控制的对象不同

- 流量控制的对象是接收方，怕发送方发的太快，使得接收方来不及处理。==滑动窗口在接受方==
- 拥塞控制的对象是网络，怕发送方发的太快，造成网络拥塞，使得网络来不及处理。==拥塞窗口在发送方==

最后取接受方和发送方的最小值。

> 快重传时，重传哪些包


![](https://gitee.com/super-jimwang/img/raw/master/img/20210306214248.png)
当包2没收到时，连回3个ACK2.那么对方就知道2需要重传，==只重传2==，当收到2时，由于4，5都收到了，所以回ACK6，表示可以回6了

# TCP三次握手和四次挥手

TCP是可靠的双向通道传输协议，所以需要三次握手建立连接和四次挥手关闭连接来保证信息传输的可靠性。



### 报文标识位

先来了解一下TCP在握手连接时候的报文用到的标志位。

- SYN：**建立连接消息的标志**
- ACK（Acknowledgment Number）：**应答消息的标志**
- FIN：连接关闭的标志



### 三次握手

![image-20210209213041707](https://gitee.com/super-jimwang/img/raw/master/img/20210209213041.png)

第一次握手：建立连接。客户端发送SYN连接请求报文段，将SYN位置为1，Sequence Number(seq)置为x；然后，客户端进入**SYN_SEND状态**，等待服务器的确认；



第二次握手： 服务器收到客户端的SYN报文段。服务器需要对这个SYN报文段进行确认，设置为ack=x+1(seq+1)；同时，自己还要发送SYN+ACK报文段，来应答建立连接请求，将SYN+ACK位置为1，seq置为y；服务器端将上述所有信息放到一个报文段（即SYN+ACK报文段）中，一并发送给客户端，此时服务器进入**SYN_RECV状态**；



第三次握手： 客户端收到服务器的SYN+ACK报文段。然后设置ack=seq+1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。



ack总是回复信息的seq+1. 如果是回复的信息，ACK就是1，标示位表示是回复。



### 为什么要三次握手

为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。如果只有两次握手，client发送连接请求后不再ACK服务端的SYN。此时client由于自身的原因判断建立连接失败，可能会重复建立TCP连接，而服务端却会认为那些被client丢弃的TCP连接依然有效，会浪费服务端资源。

举例：**比如假设只有两次握手，客户端向服务端发起了连接请求，但是由于网络延迟，被滞留了，很久以后才到达了服务端，服务端以为是新的链接请求，就返回确认报文，并由于只有两次握手，服务端开始等待客户端的数据，因此浪费了资源**



## 四次挥手过程

![image-20210209213541539](https://gitee.com/super-jimwang/img/raw/master/img/20210209213541.png)

第一次挥手： client发送关闭连接请求。向server发送一个FIN报文段，设置Sequence Number；此时，client进入FIN_WAIT_1状态；这表示client没有数据要发送给server了；



第二次挥手： server收到了client发送的FIN报文段，向client返回ACK报文段, 设置ack=seq+1，seq=v；client进入FIN_WAIT_2状态；server告诉client，我“同意”你的关闭请求，但是你要等一下，我还有东西要给你；



第三次挥手： server向client发送FIN+ACK报文段，设置ack=seq+1，seq=w；确认没有数据要传输了，可以进行关闭连接，同时server进入LAST_ACK状态，等待client确认收到最后的数据；==**注意，这里的ack=seq+1，seq是客户端发送的第一次挥手**==



第四次挥手： client收到server发送的FIN报文段，向server发送ACK报文段，然后client进入TIME_WAIT状态；server收到主机1的ACK报文段以后，就关闭连接；==**此时，client等待2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，client也可以关闭连接了。**== 是server先关闭，后才是client关闭



### 为什么需要四次挥手

TCP是全双工模式，这就意味着，当主机1发出FIN报文段时，只是表示主机1已经没有数据要发送了，主机1告诉主机2，它的数据已经全部发送完毕了；但是，这个时候主机1还是可以接受着来自主机2的数据；当主机2返回ACK报文段时，表示它表示已经知道主机1没有数据发送了，但主机2还是有数据要发送数据到主机1的；当主机2也发送了FIN报文段时，这个时候就表示主机2也没有数据要发送了，就会告诉主机1，我也没有数据要发送了，之后彼此就会愉快的中断这次TCP连接。

### TIME_WAIT和CLOSE_WAIT的区别

CLOSE_WAIT(服务端)是被动关闭形成的；当对方close socket而发送FIN报文过来时，回应ACK之后进入CLOSE_WAIT状态。随后检查是否存在未传输数据，如果没有则发起第三次挥手，发送FIN报文给对方，进入LAST_ACK状态并等待对方ACK报文到来

TIME_WAIT(客户端)是主动关闭连接方式形成的；处于FIN_WAIT_2状态时，收到对方FIN报文后进入TIME_WAIT状态；之后再等待两个MSL(Maximum Segment Lifetime:报文最大生存时间)



### 为什么需要等待2MSL后，client才关闭

MSL(Maximum Segment Lifetime)：报文段最大生存时间，它是任何报文段被丢弃前在网络内的最长时间。

原因有二：

- 保证TCP协议的全双工连接能够可靠关闭
- 保证这次连接的重复数据段从网络中消失

==**第一点：由于网络的不稳定，可能client最后回复的fin报文没有被server正常接收到，那么这个时间最大为MSL。当没接受时，server会再次发送FIN，那么这个时间最大也为MSL。因此要等2MSL后才可以关闭。**==

==**第二点：确保这次链接中的数据从网络消失。如果client直接close，后又向server发起了新的链接，那么可能会时相同端口号的，可能会收到上一次链接中的数据。**==



## SYN Flood

SYN Flood 伪造 SYN 报文向服务器发起连接，服务器在收到报文后用 SYN_ACK 应答，此应答发出去后，不会收到 ACK 报文，造成一个半连接

若攻击者发送大量这样的报文，会在被攻击主机上出现大量的半连接，耗尽其资源，使正常的用户无法访问，直到半连接超时

> TCP是如何保证可靠传输

1. 应用数据被分割成TCP认为最合适发送的数据块
2. TCP给发送的每一个包进行编号，接收方对数据包进行排序再给应用层
3. 校验和，对验证有错的丢弃，并不确认收到此报文
4. TCP的接收端会丢弃重复的数据
5. 流量控制：使用滑动窗口，提示发送方降低发送的速率
6. 拥塞控制
7. ARQ协议，每发完一个分组就停止发送，等待对方确认。收到确认后再发下一组
8. 超时重传：超时还未确认的，就会在发送一次。

> 什么是ARQ协议

Automatic Repeat-reQuest。自动重传请求
它又分为停止等待ARQ协议和连续ARQ协议。

> 停止等待ARQ协议原理说一下

每发完一个分组就停止发送，等待对方确认ACK。然后再发送

> 连续ARQ协议原理说一下

发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方采用累计确认，对按序到达的最后一个分组发送确认，表明到达这个分组为止的所有分组都已经确认收到了。

> time_wait状态只会出现在客户端吗

服务端也会，如果服务端是主动关闭的一方。

> 服务端主动关闭会有什么问题？如何解决

因为time_wait等2MSL，客户端的一个连接对应服务端的一个fd，而fd是有限的，因此如果有大量的time_wait浪费了fd，新来的连接就无法连接了。

服务端为了解决这个TIME_WAIT问题，可选的方式有3种：
（1）保证由客户端主动发起关闭

（2）关闭的时候使用RST方式

（3）对处于TIME_WAIT状态的TPC允许重用

# TCP停止等待协议、连续ARQ协议

## 停止等待协议

所谓停止等待协议就是每发送完一组数据后，等待对方确认并且收到确认后，再发送下一组数据。

可能会发生四种情况：无差错，出现差错，确认丢失和确认迟到

### 出现差错

当B收到M1时，检测出了差错，就抛弃M1，并什么也不做

A在超过一段时间仍然没有收到确认，就认为数据丢失了，然后会重传一次。这叫超时重传

![image-20210210160601249](https://gitee.com/super-jimwang/img/raw/master/img/20210210160601.png)

### 确认丢失

当A发送M1消息，B收到后，B向A发送了一个M1确认消息，但却在传输过程中丢失。而A并不知道，在超时计时过后，A重传M1消息，B再次收到该消息后采取以下两点措施：

​    1>、丢弃这个重复的M1消息，不向上层交付。

​    2>、向A发送确认消息。（不会认为已经发送过了，就不再发送。A能重传，就证明B的确认消息丢失）。

![image-20210210160610047](https://gitee.com/super-jimwang/img/raw/master/img/20210210160610.png)

### 确认迟到

 所谓确认迟到，就是B发送的确认消息没有丢失，但是却迟到（过了很长一段时间才到）

  A发送M1消息，B收到并发送确认。在超时时间内没有收到确认消息，A重传M1消息，B仍然收到并继续发送确认消息（B收到了2份M1）。此时A收到了B第二次发送的确认消息。接着发送其他数据。过了一会，A收到了B第一次发送的对M1的确认消息（A也收到了2份确认消息）。处理如下：

​    **1>、A收到重复的确认后，直接丢弃。**

​    **2>、B收到重复的M1后，也直接丢弃重复的M1。**

![image-20210210160703193](https://gitee.com/super-jimwang/img/raw/master/img/20210210160703.png)

## 连续ARQ协议

![image-20210210160742207](https://gitee.com/super-jimwang/img/raw/master/img/20210210160810.png)

连续ARQ协议可以大大提高信道利用率

![image-20210210160810491](https://gitee.com/super-jimwang/img/raw/master/img/20210210160810.png)

 连续ARQ规定，发送方每收到一个确认就将滑动窗口向前（时间增大方向）滑动一格。

==接受方采用**累积确认**的方式：**接收方不必每收到一个消息，就发送一个确认。而是在收到几条消息后，对按序到达的最后一条消息发送确认**。表示，这个消息之前的所有消息全部收到。==



# TCP粘包和拆包

## 什么是粘包和拆包

为了提高带宽利用率，tcp协议会使用Nagle算法，将多个数据包打包成一个tcp报文发送出去，这就是所谓的粘包。

而如果通讯的一端发送的数据包超过一次tcp报文所能传输的最大值MTU时，就会将一个数据包拆成多个最大tcp长度的tcp报文分开传输，这就叫做拆包。

MTU:

泛指通讯协议中的最大传输单元。一般用来说明TCP/IP四层协议中数据链路层的最大传输单元，不同类型的网络MTU也会不同，我们普遍使用的以太网的MTU是1500，即最大只能传输1500字节的数据帧。可以通过ifconfig命令查看电脑各个网卡的MTU。

MSS:

指TCP建立连接后双方约定的可传输的最大TCP报文长度，是TCP用来限制应用层可发送的最大字节数。如果底层的MTU是1500byte，则 MSS = 1500- 20(IP Header) -20 (TCP Header) = 1460 byte。



## 拆包的两种方式

### 基于长度实现的两种方式

- 使用固定长度，所有的应用层消息都是用统一的大小
- 使用不固定的长度，但是需要在应用层协议的头部中增加表示负载长度的字段。（TCP头部有可选字段，可以在那个地方放置）

### 基于特定规则的方式

- 例如使用TCP发送JSON数据，接收方可以根据接收到的数据是否能够被解析成合法的JSON判断消息是否终结。



## 出现粘包的原因

当发送方连续的向客户端发送n条数据（循环发送），按照我们预想的，server端应该受到n条数据。然而server却收到了小于n条数据，而且每条数据的长短不一，有很多不是同一次发送的数据包却粘连到了一起，这就是粘包现象。

**粘包**可能发生在发送端也可能发生在接收端：

- 由Nagle算法造成的发送端粘包：Nagle算法是一种改善网络传输效率的算法。简单的来说就是当我们提交一段数据给TCP发送的时候，TCP并不会立即的发送这段数据，而是等一小段时间看看在等待的时间内是否还有其他的数据要发送，若有则一次性把两段数据发送出去。
- 接收端接收不及时造成的粘包：接收端TCP会把收到的数据写入一个缓冲区，然后通知应用层取数据。当应用层由于某些原因不能及时的把数据取走，就会造成TCP缓冲区堆积，存放了几段数据包，造成粘包现象。



## 解决粘包

出现粘包的关键在于接收方不能够确定将要接收的数据包的大小，因此我们需要手动对数据进行封包和拆包操作。



**封包**：==**封包就是给一段数据加上包头，这样一来数据包就分为包头和包体两个部分内容了（过滤非法包时封包还会加入包尾）。包头部分的长度是固定的，并且它存储了包体的长度。**==

**拆包：**==**根据包头的长度固定以及包头中所包含的包体的长度就能够正确的实现拆分出一个完整的数据包。**==



## UDP有粘包现象吗

UDP没有粘包现象，由于UDP发送数据的时候，没有经过Nagle算法优化，不会将多个小包合并到一次发送。另外，在UDP协议的**接收端，采用的是链式结构来记录**每一个到达的UDP包，这样接收端一次recv只会从socket缓冲区读取一个数据包。也就是说，发送端send了几次，接收端必须recv几次（无论recv时指定了多大的缓冲区）

# 图解TCPID
> 什么是协议

协议就是计算机网络之间通过网络实现通信时事先达成的一种约定
两台计算机必须支持相同的协议，并遵循相同的协议进行处理，才能进行通信。

> 什么是接口

在分层模型中，上下层交互时所遵循的约定叫做接口
而同层交互时所遵循的约定叫做协议

> OSI七层各层的作用

- 应用层：针对特定应用的协议。
- 表达层：设备固有数据格式和网络标准数据格式的转换。 将应用处理的信息转换为适合网络传输的格式，或将来自下一层的数据转换为上层能够处理的格式
- 会话层：通信管理。负责建立和断开通信链接。以及数据分割等
  - 何时建立连接，何时断开连接，以及保持多久的链接
- 传输层：管理两个节点之间的数据传输。TCP、UDP协议
- 网络层：地址管理与路由选择。IP协议，路由器，广域网
- 数据链路层：互连设备之间传送和识别数据帧。交换机，负责局域网。
- 物理层：以0、1代表电压的高低。

> 什么是分组交换？

发送端计算机将数据分组发送给路由器，路由器收到这些分组数据以后，缓存到自己的缓冲区，然后再按先进先出的顺序逐一发送给目标计算机。

> mac寻址和ip寻址的参考是什么？

mac寻址中参考地址转发表，记录的是mac地址，而ip寻址参考路由控制表。

> TCP/IP的具体含义是什么？

是利用IP进行通信时必须用到的协议群的统称。IP或ICMP、TCP或UDP、TELNET或FTP、以及HTTP等都属于TCP/IP协议

