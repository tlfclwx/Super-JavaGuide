> cpu的两级缓存说一下

第一级缓存称为L1缓存，在CPU中，通常用来将已解码的指令调入CPU的执行引擎。

第二级缓存称为L2缓存，用来存放近来使用过的若干MB的内存字。

第二级缓存会有时延，而第一级不会。

> 磁盘为什么访问速度慢

因为它是机械结构，需要等待盘面旋转以及磁臂到了正确的磁道上。

> 存储层次结构说一下

寄存器->高速缓存->主存->磁盘

> 操作系统实现输入和输出是三种方式

- 忙等待：用户程序发出一个系统调用，内核将其翻译成一个对应设备驱动程序的过程调用。设备驱动程序启动IO，并且一直轮询，直到完成。
- 中断：设备驱动程序启动设备并让设备完成操作时发出一个中断。设备驱动程序此时返回。当设备驱动程序监测到该设备的操作完毕时，发出中断通知操作完成。
- DMA：IO使用一种特殊的直接存储器访问（Direct Memory Access, DMA）芯片。

> 发生中断时，进程的寄存器数据保存在哪？

保存在PCB中。因为寄存器数据很小所以能保存在PCB中，而内存中的数据就不行了

> 什么是守护进程

运行在后台，处理系统特殊任务的进程。比如电子邮件进程，当收到电子邮件时，被唤醒通知。

> 父进程fork子进程，内存空间如何分配？

拥有相同的内存映射，当某一个进程要修改时，采用写时复制技术，复制相同大小的内存。因此更改数据互不影响。

> 什么是进程组

进程和它所有子进程以及后裔共同组成一个进程组。用户从键盘发出一个信号时，该信号被送给当前与键盘相关的进程组中。每个进程都可以分别捕获、忽略信号。

> PCB的作用

进程控制块PCB，保存了进程状态的重要信息，包含程序计数器、堆栈指针、内存分配状况、所打开文件的状态、账号和调度信息，以及其他在进程由运行状态转换到就绪或阻塞时所需要保存的信息，从而保证该进程随后能再次启动。

> 进程置换出内存后时，原内存的数据保存在哪

磁盘的交换区，交换区大小有限，如果满了，进程只能挂起。

## 进程间通信
> 多个进程共享内存，会有什么问题，如何解决？实现方法？

进程通信问题

会有竞争问题，需要通过临界区解决。临界区其实就是实现了进程之间的互斥，同时只有一个进程能进入临界区。

- 屏蔽中断（不好的方案）
  - 当进程要进入临界区时，屏蔽所有中断，那么该进程就不会因为中断而进入阻塞，会一直运行，直到离开临界区，再打开中断。
  - 但是有问题，把屏蔽中断的权利交给用户进程不安全。另外如果是多核的，那么其他核的进程仍有可能进入临界区
- 锁变量（不好的方案）
  - 这个方法跟多进程共享内存一样，也是把锁变量放在共享内存中。但是其问题跟多线程一样，读出来没有锁，要上锁前被别人修改了。
- 严格轮换法（不好的方案）
  - 两个进程循环判断标识位。如果为0，进程a进入，等退出的时候把标示位改为1，那么b才可以进入。
  - 但是如果进程a把标示位改了之后，而进程b卡在了非临界区的操作，那么这回临界区没人用，而a又进不去
  - ![](https://gitee.com/super-jimwang/img/raw/master/img/20210317185147.png)
- Peterson解法（软件方法）
  - ![](https://gitee.com/super-jimwang/img/raw/master/img/20210317185744.png)
  - 考虑两个进程同时调用enter_region，进程0先进去，进程2后进去。那么此时turn=1。进程1的while循环成立，一直忙循环。进程0不成立，方法返回，进入临界区。当进程0结束之后，`interested[0]=false`，进程1出循环，方法返回，进入临界区。
- TSL指令（硬件）
  - `TSL RX, LOCK` 这个指令是把LOCK存入寄存器，并把LOCK设为1，寄存器中是LOCK被修改前的值。LOCK存在共享内存中，被多个进程共享。
  - 该指令的读写操作保证是不可分割的，即该指令结束之前其他处理器不允许访问该内存字。==执行TSL指令的CPU将锁住内存总线，以禁止其他CPU在本指令结束前访问内存。==
  - ![](https://gitee.com/super-jimwang/img/raw/master/img/20210317190702.png)
- 信号量
  - 上面两种算法都是通过忙等待实现的，浪费CPU。通过信号量可以避免忙等待。如果要消费一个信号量，但是信号量当前为0，就进入睡眠。等信号量被释放出来后，会唤醒一个进程去消费，这个过程是原子的。
  - 信号量中检查数值、修改变量值以及可能发生的睡眠操作都是原子操作。==原子的意义在于当前cpu被原子操作占用，因此在修改、查询的时候，不可能会有别的进程过来修改，**除非多核cpu**==。
  - ==因此，为了防止多核CPU造成的问题，还需要借助TSL指令，把内存总线给锁了。==
- 互斥量
  - 互斥量是信号量的简易版，不需要信号量的计数能力。
- 管程
  - 是编程概念，不是基于操作系统的，并不是所有编程语言都支持
- 消息传递
  - send和receive，是基于操作系统的
- 屏障
  - 用于进程组
  - 在每个阶段的结尾安置屏障，当进程运行完该阶段时，被挂起，等待所有进程都到达，才会一起被释放。
- 管道

> peterson、信号量这些算法需要共享变量，不同进程间怎么解决

1. 可以放在内核中，并且只能通过系统调用来访问
2. 共享内存的方法

> 时钟无法停止运行时间过长的用户线程怎么理解

时间片是分配给进程的。一个单独的进程内部，没有时钟中断，所以不可能用轮转调度的方式调度线程

如果一个线程开始运行，该线程所在进程中的其他线程都不能运行，除非第一个线程自愿的放弃 CPU，在一个单进程内部，没有时钟中断，所以不可能使用轮转调度的方式调度线程。除非其他线程能够以自己的意愿进入运行时环境，否则调度程序没有可以调度线程的机会。

对于用户级线程，内核并不知道有线程存在，所以内核还是和以前一样地操作，选取一个进程，假设为A，并给予A时间片控制，A的线程调度程序决定哪个线程运行，假设为A1。由于多道线程不存在时钟中断，所以，这个线程可以按其意愿任意运行多长时间。如果该线程用完了进程的全部时间片，内核就会选择另一个进程运行。

==在线程A终于又一次运行时，线程A1会接着运行。该线程会继续耗费A进程的所有时间，直到它完成工作。==

==注意这里是用户线程，如果是内核线程运行时间超过时间片是会被挂起的==

> 什么是管程，优缺点

管程是一个编程概念，任何时刻管程内只能有一个活跃进程。java中的synchronized就是管程的一种实现。

为了能让进入管程的进程发现自己无法继续运行时被阻塞，管程还引入了wait和signal。这就是为什么synchronized中才能用wait和signal

优点：不需要手动管理，用信号量的话需要手动管理，如果顺序错了就会发生死锁

缺点：并不是所有编译器都能用管程的。编译器必须要识别管程并用某种方式对其互斥做出安排

## 内存管理
> 虚拟内存不足时，交换出去的进程放在哪

磁盘的交换区中，如果交换区也不足了，那么这个进程只能暂时挂起或者直接结束进程。

> 进程的内存在运行时会增长该如何解决？

给进程预留一些空间，用于增长用。比如C语言，堆栈和数据区中间会空出很多空间，用来分配数据等用途。如果还是不够，进程必须移动到足够大的空闲区中，或者结束进程。

![](https://gitee.com/super-jimwang/img/raw/master/img/20210319171035.png)

> 操作系统空闲内存管理的方法，如何跟踪内存使用情况？

1. 使用位图。将内存划分为多个单位，每个单位是固定数量的字节，对应位图中的一位。那么位图中0表示空闲，1表示占用，当需要分配一个k大小的进程时，只需要找到连续k个0就行了。
![](https://gitee.com/super-jimwang/img/raw/master/img/20210319171634.png)

2. 链表法。链表的每个节点包括了一个进程或者是两个进程间的空闲片段。如上图，H表示空闲区，P表示进程，还有起始地址、长度、指向下一个节点的指针。用双向链表，可以在进程释放时，检查左右是否为空闲的，如果都是空闲的，那么就可以合并成一个大的区域了。

> 在知道需要分配的空间的情况下，当内存管理使用链表法的时候，如何决定在哪个区域分配进程？

1. 首次适配法。沿着链表遍历，遇到第一个足够大的空闲区，就把空闲区分为两部分，一部分正好供进程使用，多出来的一部分，形成新的空闲区
2. 下次适配法。在首次适配法的基础上记录了这一次存储的位置，下次搜索的时候，直接从上一次的位置开始往后遍历
3. 最佳适配法。遍历整个链表，选择空间最接近需求的。但是速度很慢，为了提高速度，可以把空闲和进程分为两个链表来存储，空闲区按照从小到大存入链表，那么只要遍历到足够大的，那一定是最小满足需求的内存。
4. 快速适配法。将常用大小的空闲区维护单独的链表。比如有一个n项的表，该表的第一项是指向大小为4kb的空闲区链表表头的指针，第二项是指向大小为8kb空闲区链表表头的指针。和提升的最佳适配法一样，在进程结束后，难以将相邻的空闲区域合并。
5. 最差适配法。总是分配最大的空闲空间。

> 讲一下虚拟内存

- 每个程序拥有自己的地址空间，被分割成多个块，每一块被称为一页。==每一页有连续的地址范围。这些页被映射到物理内存，但并不是所有的页都必须在内存中才能运行。==
- 当程序引用到一部分不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的指令。
- 虚拟内存不会被直接送到内存总线上，而是被送到内存管理单元（MMU），MMU负责把虚拟地址映射为物理内存地址

> 虚拟内存是无限大的吗？

- 不是，受CPU寻址空间限制，16位的是64kb，32位的是4G

> 发生一次缺页中断，mmu会做什么？

- 先根据调度算法，选一个内存中的帧，把它的内容写入磁盘，随后把需要访问的页面读到刚才回收的帧中，然后修改页表的对应关系。
  - 先把原虚拟内存的映射改为未映射，使以后任何对虚拟地址的访问都导致中断
  - 然后把新换进来的物理内存与其虚拟地址做映射。

> 分页系统有什么不足吗？如何改进

**不足**
- 页表查询每次要访问内存，本来不用页表的情况下，只需要访问一次内存直接访问到数据了，但是有了页表，需要多次访问内存。
- 如果虚拟地址空间很大，页表也会很大。

**改进**

- 加速：转换检测缓冲区（Translation Lookaside Buffer,TLB），也称为快表。通常在MMU中，包含少量的表项，每个表项记录了页面的相关信息。
  - 如何工作：硬件首先通过将虚拟页号与TLB中所有表项同时（并行）进行匹配，判断虚拟页面是否在其中。如果在，就直接读出帧号，否则需要访问页表查询。
- 大空间：多级页表，避免把全部页表一直保存在内存中，==空闲的顶级表页将不会有对应的二级表页==。运行原理如图：![](https://gitee.com/super-jimwang/img/raw/master/img/20210320163219.png)
  - 事例：假设32位虚拟地址0x00403004。对应PT1=1，PT2=3，偏移4。首先通过顶级页表用PT1作为索引，得到表项1，然后用PT2作为索引，在表项1对应的二级页表中检索到内存地址，然后加上偏移量，就是要找的数据位置了。
  - 在一个程序只有4mb程序段，4mb数据段和4mb堆栈段的情况下。原本需要2^20个表项来表示的，现在只需要四页就行了（顶级页表+二级页表（负责程序段）+二级页表（数据段）+二级页表（堆栈段）），4*1024个表项。
- 大空间：倒排页表，每个表项不再是虚拟地址->物理内存了，而是物理内存->虚拟地址。由于虚拟地址比物理内存多得多，所以这样也是可以减小页表的空间的。但是这种方法从虚拟地址映射到物理内存就很麻烦，需要遍历。

> 如何判断虚拟地址对应的数据是在磁盘上还是内存中？

所有的地址都根据页表翻译为物理地址，如果当前线性地址所对应的页表没有指向物理地址的话，说明还没有映射到RAM中，这时候会导致缺页中断，然后操作系统接管中断处理，查找相应的PFN表，并将硬盘上的相应的数据映射到RAM中，然后写相应的页表，中断返回后CPU会重新请求这个页，这样就可以完成数据的传送和读写了

> 有哪些页面置换算法

- 最近未使用（NRU）。表项中有读写标志位，根据读写位可以将页分为1.没有被访问，没有被修改 2.没有被访问，被修改 3.被访问，没有被修改 4.被访问，被修改。每次都淘汰一个没有被访问，被修改的页。==这个页意味着，之前被访问过，并被修改了，但是由于时钟中断清零了读位。==
- FIFO
- 第二次机会页面置换算法。在FIFO基础上做修改，淘汰最老页面的时候，检测R读位是否位0，如果是说明又老，最近又没读过，就删除。
- 时钟页面置换算法
- LRU
  - 硬件实现。有一个64位计数器，每条指令执行完之后自动+1，并保存到表项中。一旦发生缺页中断，就检查表项中的计数器的值，选最小的删除。
  - 软件实现。老化算法，将页面与一个软件计数器关联，每次发生时钟中断，将计数器向右移动一位，该页面的计数器最左端加上该页面的R读位的值（0或1）。每次取最小的计数器对应的页面进行移除。

> 当发生页面置换算法时，是置换自己进程的页面出去，还是转换别人的进程？

两者都行
- 若只置换自己的，那么称为局部页面置换算法
- 若可以置换别人进程的页，称为全局页面置换算法

> 父进程fork后，子进程的空间如何分配

- 父子进程共享程序段和数据段。父子进程都有自己的页表，但是指向同一个页面集合。
- 当一个进程更新数据的时候，引发操作系统陷阱，生成一个该页的副本，从此开始，两个进程有各自的数据内存。==写时复制==

> 分页系统在进程创建，进程执行，缺页中断和进程终止时会做什么

- 进程创建时，确认程序和数据的初始大小，并为它们创建页表，在内存中为页表分配空间初始化。当进程被换出内存后，页表也会移除。操作系统还需要在磁盘的交换区中分配进程的空间，以便在进程被交换出去的时候有地方防止。
- 当调度一个进程执行的时候，必须重置MMU，刷新TLB，清除以前进程遗留的痕迹
- 缺页中断时，通过硬件寄存器来确定哪个虚拟地址造成了缺页中断
- 进程退出时，必须释放进程的页表、页面和页面在磁盘上所占的空间（交换区里的空间要清空）

## 文件系统
> linux的文件命名区分大小写吗？

区分。

> 操作系统中文件结构有哪些？linux用哪一个

- 字节序列。一种无结构的字节序列，其文件内容的任何含义只在用户程序中解释。linux用这个。
- 记录序列。文件是具有固定长度记录的序列，每个记录有内部结构
- 树

> 文件系统布局说一下

文件系统放在磁盘上，磁盘划分为一个或多个分区，每个分区中有一个独立的文件系统。磁盘的0号扇区成为主引导记录MBR，引导计算机。MBR结尾是分区表。该表给出了每个分区的起始和结束地址。

在计算机被引导，BIOS读入并执行MBR后，MBR会确定活动分区，读入它的第一个块，成为引导块。引导块存储了该分区的操作系统。

![](https://gitee.com/super-jimwang/img/raw/master/img/20210323173225.png)

> 文件的实现，是如何找到文件对应的磁盘地址的？

- 连续分配。把每个文件作为一连串连续数据块存储在磁盘上。这种方法很简单有效，但是如果删除了一个文件，那么就会产生空洞。造成空间的浪费
- 链表分配。为每个文件构造磁盘块链表，每个块的第一个字作为指向下一块的指针，块的其他部分存放数据。
  - ![](https://gitee.com/super-jimwang/img/raw/master/img/20210323180127.png)
  - 随机访问很慢，另外头节点占用了空间，导致存储数据的字节不再是2的幂次。
- 采用内存中表进行链表分配。取出磁盘块的指针字，把它们放在内存的一个表中。找文件的物理地址时，就去这张表里找。整张表需要占用很大的内存空间
- i节点。给每个文件赋予一个称为i节点的数据结构，其中记录了文件属性和文件块的磁盘地址。只在对应文件打开时，其i节点才在内存中。而在目录项中存的是一个i节点的指针，那么就可以根据路径直到i节点的指针，然后打开文件了。

> 什么是操作系统的日志系统，有什么用？

- 记录操作系统下一步要做什么，当操作系统即将完成它们之前崩溃，重启时，可以通过查看日志，获取崩溃前要执行的记录。
- 只有当日志项写入，不同的操作才可以进行。当所有操作完成后，擦除日志项。

> 什么是文件系统的一致性，如何保证一致性

如果在修改过的磁盘块全部写回之前系统崩溃，则文件系统有可能处于不一致状态。

一致性检查分为两种：块的一致性检查和文件的一致性检查。
- 块的一致性：有两张表，一张用于记录该块在文件中出现的次数，第二张表用于记录该块在空闲表或空闲位图出现的次数。正常的情况下，只能在一张表内有标记1.否则就是有问题。
- 文件的一致性：一张表，其中一个文件对应一个计数器。从根目录开始检验，沿着目录树递归下降，检查文件系统中的每个目录，目录中每个文件，表中对应文件+1. 然后根据i节点中的连接数目比较，如果一致说明没问题。

> 提高文件系统的性能的方法有哪些

- 磁盘的高速缓存
- 块提前读。在文件是顺序读取的前提下，当需要k块时，提前把k+1块也放入缓存中。
- 减少磁盘臂运动。
  - 把有可能顺序访问的块放在一起
  - 系统采用1kb的块，而按2kb来分配，那么可以让起码2kb的数据连在一起。因此寻道次数减少一半。

> 磁盘的缓存是什么

磁盘的高速缓存指的是一系列的块，它们逻辑上属于磁盘，但实际上基于性能的考虑被保存在==内存中==。注意，缓存的单位是==块==。
- 每次在使用时，检查是否在缓存中，首先把它从磁盘读取到缓存中，之后对同一个块的请求都通过高速缓存完成。
- 存储结构是散列表，并且每个块之间有一个双向链表描述使用时间的先后顺序（LRU）

![](https://gitee.com/super-jimwang/img/raw/master/img/20210324155607.png)

当缓存满了之后，会根据置换算法将缓存中的块换出去，==如果调出的块被修改过，需要写回磁盘==。但是如果在写回磁盘前发生了系统崩溃，就会导致文件系统不一致。

解决这个问题，unix有一个sync系统调用，在系统后台运行一个通常名为update的程序，它在无限循环中不断执行sync调用，每两次调用之间休眠30秒，也就是说最多丢失不超过30秒的工作内容。

## IO设备
> 什么是dma

直接存储器存取，

DMA控制器获得总线控制权后，CPU即刻挂起或只执行内部操作，由DMA控制器输出读写命令，直接控制RAM与I/O接口进行DMA传输。 在DMA控制器的控制下，在存储器和外部设备之间直接进行数据传送，在传送过程中不需要中央处理器的参与。开始时需提供要传送的数据的起始位置和数据长度。




# 处理机调度

在多道程序系统中，进程的数量往往多于处理机的个数，这样就不能同时并行的处理各个进程。

处理机调度就是，==**从就绪队列中按照一定的算法选择一个进程并将处理机分配给它运行**==，已实现进程的并行执行。

## 处理机调度层次

分为三个层次：高级调度、中级调度、低级调度



### 高级调度（作业调度）

由于内存空间有限，有时无法将用户提交的作业全部的放入到内存中，因此就需要确定某种规则来决定将作业调入内存的顺序。

**高级调度（作业调度）**：按照一定的原则，从外存上处于后备队列的作业中挑选一个或多个作业，给他们分配内存等必要资源，并**建立相应进程**（PCB）等，使他们获得竞争处理机的权利。

==**高级调度是辅存（外存）与内存之间的调度。每个作业只调入一次，调出一次。作业调入时会创建相应的PCB，作业调出时会撤销PCB。高级调度主要是指调入的问题，因为只有调入的时机需要操作系统来决定，但调出的时机必然是该作业的运行结束。**==



### 中级调度（内存调度）

==**在引入了虚拟存储技术之后，可以将暂时不能运行的进程调至外存等待。等他重新具备了运行的条件且内存有空闲时，在重新调入内存。**==

==是在虚拟内存空间不足的时候，把进程置换出去，放到磁盘的交换区。==

这样做的目的是==**提高内存的使用率和系统吞吐量。**==



暂时调到外存等待的进程状态为**挂起状态**。

**注意：**==**虽然进程进入了挂起状态，但他的PCB不会一起调到外存中，而是存到一个PCB挂起队列，并且常驻内存**==。PCB中记录了进程数据在外存中的存放位置，进程状态信息，OS会通过内存中的PCB来管理监控各个进程。（因此不能调入外存）。



**中级调度（内存调度）**：就是决定将哪个处于挂起状态的进程重新调入内存。

一个进程可能会被多次的调入、调出内存，因此**中级调度的发生频率要比高级调度高的多**。



#### 七状态模型和进程挂起

![image-20210203152331441](https://gitee.com/super-jimwang/img/raw/master/img/20210203152331.png)

“挂起”和“阻塞”的区别

两种状态都是暂时不能获得CPU的服务，但==**挂起状态时将进程映像调到外存中去了，而阻塞状态下的进程映像还在内存中。**==



### 低级调度（进程调度）

**低级调度（进程调度）**：其主要的任务是按照某种方法的策略==**从就绪队列中选取一个进程，将处理机分配给他们。**==

进程调度是操作系统中**最基本的一种调度**，在一般的操作系统中对必须配置进程调度。进程调度的**频率很高**，一般几十毫秒一次。

### ==对比==

![image-20210203152536766](https://gitee.com/super-jimwang/img/raw/master/img/20210203152536.png)

作业是操作者交给操作系统的执行单位。一个作业可以包括多个进程。

# OS的运行机制和体系结构

![image-20210128104524389](https://gitee.com/super-jimwang/img/raw/master/img/20210128104524.png)

### 什么是指令

代码都会被翻译成很多条的指令执行，每一条指令就是让cpu干一些工作。“指令”就是CPU能识别、执行的最基本命令。比如加法指令。

==有的指令是普通的指令，比如加减乘除运算指令，我们称它为**非特权指令**。而有的指令拥有着很高的权限，比如内存清零、关机等，一旦用户程序执行了这个指令，可能会造成严重的后果，我们称这样的指令为**特权指令**。==

特权指令不允许普通的用户程序使用的。



### 如何判断是否执行特权指令

我们将cpu分为用户态（目态）和内核态（管态）。

**用户态（目态）：**==此时cpu只能执行非特权指令，一般是用户程序在执行==

**内核态（管态）：**此时cpu可以执行非特权指令和特权指令，一般是内核程序在执行（内核程序是内核的管理者）



==操作系统一般用**程序状态关键字（PSW）**中的某个标志位来识别当前处理器处于一个什么状态==。如0表示用户态，1表示内核态。





### 操作系统内核结构

内核是计算机配置底层的软件，是操作系统最基本、最核心的部分。实现操作系统内核功能的程序就是内核程序。

![image-20210128104406074](https://gitee.com/super-jimwang/img/raw/master/img/20210128104406.png)

操作系统分为内核部分和非内核功能。==内核功能主要包括一些底层的操作，比如进程管理、存储器管理、设备管理、文件管理、处理机管理等。非内核功能主要是操作系统提供给用户的功能，比如任务管理器等。==

时钟管理：实现计时功能

中断处理：处理中断请求

原语：原语是一种特殊的程序，是最接近硬件的部分，这种程序运行具有原子性，执行过程是不可分割的整体，运行时间比较短、调用频繁。



对于进程管理、存储器管理、设备管理，有的操作系统不会把这部分归作内核功能，也就是不同的操作系统内核划分可能不一样。



### 大内核和微内核

![image-20210128104320218](https://gitee.com/super-jimwang/img/raw/master/img/20210128104320.png)

微内核会造成频繁的用户态和内核态的切换

# linux相关
> 软硬链接是什么

硬连接的nodeid跟文件一样，就是一个文件，往里面写东西也会同时出现在原文件中。这两个都是指向同一块硬盘中的区块。

软连接保存了其代表文件的绝对路径。如果把原文件删了，软连接就失效了。而硬连接不会失效。

> 什么是僵尸进程

当子进程比父进程结束的早，而父进程又没有SIGCHLD来回收子进程，那么子进程会一直在进程列表中保留一个位置。

僵尸进程是非常特殊的一种，它已经放弃了几乎所有内存空间，没有任何可执行代码，也不能被调度，仅仅在进程列表中保留一个位 置，记载该进程的退出状态等信息供其他进程收集。除此之外，僵尸进程不再占有任何内存空间。

如果这时父进程结束了， 那么init进程自动会接手这个子进程，为它收尸，它还是能被清除的。但是如果如果父进程是一个循环，不会结束，那么子进程就会一直保持僵尸状态，这就是 为什么系统中有时会有很多的僵尸进程。

> 僵尸进程的危害

占用了进程号，而进程号是有限的

> 父子进程的如果父进程先结束了怎么办，如果子进程先结束了怎么办？ 

如果父进程先结束，那么子进程就成了==孤儿进程==。自动成为进程1（init进程）的子进程，直到关机才会被回收。

如果子进程比父进程先结束，如果父进程没有显示调用wait函数的话，会直到父进程结束时才会回收子进程的资源。这样的子进程就成了==僵尸进程==

> 子进程如何通知父进程自己结束了 

当父进程调用wait时会被阻塞住，直到收到子进程的SIGCHLLD信号，就会回收相关资源！

子进程通过SIGCHLD信号

> fork之后父子进程的内存关系 

(1)首先我们可以确定父子进程的代码段是相同的，所以代码段是没必要复制的，因此内核将代码段标记为只读，这样父子进程就可以安全的共享此代码段了。fork之后在进程创建代码段时，新子进程的进程级页表项都指向和父进程相同的物理页帧

(2)而对于父进程的数据段，堆段，栈段中的各页，由于父子进程要相互独立，所以我们采用写实复制的技术，来最大化的提高内存以及内核的利用率。刚开始，内核做了一些设置，令这些段的页表项指向父进程相同的物理内存页。调用fork之后，内核会捕获所有父进程或子进程针对这些页面的修改企图(说明此时还没修改)并为将要修改的页面创建拷贝。系统将新的页面拷贝分配给被内核捕获的进程，还会对子进程的相应页表项做适当的调整，现在父子进程就可以分别修改各自的上述段，不再互相影响了
![](https://gitee.com/super-jimwang/img/raw/master/img/20210315172306.png)

> 什么是写时复制技术

fork（）会产生一个和父进程完全相同的子进程，但子进程在此后多会exec系统调用，出于效率考虑，linux中引入了“写时复制“技术，也就是只有进程空间的各段的内容要发生变化时，才会将父进程的内容复制一份给子进程。在fork之后exec之前两个进程用的是相同的物理空间（内存区），子进程的代码段、数据段、堆栈都是指向父进程的物理空间，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。当父子进程中有更改相应段的行为发生时，再为子进程相应的段分配物理空间。

> linux常用指令

```
cd 进入指定的目录

cd .. 返回上一级目录

ls 查看当前目录下的所有的目录与文件名

touch filename 表示创建一个文件

mkdir dirname 表示创建一个目录

rm filename 表示删除一个文件

mv 移动文件或者重命名

lshw： 查看硬件信息

lscpu：查看cpu信息

df： 查看磁盘空间

ps: 查看当前文件的进程 进程号

kill：杀死

top：根据消耗的资源,从上之下排序
```

> 什么是mmap

是一种内存映射文件的方式。

即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用read,write等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。

==如果有多个进程访问同一个文件, 则每一个进程在自己的地址空间都包含有该文件的副本,这不必要地浪费了存储空间。mmap解决了这个问题==
![](https://gitee.com/super-jimwang/img/raw/master/img/20210314095926.png)

==进程A和进程B都将该页映射到自己的地址空间, 当进程A第一次访问该页中的数据时, 它生成一个缺页中断. 内核此时读入这一页到内存并更新页表使之指向它.以后, 当进程B访问同一页面而出现缺页中断时, 该页已经在内存, 内核只需要将进程B的页表登记项指向次页即可==
![](https://gitee.com/super-jimwang/img/raw/master/img/20210314095957.png)

==一定时间后系统会自动回写脏页面到对应磁盘地址，也即完成了写入到文件的过程==

> namespace是什么

namespace 是 Linux 内核用来隔离内核资源的方式。通过 namespace 可以让一些进程只能看到与自己相关的一部分资源，而另外一些进程也只能看到与它们自己相关的资源，这两拨进程根本就感觉不到对方的存在。具体的实现方式是把一个或多个进程的相关资源指定在同一个 namespace 中。

> 守护线程什么时候结束

守护线程的作用是在后台运行任务,只要还有一个以上非守护线程没有结束(即便此时主线程已结束),程序就不会结束

# IO模型

## 同步阻塞IO (blocking IO) 也叫做BIO

![image-20210202201654267](https://gitee.com/super-jimwang/img/raw/master/img/20210202201654.png)

用户线程通过系统调用read发起IO读操作，由用户空间转到内核空间。内核等到数据包到达后，然后将接收的数据拷贝到用户空间，完成read操作。

==**整个读取过程，用户线程是被阻塞的，导致在发起IO请求时，不能做任何事情，对CPU资源利用不够**==

## 同步非阻塞IO (Non-blocking IO) 也叫做NIO

同步非阻塞IO是在同步阻塞IO的基础上，将socket设置为NONBLOCK。这样做用户线程可以在发起IO请求后可以立即返回。

![image-20210202201839390](https://gitee.com/super-jimwang/img/raw/master/img/20210202201839.png)

由于socket是非阻塞的方式，因此用户线程发起IO请求时立即返回。但并未读取到任何数据，==**用户线程需要不断地发起IO请求，直到数据到达后，才真正读取到数据，继续执行。**==

==**不断的轮询，重复请求，会消耗大量的cpu资源**==

==**个人理解：一个NIO可以通过socket监视很多的用户，当一个发送请求了，就会一对一的非阻塞处理，轮询。**==

==也是多路复用==

## IO多路复用

IO多路复用是一种同步IO模型，实现一个线程可以监控多个文件句柄。一旦某个文件句柄就绪，就能通知应用程序进行相应的IO操作。没有文件句柄时就会发生阻塞，交出cpu。多路指多个文件句柄，复用指同一个线程

一句话解释：单线程或单进程同时监控若干个文件描述符是否可以执行IO操作的能力



![image-20210202202204434](https://gitee.com/super-jimwang/img/raw/master/img/20210202202204.png)

IO多路复用模型是建立在内核提供的多路分离函数select基础之上的，使用select函数可以避免同步非阻塞IO模型中轮询等待的问题。

==**用户首先将需要进行IO操作的socket添加到select中，然后阻塞等待select系统调用返回。当数据到达时，socket被激活，select函数返回。用户线程正式发起read请求，读取数据并继续执行。**==

==但是好处在于一个线程可以设置多个监听socket，不断的调用select函数，从而激活不同的socket，达到在同一个线程内同时处理多个IO请求的目的==



### 使用Reactor设计模式的多路复用

![image-20210202202741071](https://gitee.com/super-jimwang/img/raw/master/img/20210202202741.png)

通过Reactor的方式，可以将用户线程轮询IO操作状态的工作统一交给handle_events事件循环进行处理。==**用户线程注册事件处理器之后可以继续执行做其他的工作（异步），而Reactor线程负责调用内核的select函数检查socket状态。当有socket被激活时，则通知相应的用户线程（或执行用户线程的回调函数），执行handle_event进行数据读取、处理的工作。**==

由于select是阻塞的，而用户线程异步，因此也称为**异步阻塞模型**

### select函数接口、使用示例
[视频](https://www.bilibili.com/video/BV1qJ411w7du?from=search&seid=12365697407458547972)
接口

```c
#include <sys/select.h>
#include <sys/time.h>

#define FD_SETSIZE 1024
#define NFDBITS (8 * sizeof(unsigned long))
#define __FDSET_LONGS (FD_SETSIZE/NFDBITS)

// 数据结构 (bitmap)
typedef struct {
    unsigned long fds_bits[__FDSET_LONGS];
} fd_set;

// API
int select(
    int max_fd, 
    fd_set *readset,  // 读 写 异常三张bitmap
    fd_set *writeset, 
    fd_set *exceptset, 
    struct timeval *timeout
)                              // 返回值就绪描述符的数目

FD_ZERO(int fd, fd_set* fds)   // 清空集合
FD_SET(int fd, fd_set* fds)    // 将给定的描述符加入集合
FD_ISSET(int fd, fd_set* fds)  // 判断指定描述符是否在集合中 
FD_CLR(int fd, fd_set* fds)    // 将给定的描述符从文件中删除
```

示例

```c
int main() {
  /*
   * 这里进行一些初始化的设置，
   * 包括socket建立，地址的设置等,
   */

  fd_set read_fs, write_fs;
  struct timeval timeout;
  int max = 0;  // 用于记录最大的fd，在轮询中时刻更新即可

  // 初始化比特位
  FD_ZERO(&read_fs);
  FD_ZERO(&write_fs);

  int nfds = 0; // 记录就绪的事件，可以减少遍历的次数
  while (1) {
    // read_fd就是监视的文件描述符010011这就表示第二个第五第六个文件被监视
    // 1.阻塞获取 将所有的 fd_set 传入内核 让它帮我们监听是否有事件准备就绪
    // 2.每次需要把多有的fd_set从用户态拷贝到内核态  read_fd write_fd...
    // 3.nfds 表示内核返回给你有多少个 fd 准备就绪了，并将有数据的fd在bitmap中置位
    // 这里就是使用select 返回的是就绪描述符的数目。
    // select是阻塞函数，如果一直没有数据进来就会一直阻塞在这一行
    nfds = select(max + 1, &read_fd, &write_fd, NULL, &timeout); // 这里的max+1主要是为了告诉内核最大fd的，以便内核监听
    
    // 1.用户态的进程是不知道到底哪个 fd 准备就绪的，那么它就需要再遍历一遍之前需要遍历所有的 fd
    // 2.判断有无读写事件发生 看下哪几个数据准备就绪了，然后进行处理
    for (int i = 0; i <= max && nfds; ++i) {
      if (i == listenfd) {
         --nfds;
         // 这里处理accept事件

         FD_SET(i, &read_fd);//将客户端socket加入到集合中
      }
      if (FD_ISSET(i, &read_fd)) {
        --nfds;
        // 这里处理read事件
      }
      if (FD_ISSET(i, &write_fd)) {
         --nfds;
        // 这里处理write事件
      }
    }
  }
}
```

**缺点**

- 单个进程所打开的FD是有限制的，通过FD_SETSIZE设置，默认1024。==select中底层是一个long数组，因此数组是有长度限制的。==
- 每次调用select，都需要把fd_set（文件描述符标记的bitmap）从用户态拷贝到内核态，这个开销在fd很多时会很大。
- 另外数组不可重用。内核直接在fdset数组中标记，所以不可重用。
- 唤醒的时候由于进程不知道是哪个 fd 已经就绪，需要进行一次遍历，采用轮询的方法，效率较低（高并发时）`for (int i = 0; i <= max && nfds; ++i)`

### poll函数

功能与select类似

接口

```c
#include <poll.h>
// 数据结构
// 没有使用bitmap带来了一定好处
struct pollfd {
    int fd;                         // 需要监视的文件描述符
    short events;                   // 需要内核监视的事件
    short revents;                  // 实际发生的事件
};

// API
int poll(struct pollfd fds[], nfds_t nfds, int timeout);
```



示例

```c
// 先宏定义长度
#define MAX_POLLFD_LEN 4096  

int main() {
  /*
   * 在这里进行一些初始化的操作，
   * 比如初始化数据和socket等。
   */

  int nfds = 0;
  pollfd fds[MAX_POLLFD_LEN];
  memset(fds, 0, sizeof(fds));
  fds[0].fd = listenfd;
  fds[0].events = POLLRDNORM;
  int max  = 0;  // 队列的实际长度，是一个随时更新的，也可以自定义其他的
  int timeout = 0;

  int current_size = max;
  while (1) {
    // 1. 阻塞获取  每次需要把pollfd数组从用户态拷贝到内核态
    // 2. 当内核监听到有事件就绪的时候，会把pollfd结构体中的revents置成内核监听事件，并返回就绪数目
    nfds = poll(fds, max+1, timeout);
    if (fds[0].revents & POLLRDNORM) {
        // 这里处理accept事件
        connfd = accept(listenfd);
        //将新的描述符添加到读描述符集合中
    }
    // 每次需要遍历所有fd，判断有无读写事件发生
    for (int i = 1; i < max; ++i) {
      // 可以修改fds[i].fd 和 fds[i].revents = 0 实现复用
      if (fds[i].revents & POLLRDNORM) { 
         sockfd = fds[i].fd
         if ((n = read(sockfd, buf, MAXLINE)) <= 0) {
            // 这里处理read事件
            if (n == 0) {
                close(sockfd);
                fds[i].fd = -1;
            }
         } else {
             // 这里处理write事件     
         }
         if (--nfds <= 0) {
            break;       
         }
      }
    }
  }
}
```

如果有就绪的poll是会改变其结构体pollfd内的events置成内核监听事件

**优点**

- 相比select 文件描述符的数量已不再受限制。底层是链表
- 可以修改fds[i].fd文件描述符 和 fds[i].revents = 0 实现复用



**缺点**

- 每次调用poll，都需要把pollfd集合从用户态拷贝到内核态，这个开销在fd很多时会很大
- 对fd集合扫描时仍然是线性扫描，采用轮询的方法，效率较低（高并发时）`for (int i = 1; i < max; ++i)`

### epoll函数

接口

```c
#include <sys/epoll.h>

// 数据结构
// 每一个epoll对象都有一个独立的eventpoll结构体
// 用于存放通过epoll_ctl方法向epoll对象中添加进来的事件
// epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可
struct eventpoll {
    /*红黑树的根节点，这颗树中存储着所有添加到epoll中的需要监控的事件*/
    struct rb_root  rbr;
    /*双链表中则存放着将要通过epoll_wait返回给用户的满足条件的事件*/
    // 就绪队列
    struct list_head rdlist;
};

// API

// 内核中加一个 eventpoll 对象，把所有需要监听的 fd 都放到这个对象中
int epoll_create(int size); 
// epoll_ctl 负责把 fd 增加、删除到内核红黑树
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
// epoll_wait 负责检测红黑树，就绪则放到可读队列，没有可读 fd 则阻塞进程
int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);

struct epoll_event {
    __uint32_t events; // 回调事件
    epoll_data_t data; // 存储fd等
};

```

示例

```c
int main(int argc, char* argv[])
{
   /*
   * 在这里进行一些初始化的操作，
   * 比如初始化数据和socket等。
   */

    // 内核中创建eventpoll对象
    epfd=epoll_create(256);
    // 需要监听的epfd 放到 eventpoll中
    epoll_ctl(epfd,EPOLL_CTL_ADD,listenfd,&ev);
 
    while(1) {
      // 阻塞获取 准备好了的 epfd。
      // 内核监测到就绪的事件之后，把时间放到rdlist
      nfds = epoll_wait(epfd,events,20,0);
      // 这里就直接对收到就绪的rdlist 进行遍历  不需要再遍历所有的 fd
      // 是怎么做到的呢，下面继续分析
      for(i=0;i<nfds;++i) {
          if(events[i].data.fd==listenfd) {
              // 这里处理accept事件
              connfd = accept(listenfd);
              // 接收新连接写到内核对象中
              epoll_ctl(epfd,EPOLL_CTL_ADD,connfd,&ev);
          } else if (events[i].events&EPOLLIN) {
              // 这里处理read事件
              read(sockfd, BUF, MAXLINE);
              //读完后准备写
              epoll_ctl(epfd,EPOLL_CTL_MOD,sockfd,&ev);
          } else if(events[i].events&EPOLLOUT) {
              // 这里处理write事件
              write(sockfd, BUF, n);
              //写完后准备读
              epoll_ctl(epfd,EPOLL_CTL_MOD,sockfd,&ev);
          }
      }
    }
    return 0;
}
```

epolln内部存了一个列表，所以不需要遍历所有的fd了，只需要遍历这个列表就行了` for(i=0;i<nfds;++i) `

## 异步IO

![image-20210202203301515](https://gitee.com/super-jimwang/img/raw/master/img/20210202203301.png)

异步IO模型中，用户线程直接使用内核提供的异步IO API发起read请求，且发起后立即返回，继续执行用户线程代码。不过此时用户线程已经将调用的AsynchronousOperation和CompletionHandler注册到内核，然后操作系统开启独立的内核线程去处理IO操作。当read请求的数据到达时，由内核负责读取socket中的数据，并写入用户指定的缓冲区中。最后内核将read的数据和用户线程注册的CompletionHandler分发给内部Proactor，Proactor将IO完成的信息通知给用户线程（一般通过调用用户线程注册的完成事件处理函数），完成异步IO。

==**在多路复用中，用户线程是收到Reactor的通知，再去拷贝数据，而在异步IO中，内核会直接读取socket中的数据，拷贝到指定缓冲区，再通知用户。**==



> epoll 水平触发和边缘触发的区别


水平触发
1. 对于读操作
只要缓冲内容不为空，LT模式返回读就绪。

2. 对于写操作
只要缓冲区还不满，LT模式会返回写就绪。

边缘触发
1. 对于读操作
（1）当缓冲区由不可读变为可读的时候，即缓冲区由空变为不空的时候。
（2）当有新数据到达时，即缓冲区中的待读数据变多的时候。

1. 对于写操作
（1）当缓冲区由不可写变为可写时。
（2）当有旧数据被发送走，即缓冲区中的内容变少的时候。


> IO多路复用用来解决什么问题

单线程就可以处理多个文件描述符的输入问题，而不需要每个文件描述符分配一个线程。

> 讲一下select的原理，缺点

有一个max最大值，然后用max开一个fd_set的long数组用来保存标记。通过select方法讲fd_set由用户态拷贝到内核态。阻塞。一旦由数据到了，select方法返回，并且会在fd_set中标记有数据的文件描述符。然后开始遍历fd_set，遇到了标记就处理。


缺点：
- 有max的最大监视限制，默认是1024
- 每次都需要把fd_set从用户态拷贝到内核态
- 每次都需要轮询fd_set 
- fd_set不可复用

> 讲一下poll的原理，缺点

有pollfd结构体，其中fd就是文件描述符，还有fd.events表示关心的事件还有一个revents，用于如果有数据就设置它（这是与select的不同，select中直接修改了原来的fd，导致不能重用）
poll阻塞，然后有数据来了，就返回，然后就是遍历pollfds链表，检查revents，如果有就读，并且把它重置为0。那么每次的pollfds都是一样的，就可以重复利用了

改进：
- 用pollfds链表，所以就等于没有max限制了
- 实现了重用

缺点：
- 还是需要每次都拷贝进内核态
- 还是需要线性扫描数组

> epoll的原理和改进

内部是红黑树

epoll_create: 在内核cache里建了个红黑树用于存储以后epoll_ctl传来的socket外，还会再建立一个rdllist双向链表，用于存储准备就绪的事件

epoll_ctl: 操作epfd树。注册 修改 删除。有一个epoll_event参数，里面有events，就是让内核检测的兴趣事件。`epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)`

![](https://gitee.com/super-jimwang/img/raw/master/img/20210309190917.png)
这个是通过epoll_create创建的根节点和epoll_ctl插入的一个节点。这个插入的节点就是结构体`epoll_event`

epoll_wait: 观察这个rdllist双向链表里有没有数据即可，`epoll_wait(int epfd, struct epoll_event* events, int maxevents, int timeout)`
这里的events是一个数组。把rdllist上的epoll_event一个一个copy到数组里。

红黑树上的节点，一旦IO就绪，就会调用回调函数，加入rdllist中，等待wait使用。

> epoll水平触发和边缘触发的应用场景

关于读事件，如果业务可以保证每次都可以读完，那就可以使用边缘触发，否则使用水平触发。

对于写事件，如果一次性可以写完那就可以使用水平触发，写完删除写事件就可以了；但是如果写的数据很大也不在意延迟，那么就可以使用边缘触发。

# 中断、异常和系统调用

## 中断

发生中断意味着操作系统的介入，开展管理工作。==**cpu收到中断信号，切换到内核态，cpu把权限交给操作系统，操作系统内核对中断信号进行处理（如进程1的时间片用完了，触发中断，操作系统进程管理模块切换为进程2执行，把cpu交给进程2，切换回用户态）**==。



1. 中断发生，cpu立刻进入内核态
2. 中断发生，暂停线程的执行，并由操作系统对中断进行处理
3. 对于不同的中断信号会有不同的处理



**中断是cpu用户态切换到内核态唯一的途径。**

**内核态切换到用户态 通过执行一个特权指令，将程序状态字（PSW）标志设置为用户态即可**



还有一种触发中断的情况，就是系统调用。下面详细讲

1. 当进程1发出系统调用的时候，就会触发一个**内中断（又称异常）。**这时候cpu切换回内核态，对中断信号进行处理。
2. 进程1 要进行打印操作，==**这时候操作系统会让进程1进入等待状态等待打印机IO操作。这时操作系统会换下一个进程2运行，把cpu交给进程2，切换回用户态开始工作。**==
3. 当IO完成之后，设备向cpu发出**外中断信号，**此时cpu切换回内核态，对中断信号进行处理。
4. 操作系统是IO完成了，就会唤醒进程1，把cpu交给进程1，切换回用户态，让程序继续执行。

### 中断的分类

中断分为==**内中断（也叫异常，陷入）**==和==**外中断**==

![image-20210201212506283](https://gitee.com/super-jimwang/img/raw/master/img/20210201212506.png)

内中断包括：

- 陷入：自愿提出的中断，比如系统调用
- 故障：错误引起的，比如缺页中断
- 终止：不可恢复的错误，比如除以0



### 中断的处理过程

1. 执行完每一条指令之后，cpu都要去检查当前是否有中断发生
2. 如果检测到外部中断信号，则需要保护被中断的进程的cpu环境（如程序的状态字PSW、程序的计数器PC、各种通用寄存器）
3. 根据中断信号类型转入相应的中断处理程序
4. 恢复原来过程的CPU环境并退出 中断，返回原过程继续往下执行

## 系统调用（内中断的一种）

![image-20210201212924530](https://gitee.com/super-jimwang/img/raw/master/img/20210201212924.png)

指OS提供给用户程序使用的接口，用户程序通过系统调用请求获得操作系统的服务，系统调用会使cpu从内核态切换到用户态。

用户接口分为命令接口和程序接口

命令接口：允许用户直接的去使用

程序接口：亦称为系统调用，允许用户通过程序间接使用，由一组系统调用组成



### 系统调用的过程

1. 传递系统调用的参数（int指令参数x会指明系统调用号。此处的int不是整数的意思，其实是interrupt的缩写，称为陷入指令）
2. 执行**陷入指令**（在用户态下执行的），执行陷入指令之后会立即触发一个内中断，cpu进入内核态
3. 执行系统调用相关的服务程序（内核态下执行）
4. 返回给用户程序，切换回用户态

注意：

- 发系统调用请求时在用户态下，而系统调用相关的处理过程是在内核态下进行的。
- 陷入指令是唯一一个只能在用户态下执行而不能在内核态下执行的指令

# 页面置换算法

当通过虚拟地址映射物理地址的过程中，发现页面不存在，此时就会发生缺页中断。需要通过页面置换算法将硬盘中的信息置换到内存中

## 最佳置换算法 OPT

从主存中移出永远不再需要的页面；如无这样的页面存在，则选择最长时间不需要访问的页面。于所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面，这样可以保证获得最低的缺页率。

## 先进先出置换算法 FIFO

是最简单的页面置换算法。这种算法的基本思想是：当需要淘汰一个页面时，总是选择驻留主存时间最长的页面进行淘汰，即先进入主存的页面先淘汰。其理由是：最早调入主存的页面不再被使用的可能性最大。 

## 最近最久未使用算法 LRU

这种算法的基本思想是：利用局部性原理，根据一个作业在执行过程中过去的页面访问历史来推测未来的行为。它认为过去一段时间里不曾被访问过的页面，在最近的将来可能也不会再被访问。所以，这种算法的实质是：==**当需要淘汰一个页面时，总是选择在最近一段时间内最久不用的页面予以淘汰。**==

> 除了LinkedHashMap还有什么办法实现LRU

方法1. 使用多个移位寄存器，每一个页都对应了多个移位寄存器。如果本时刻，这个页被访问了，那么移位寄存器的最高位置1. 每过一段时间，全部移位寄存器右移一位，高位补0. 某时刻LRU，就选值最小的那一个淘汰即可

![](https://gitee.com/super-jimwang/img/raw/master/img/20210315183512.png)

方法2. 利用栈。这个栈是特殊的，每次最新进来的页面都先从栈中取出，然后放在栈顶。当栈满了之后，还要往里加，就把栈底的置换出去
![](https://gitee.com/super-jimwang/img/raw/master/img/20210315184032.png)

# 虚拟内存与分配

## 虚拟内存

虚拟内存的基本思想是，每个进程有用独立的逻辑地址空间，内存被分为大小相等的多个块,称为页(Page).每个页都是一段连续的地址。==**对于进程来看,逻辑上貌似有很多内存空间，其中一部分对应物理内存上的一块(称为页框，通常页和页框大小相等)，还有一些没加载在内存中的对应在硬盘上**==

虚拟内存实际上可以比物理内存大。当访问虚拟内存时，会访问**MMU（内存管理单元）**去匹配对应的物理地址，==**而如果虚拟内存的页并不存在于物理内存中，会产生缺页中断，从磁盘中取得缺的页放入内存，如果内存已满，还会根据某种算法将磁盘中的页换出。**==

 而虚拟内存和物理内存的匹配是通过页表实现，页表存在MMU中

### 没有虚拟内存的问题

- 多个程序需要运行，但是内存空间不足了，就需要将其他程序暂时拷贝到硬盘当中，然后将新的程序装入内存运行.由于大量的数据装入装出，内存的使用效率低
- 程序可以直接访问物理内存，一个进程可以修改其他进程的内存数据
- 多线程情况下，不知道哪些物理内存可用



虚拟内存主要提供了如下三个重要的能力：

- 它把主存看作为一个存储在硬盘上的虚拟地址空间的高速缓存，并且只在主存中缓存活动区域（按需缓存）。
- 它为每个进程提供了一个一致的地址空间，从而降低了程序员对内存管理的复杂性。
- 它还保护了每个进程的地址空间不会被其他进程破坏。

## 内存分配

内存分配申请的是虚拟的内存空间，并没有拿到真正的物理内存空间。但是==**在第一次访问该内存的时候**==，程序会发现虚拟内存地址没有影射到物理内存地址，于是触发==**缺页中断（异常）**==

此时，进程会陷入内核态，执行一下操作：

1. 检查要访问的虚拟地址是否合法
2. 查找分配一个物理页
3. 填充物理内容（读取磁盘，或者直接置0）。
4. 建立虚拟内存和物理内存的映射关系



## 逻辑地址和物理地址的映射

### 分页机制

程序或操作系统逻辑地址分为多个**页**（page），将物理地址分为多个**帧**（page frame 也叫页，这里方便区分称为帧）。

**逻辑地址页到物理地址帧的映射**称为 **页表**（page table）。页号和帧号进行映射，其实页表不仅仅存了映射关系，还存当前页、帧的状态（例如是否可用，权限是否足够等）。

![image-20210131231106127](https://gitee.com/super-jimwang/img/raw/master/img/20210131231106.png)

==**每一个进程都有一张自己的页表**==



分页内存寻址过程小例子

机器：32位操作系统  256MB内存 页大小4KB

程序：32位

4K=12bit

逻辑地址 32bit=20bit页号+12bit偏移

物理地址 28bit=16bit帧号+12bit偏移

对于地址0x000011a3  页号00001 偏移 1a3。根据页号找到帧号，帧号+偏移=物理地址。

![image-20210131231835787](https://gitee.com/super-jimwang/img/raw/master/img/20210131231835.png)

根据页号去页表中找到对应帧号，对应帧号+偏移量就是真实物理地址



1. 如果查表后发现帧号是磁盘会发生什么？

这时候会触发**缺页中断**，切换到内核态，内核从磁盘读取数据加载到内存中，然后把物理地址在page table进行更新，然后重新进行内存寻址的过程。

2. 如果从磁盘加载进内存时，内存帧满了怎么办？

这时候会触发**页面置换（页面置换算法）**，将不太常用的帧 从RAM中逐出到磁盘中，让出位置来存储。



> 当通过页面置换算法的时候，原本存在内存中的页现在存哪里去了

linux中存到swap中去了。因为swap速度比磁盘快。swap就是磁盘分出了一部分当作swap区。==如果物理内存的数据被修改过之后，需要重新写回磁盘==

Swap空间的作用可简单描述为：当系统的物理内存不够用的时候，就需要将物理内存中的一部分空间释放出来，以供当前运行的程序使用。那些被释放的空间可能来自一些很长时间没有什么操作的程序，这些被释放的空间被临时保存到Swap空间中，等到那些程序要运行时，再从Swap中恢复保存的数据到内存中。这样，系统总是在物理内存不够时，才进行Swap交换。




# 线程

## 线程带来的变化

**资源分配、调度方面：**

在传统的进程机制中，进程是资源分配、调度的基本单位。引入线程以后，==**进程是资源分配的基本单位，线程是调度的基本单位**==。

**并发性方面：**

在传统的进程机制中，只能进程间并发。引入线程之后，各线程间也能并发，也就意味着一个应用程序通过分时复用可以同时的做多件事，比如qq同时视频和发送消息。

**系统开销方面：**

传统的进程间并发，需要切换进程的运行环境，系统开销很大。==**线程间并发，是同一进程内的线程切换，不需要直接切换进程，开销比较小**==。（进程切换需要存储PCB状态等）



## 用户级线程和内核级线程

用户级线程： 所有的线程管理工作由应用程序负责

内核级线程：内核级线程的管理工作是由操作系统内核负责的

## 线程同步是干嘛用的，实现方式有哪些

线程同步用于并发访问关键资源时避免冲突。

互斥量（Synchronized/Lock），只有拥有互斥对象的线程才有访问公共资源的权限。实现资源互斥
信号量：PV操作，P是-，V是+。对于P，m>0时就-1，否则挂起进程的执行。对于V，如果有其他进程因等待m而被挂起，就让他恢复，否则m+1。实现多个线程访问同一个共享资源
事件信号：wait/notify。控制优先级和执行顺序

# 死锁

## 什么是死锁

在并发环境下，各进程竞争资源而造成的一种相互等待对方手里资源，导致各个进程都阻塞，都无法向前推进的现象，就是死锁



## 死锁的必要条件

- 互斥条件：对必须互斥访问的资源的争抢才会导致死锁
- 不可剥夺条件：进程所获的的资源没有使用完之前，不能由其他进程强行夺走，只能主动释放
- 循环等待条件：存在循环等待链，链上的每一个进程已经获得的资源被下一个进程请求。
- 占有且等待条件：进程已经获取了一项资源，但是又提出了其他请求，此时请求被阻塞，但又对自己的资源保持不放。



## 死锁的处理策略

### 预防死锁

破坏死锁的四个必要条件中的一个或几个



**破坏互斥条件**：把互斥的资源改造成共享使用，则系统不会进入死锁状态。比如**SPOOLing技术**，把独占设备改造成共享设备。在使用之后，各个请求被处理，进程不需要阻塞等待。

缺点：但并不是所有的资源都可以使用这一项技术改造成共享资源



**破坏不可剥夺条件：**方式一：当某一个进程请求的资源得不到满足的时候，立即释放保持的所有条件，待以后需要的时候在申请。方式二：当进程需要的资源被其他进程所占有的时候，由操作系统协助把需要的资源剥夺（涉及优先级）。

缺点：复杂、反复申请释放资源增加开销，可能使以前的一些工作失效。因此这种方法只适用于易保存易恢复状态的资源。



**破坏占有且等待条件**：采用静态分配法，进程运行前一次性申请完它所需要的所有资源。

缺点：资源利用率低，可能会导致饥饿。



**破坏循环等待条件：**顺序资源分配法。给系统中的资源编号，规定进程按照递增的顺序请求资源。一个进程已经占有小编号资源才有资格申请大编号资源。

缺点：不方便新增资源，进程使用资源的顺序可能不是递增的。会导致资源浪费





### 避免死锁

用某种方法防止系统进入不安全状态，如银行家算法。

**安全序列**，指系统按照一个序列分配资源，每个进程都能顺利的完成。安全序列可以有很多个。



如果系统找不出任何一个安全序列，系统就进入了不安全状态。这就意味着之后可能所有的进程都无法继续进行下去。当然如果一些进程归还了一些资源，系统可能也有可能重新回到安全状态，不过我们要考虑最坏的情况。



处于安全状态，一定不会死锁；处于不安全状态，就可能发生死锁。因此在资源分配之前预先判断这次分配是否会导致系统进入不安全状态。**未雨绸缪，这也是银行家算法的核心思想**

![image-20210206162153879](https://gitee.com/super-jimwang/img/raw/master/img/20210206162153.png)

> 银行家算法

1. 检查手上资源够不够一个进程完成
   1. 不够就不安全
2. 若分配了，是否能满足一个进程的需求
   1. 不能则不安全
3. 分配给一个进程之后，进程原有的资源也能一起释放出来
4. 继续重复2，3.如果能这么一种分配顺序所有进程都能安全执行完，就安全。

### 死锁的检测和解除

允许死锁发生，不过操作系统会检测死锁的发生，然后才去某种措施解决。

# 生产者消费者问题

![image-20210206153202837](https://gitee.com/super-jimwang/img/raw/master/img/20210206153202.png)

对于缓冲区而言是互斥的，同一时刻只能由一个进程完成生产或消费（缓冲区是临界资源，各进程必须互斥的访问）
生产者、消费者共享一个初始为空、大小为n的缓冲区。
只有缓冲区没满时，生产者才能把产品放进缓冲区，否则必须等待。
只有缓冲区不空时，消费者才能从中取出产品，否则等待。

```
semaphore mutex = 1;  // 互斥信号量，实现对缓冲区的互斥访问
semaphore empty = n;  // 同步信号量，表示空闲缓冲区的数量
semaphore full  = 0;  // 同步信号量，表示产品的数量，即非空缓冲区的数量

void producer() {
    while (1) {
        /*生产一个产品*/
        P(empty); // 消耗一个空闲缓冲区。这里是先判断了商品是否已满，如果不满，就能消耗一个缓冲区，否则就阻塞着，等商品被消耗了再来增加产品。
        
        P(mutex); // 对缓冲区上锁。 互斥锁，避免同时的生产和消耗，导致数字出问题
        /*把产品放入缓冲区*/
        V(mutex); // 对缓冲区解锁
        
        V(full);  // 增加一个产品
    }
}

void consumer() {
    while (1) {
        P(full);  // 消耗一个产品
        
        P(mutex); // 对缓冲区上锁
        /*从缓冲区取出一个产品*/
        V(mutex); // 对缓冲区解锁
        
        V(empty); // 增加一个空闲缓冲区
        /*使用产品*/
    }
}
```

**注意：顺序不能颠倒**

1. P(empty); V(empty);是实现消费产品之后，对空闲缓冲区的数目实现进程的同步，因此在消费者最后执行V操作，在生产者最前面进行P操作。
2. P(full); V(full);是实现生产产品之后，对产品的的数目的实现进程同步，因此在生产者最后执行V操作，在消费者最前面进行P操作。
3. P(mutex);V(mutex)；实现对缓冲区临界资源的互斥访问。

## 问题

这里如果交换了两个P的位置，那么可能先拿到了互斥锁，此时发现商品满的，不需要上商品，阻塞了，但是互斥锁还在手里。消费者就没法消费了，那么就死锁了，永远没人来消费。



如果交换两个V的位置，不会死锁，但是锁的粒度增大，会导致运行效率低。

# 内核态和用户态以及其切换

## 内核态和用户态

内核态：cpu可以访问内存的所有数据，包括外围设备，例如硬盘，网卡，cpu也可以将自己从一个程序切换到另一个程序。

用户态：只能受限的访问内存，且不允许访问外围设备，占用cpu的能力被剥夺，cpu资源可以被其他程序获取。



为什么要有用户态和内核态？

由于需要限制不同的程序之间的访问能力, 防止他们获取别的程序的内存数据, 或者获取外围设备的数据, 并发送到网络, CPU划分出两个权限等级 -- 用户态和内核态。

安全隔离，保护内核地址空间



用户空间是用户程序的运行空间

所有用户程序都是运行在用户态的, 但是有时候程序确实需要做一些内核态的事情, 例如从硬盘读取数据, 或者从键盘获取输入等。这时候就需要切换到内核态



## 用户态和内核态的切换

这时需要一个这样的机制: 用户态程序切换到内核态, 但是不能控制在内核态中执行的指令

这种机制叫系统调用, 在CPU中的实现称之为陷阱指令(Trap Instruction)

他们的工作流程如下:

1. 用户态程序将一些数据值放在寄存器中, 或者使用参数创建一个堆栈(stack frame), 以此表明需要操作系统提供的服务.
2. 用户态程序执行陷阱指令
3. CPU切换到内核态, 并跳到位于内存指定位置的指令, 这些指令是操作系统的一部分, 他们具有内存保护, 不可被用户态程序访问
4. 这些指令称之为陷阱(trap)或者系统调用处理器(system call handler). 他们会读取程序放入内存的数据参数, 并执行程序请求的服务
5. 系统调用完成后, 操作系统会重置CPU为用户态并返回系统调用的结果



用户态切换到内核态的3种方式

（1）系统调用

这是用户态进程主动要求切换到内核态的一种方式。用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作。例如fork（）就是执行了一个创建新进程的系统调用。系统调用的机制核心是使用了操作系统为用户特别开放的一个中断来实现，如Linux的int 80h中断。

（2）异常

当cpu在执行运行在用户态下的程序时，发生了一些没有预知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关进程中，也就是切换到了内核态，如缺页异常。

（3）外围设备的中断

当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令而转到与中断信号对应的处理程序去执行，如果前面执行的指令时用户态下的程序，那么转换的过程自然就会是 由用户态到内核态的切换。如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后边的操作等。

这三种方式是系统在运行时由用户态切换到内核态的最主要方式，其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。从触发方式上看，切换方式都不一样，但从最终实际完成由用户态到内核态的切换操作来看，涉及步骤是一样的，都相当于执行了一个中断响应的过程。系统调用实际上最终是中断机制实现的，而异常和中断的处理机制基本一致。



# 内存泄漏和内存溢出

## 内存溢出

指程序在申请内存时，没有足够的空间使用。比如申请了一个integer，但给它存了long才能存下的数，那就是内存溢出。内存溢出就是你要求分配的内存超出了系统能给你的，系统不能满足需求，于是产生溢出。

### 内存溢出的可能原因

- 内存中加载的数据量过于庞大，以至于一次性存不下
- 死循环或者过多次数的递归
- 启动参数内存设置的过小
- 对象引用没有回收，导致jvm gc无法回收，从而减少了可用的内存



### 内存溢出的解决方案

第一步，直接增加内存

第二步，检查错误日志，查看“OutOfMemory”错误前是否有其它异常或错误。

第三步，对代码进行走查和分析，找出可能发生内存溢出的位置。



重点排查以下几点：

1.检查对数据库查询中，是否有一次获得全部数据的查询。一般来说，如果一次取十万条记录到内存，就可能引起内存溢出。这个问题比较隐蔽，在上线前，数据库中数据较少，不容易出问题，上线后，数据库中数据多了，一次查询就有可能引起内存溢出。因此对于==**数据库查询尽量采用分页的方式查询**==。

2.检查代码中是否有死循环或递归调用。

3.检查是否有大循环重复产生新对象实体。

4.检查List、MAP等集合对象是否有使用完后，未清除的问题。List、MAP等集合对象会始终存有对对象的引用，使得这些对象不能被GC回收。



第四步，使用内存查看工具动态查看内存使用情况

## 内存泄漏

指你向系统申请分配内存使用(new)，可是使用完了以后却不归还(free)，结果你申请到的那块内存不能再次访问使用(你把内存地址弄丢了)，而系统也不能再次将他分配给需要的程序。一次内存泄露危害可以忽略，但内存泄露的堆积后果非常严重，无论多少内存迟早会被吃光。memory leak会最终会导致out of memory！

### 内存泄漏的分类**以发生的方式来分类，内存泄漏可以分为4类：**



- 常发性内存泄漏。发生内存泄漏的代码会被多次执行到，每次被执行的时候都会导致一块内存泄漏。
- 偶发性内存泄漏。发生内存泄漏的代码只有在某些特定环境或操作过程下才会发生。常发性和偶发性是相对的。对于特定的环境，偶发性的也许就变成了常发性的。所以测试环境和测试方法对检测内存泄漏至关重要。
- 一次性内存泄漏。发生内存泄漏的代码只会被执行一次，或者由于算法上的缺陷，导致总会有一块仅且一块内存发生泄漏。比如，在类的构造函数中分配内存，在析构函数中却没有释放该内存，所以内存泄漏只会发生一次。
- 隐式内存泄漏。程序在运行过程中不停的分配内存，但是直到结束的时候才释放内存。严格的说这里并没有发生内存泄漏，因为最终程序释放了所有申请的内存。但是对于一个服务器程序，需要运行几天，几周甚至几个月，不及时释放内存也可能导致最终耗尽系统的所有内存。所以，我们称这类内存泄漏为隐式内存泄漏。

# 内存管理
> 内存管理主要做什么

主要负责内存的分配与回收（melloc和free）。将逻辑地址转换为物理地址。

> 内存管理有几种方式 说一下

连续分配管理和非连续分配管理。

连续分配管理比如块式管理，非连续分配管理比如页式管理和段式管理还有段页式管理

1. 块式管理：
   - 把内存分为几个固定大小的块，每个块只包含一个进程。
2. 页式管理：
   - 将内存分为大小相等的页，且固定页的形式（4kb）。提高了内存利用率，减少了碎片，页式管理可以通过页表对应逻辑地址和物理地址。
3. 段式管理：
   - 页式管理无实际意义。而段式管理有实际意义，每个段定义了一组逻辑信息。比如代码段，数据段等。
4. 段页式管理：
   - 结合分段和分贝思想，先将用户程序分成若干段并分别赋予段名，再将这些段分为若干页
   - 地址结构:由段号、段内页号和页内地址三项共同构成地址

> 讲一下快表和多级页表吧

快表和多级页表都是页表管理中的。
快表是为了加速虚拟地址到物理地址的映射。快表放在缓存中，因此不需要对内存进行IO，速度更快。其流程如下：
- 先访问缓存中的快表，如果不存在
- 再去访问页表，如果有就把该想保存到快表中
- 当快表填满之后，需要进行淘汰。

多级页表是为了避免把全部页表一直放在内存中而占用空间。因此只存一部分在内存中。

> 什么是局部性原理说一下

- 时间局部性：如果一条指令被执行了，或者一个数据被访问了，那么最近很可能再次执行和访问。这是因为程序中大量的循环。
- 空间局部性：如果访问了某个存储单元，那么这个地址附近的也很可能会被访问。因为数据大多是顺序分布的，比如数组等。

> 虚拟内存的实现要依赖什么

页面置换算法，当发生缺页中断的时候，就需要页面置换。




# 零拷贝
> 什么是零拷贝

零拷贝描述的是CPU不执行拷贝数据从一个存储区域到另一个存储区域的任务，这通常用于通过网络传输一个文件时以减少CPU周期和内存带宽。

> 零拷贝的好处

减少甚至完全避免不必要的CPU拷贝，从而让CPU解脱出来去执行其他的任务
减少内存带宽的占用
通常零拷贝技术还能够减少用户空间和操作系统内核空间之间的上下文切换

> 零拷贝的实现方向有那些

① 直接 I/O：对于这种数据传输方式来说，应用程序可以直接访问硬件存储，操作系统内核只是辅助数据传输。这种方式依旧存在用户空间和内核空间的上下文切换，但是硬件上的数据不会拷贝一份到内核空间，而是直接拷贝至了用户空间，因此直接I/O不存在内核空间缓冲区和用户空间缓冲区之间的数据拷贝。

② 在数据传输过程中，避免数据在用户空间缓冲区和系统内核空间缓冲区之间的CPU拷贝，以及数据在系统内核空间内的CPU拷贝。

③ copy-on-write(写时复制技术->父子进程fork的时候就用了这个技术)：在某些情况下，Linux操作系统的内核空间缓冲区可能被多个应用程序所共享，操作系统有可能会将用户空间缓冲区地址映射到内核空间缓存区中。当应用程序需要对共享的数据进行修改的时候，才需要真正地拷贝数据到应用程序的用户空间缓冲区中，并且对自己用户空间的缓冲区的数据进行修改不会影响到其他共享数据的应用程序。所以，如果应用程序不需要对数据进行任何修改的话，就不会存在数据从系统内核空间缓冲区拷贝到用户空间缓冲区的操作。

> 讲一下传统的IO过程中如何拷贝的流程

![](https://gitee.com/super-jimwang/img/raw/master/img/20210316142017.png)
① 发出read系统调用：导致用户空间到内核空间的上下文切换(第一次上下文切换)。通过DMA引擎（直接内存访问）将文件中的数据从磁盘上读取到内核空间缓冲区(第一次拷贝: hard drive ——> kernel buffer)。
② 将内核空间缓冲区的数据拷贝到用户空间缓冲区(第二次拷贝: kernel buffer ——> user buffer)，然后read系统调用返回。而系统调用的返回又会导致一次内核空间到用户空间的上下文切换(第二次上下文切换)。
③ 发出write系统调用：导致用户空间到内核空间的上下文切换(第三次上下文切换)。将用户空间缓冲区中的数据拷贝到内核空间中与socket相关联的缓冲区中(即，第②步中从内核空间缓冲区拷贝而来的数据原封不动的再次拷贝到内核空间的socket缓冲区中。)(第三次拷贝: user buffer ——> socket buffer)。
④ write系统调用返回，导致内核空间到用户空间的再次上下文切换(第四次上下文切换)。通过DMA引擎将内核缓冲区中的数据传递到协议引擎(第四次拷贝: socket buffer ——> protocol engine)，这次拷贝是一个独立且异步的过程。

==总的来说，传统的I/O操作进行了4次用户空间与内核空间的上下文切换，以及4次数据拷贝。其中4次数据拷贝中包括了2次DMA拷贝和2次CPU拷贝。==

> write系统调用一定保证数据写入了吗？

事实上调用的返回并不保证数据被传输；它甚至不保证传输的开始。它只是意味着将我们要发送的数据放入到了一个待发送的队列中，在我们之前可能有许多数据包在排队。除非驱动器或硬件实现优先级环或队列，否则数据是以先进先出的方式传输的。

> 传统I/O模式为什么将数据从磁盘读取到内核空间缓冲区，然后再将数据从内核空间缓冲区拷贝到用户空间缓冲区了？为什么不直接将数据从磁盘读取到用户空间缓冲区就好？

传统I/O模式之所以将数据从磁盘读取到内核空间缓冲区而不是直接读取到用户空间缓冲区，是为了减少磁盘I/O操作以此来提高性能。因为OS会根据局部性原理在一次read()系统调用的时候预读取更多的文件数据到内核空间缓冲区中，这样当下一次read()系统调用的时候发现要读取的数据已经存在于内核空间缓冲区中的时候只要直接拷贝数据到用户空间缓冲区中即可，无需再进行一次低效的磁盘I/O操作

理解：一次IO读进来的不全是用户现在要的，还有一些根据局部性原理一起读进来的，所以都先放到内核，如果用户态要用直接从内核拿。

> 如何实现零拷贝IO

1. sendfile
2. mmap


> sendfile如何实现零拷贝

![](https://gitee.com/super-jimwang/img/raw/master/img/20210316142001.png)
① 发出sendfile系统调用，导致用户空间到内核空间的上下文切换(第一次上下文切换)。通过DMA引擎将磁盘文件中的内容拷贝到内核空间缓冲区中(第一次拷贝: hard drive ——> kernel buffer)。然后再将数据从内核空间缓冲区拷贝到内核中与socket相关的缓冲区中(第二次拷贝: kernel buffer ——> socket buffer)。
② sendfile系统调用返回，导致内核空间到用户空间的上下文切换(第二次上下文切换)。通过DMA引擎将内核空间socket缓冲区中的数据传递到协议引擎(第三次拷贝: socket buffer ——> protocol engine)

==总的来说，通过sendfile实现的零拷贝I/O只使用了2次用户空间与内核空间的上下文切换，以及3次数据的拷贝。其中3次数据拷贝中包括了2次DMA拷贝和1次CPU拷贝。==

> 传统IO和sendfile零拷贝IO的不同

- 传统I/O通过两条系统指令read、write来完成数据的读取和传输操作，以至于产生了4次用户空间与内核空间的上下文切换的开销；而sendfile只使用了一条指令就完成了数据的读写操作，所以只产生了2次用户空间与内核空间的上下文切换。
- 传统I/O产生了2次无用的CPU拷贝，即内核空间缓存中数据与用户空间缓冲区间数据的拷贝；而sendfile最多只产出了一次CPU拷贝，即内核空间内之间的数据拷贝，甚至在底层操作体系支持的情况下，sendfile可以实现零CPU拷贝的I/O。
- 因传统I/O用户空间缓冲区中存有数据，因此应用程序能够对此数据进行修改等操作；而sendfile零拷贝消除了所有内核空间缓冲区与用户空间缓冲区之间的数据拷贝过程，因此sendfile零拷贝I/O的实现是完成在内核空间中完成的，这对于应用程序来说就无法对数据进行操作了。


> mmap如何实现零拷贝IO

① 发出mmap系统调用，导致用户空间到内核空间的上下文切换(第一次上下文切换)。通过DMA引擎将磁盘文件中的内容拷贝到内核空间缓冲区中(第一次拷贝: hard drive ——> kernel buffer)。
② mmap系统调用返回，导致内核空间到用户空间的上下文切换(第二次上下文切换)。接着用户空间和内核空间共享这个缓冲区，而不需要将数据从内核空间拷贝到用户空间。因为用户空间和内核空间共享了这个缓冲区数据，所以用户空间就可以像在操作自己缓冲区中数据一般操作这个由内核空间共享的缓冲区数据。
③ 发出write系统调用，导致用户空间到内核空间的上下文切换(第三次上下文切换)。将数据从内核空间缓冲区拷贝到内核空间socket相关联的缓冲区(第二次拷贝: kernel buffer ——> socket buffer)。
④ write系统调用返回，导致内核空间到用户空间的上下文切换(第四次上下文切换)。通过DMA引擎将内核空间socket缓冲区中的数据传递到协议引擎(第三次拷贝: socket buffer ——> protocol engine)

==总的来说，通过mmap实现的零拷贝I/O进行了4次用户空间与内核空间的上下文切换，以及3次数据拷贝。其中3次数据拷贝中包括了2次DMA拷贝和1次CPU拷贝。==

### 零拷贝

#### 传统 IO 问题

传统的 IO 将一个文件通过 socket 写出

```java
File f = new File("helloword/data.txt");
RandomAccessFile file = new RandomAccessFile(file, "r");

byte[] buf = new byte[(int)f.length()];
file.read(buf);

Socket socket = ...;
socket.getOutputStream().write(buf);
```

内部工作流程是这样的：

![](https://gitee.com/super-jimwang/img/raw/master/img/20210527150704.png)

1. java 本身并不具备 IO 读写能力，因此 read 方法调用后，要从 java 程序的**用户态**切换至**内核态**，去调用操作系统（Kernel）的读能力，将数据读入**内核缓冲区**。这期间用户线程阻塞，操作系统使用 DMA（Direct Memory Access）来实现文件读，其间也不会使用 cpu

   > DMA 也可以理解为硬件单元，用来解放 cpu 完成文件 IO

2. 从**内核态**切换回**用户态**，将数据从**内核缓冲区**读入**用户缓冲区**（即 byte[] buf），这期间 cpu 会参与拷贝，无法利用 DMA

3. 调用 write 方法，这时将数据从**用户缓冲区**（byte[] buf）写入 **socket 缓冲区**，cpu 会参与拷贝

4. 接下来要向网卡写数据，这项能力 java 又不具备，因此又得从**用户态**切换至**内核态**，调用操作系统的写能力，使用 DMA 将 **socket 缓冲区**的数据写入网卡，不会使用 cpu



可以看到中间环节较多，java 的 IO 实际不是物理设备级别的读写，而是缓存的复制，底层的真正读写是操作系统来完成的

* 用户态与内核态的切换发生了 3 次，这个操作比较重量级
* 数据拷贝了共 4 次



#### NIO 优化

通过 DirectByteBuf 

* ByteBuffer.allocate(10)  HeapByteBuffer 使用的还是 java 内存
* ByteBuffer.allocateDirect(10)  DirectByteBuffer 使用的是操作系统内存

![](https://gitee.com/super-jimwang/img/raw/master/img/20210527150711.png)

大部分步骤与优化前相同，不再赘述。唯有一点：java 可以使用 DirectByteBuf 将堆外内存映射到 jvm 内存中来直接访问使用

* 这块内存不受 jvm 垃圾回收的影响，因此内存地址固定，有助于 IO 读写
* java 中的 DirectByteBuf 对象仅维护了此内存的虚引用，内存回收分成两步
  * DirectByteBuf 对象被垃圾回收，将虚引用加入引用队列
  * 通过专门线程访问引用队列，根据虚引用释放堆外内存
* 减少了一次数据拷贝，用户态与内核态的切换次数没有减少



进一步优化（底层采用了 linux 2.1 后提供的 sendFile 方法），java 中对应着两个 channel 调用 transferTo/transferFrom 方法拷贝数据

![](https://gitee.com/super-jimwang/img/raw/master/img/20210527150715.png)

1. java 调用 transferTo 方法后，要从 java 程序的**用户态**切换至**内核态**，使用 DMA将数据读入**内核缓冲区**，不会使用 cpu
2. 数据从**内核缓冲区**传输到 **socket 缓冲区**，cpu 会参与拷贝
3. 最后使用 DMA 将 **socket 缓冲区**的数据写入网卡，不会使用 cpu

可以看到

* 只发生了一次用户态与内核态的切换
* 数据拷贝了 3 次



进一步优化（linux 2.4）

![](https://gitee.com/super-jimwang/img/raw/master/img/20210527150719.png)

1. java 调用 transferTo 方法后，要从 java 程序的**用户态**切换至**内核态**，使用 DMA将数据读入**内核缓冲区**，不会使用 cpu
2. 只会将一些 offset 和 length 信息拷入 **socket 缓冲区**，几乎无消耗
3. 使用 DMA 将 **内核缓冲区**的数据写入网卡，不会使用 cpu

整个过程仅只发生了一次用户态与内核态的切换，数据拷贝了 2 次。所谓的【零拷贝】，并不是真正无拷贝，而是在不会拷贝重复数据到 jvm 内存中，零拷贝的优点有

* 更少的用户态与内核态的切换
* 不利用 cpu 计算，减少 cpu 缓存伪共享
* 零拷贝适合小文件传输



# 进程线程间的通信方式

## 为什么进程间需要通信

进程是一个独立的资源分配单元，不同进程（这里所说的进程通常指的是用户进程）之间的资源是独立的，没有关联，不能在一个进程中直接访问另一个进程的资源（例如打开的文件描述符）。

**进程间通信的目的：**

- 数据传输：一个进程需要将它的数据发送给另一个进程。
- 通知事件：一个进程需要向另一个或一组进程发送消息，通知它（它们）发生了某种事件（如进程终止时要通知父进程）。
- 资源共享：多个进程之间共享同样的资源。为了做到这一点，需要内核提供互斥和同步机制。
- 进程控制：有些进程希望完全控制另一个进程的执行（如 Debug 进程），此时控制进程希望能够拦截另一个进程的所有陷入和异常，并能够及时知道它的状态改变。



## 进程间通信的方式

### 管道

管道包括三种:

- 普通管道PIPE：      通常有两种限制,一是单工==（只能一个方向传输）==,只能单向传输;二是只能在父子或者兄弟进程间使用.
- 流管道s_pipe:       去除了第一种限制,为半双工==（可以两个方向传输，但是不能同时传输）==，只能在父子或兄弟进程间使用，可以双向传输.
- 命名管道:name_pipe：去除了第二种限制,可以在许多**并不相关的进程**之间进行通讯.



常见的linux命令“|“是匿名管道，普通管道的一种。单工，并且只能在父子或者兄弟进程间使用。

通过mkfifo可以创建命名管道。

```
mkfifo pipe
打开两个终端
shell1 : echo 'golang' > pipe
shell2 : cat < pipe
```

但是这个是==半双工==，不能同时两个方向传输的。



管道都是将数据写了在内核中的缓存，读取也需要通过内核。另外==遵循先进先出原则==。



### 信号量

- 信号量是一个计数器，可以用来控制多个进程对共享资源的访问。
- 它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。
- 因此，主要作为进程间以及同一进程内不同线程之间的同步手段。



**信号量不仅可以实现访问的互斥性，还可以实现进程间的同步**，信号量其实是一个计数器，表示的是资源个数，其值可以通过两个原子操作来控制，分别是 **P 操作和 V 操作**。



### 消息队列

- 消息队列是由消息的链表，存放在==内核==中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

消息队列提供了一种从一个进程向另一个进程发送一个数据块的方法。每个数据块被认为含有一个类型，接收进程可以独立地接收含有不同类型的数据结构。我们可以通过发送消息来避免命名管道的同步和阻塞问题。但是消息队列与命名管道一样，每个数据块都有一个最大长度的限制。

使用消息队列进行进程间通信，可能会受到数据块最大长度的限制约束等，消息队列通信的速度不是最及时的，毕竟**每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程**。如果频繁的发生进程间的通信行为，那么进程需要频繁地读取队列中的数据到内存，相当于间接地从一个进程拷贝到另一个进程，这需要花费时间。

  **1、消息队列的特点**

  **(1)消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识.
  (2)==消息队列允许一个或多个进程向它写入与读取消息.==
  (3)管道和命名管道都是通信数据都是先进先出的原则。
  (4)==消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比FIFO更有优势。==**



### 信号

信号是进程间通信机制中**唯一的异步通信机制**，信号可以在应用进程和内核之间直接交互，内核也可以利用信号来通知用户空间的进程发生了哪些系统事件，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令），一旦有信号发生，**进程有三种方式响应信号 1. 执行默认操作、2. 捕捉信号、3. 忽略信号**。有两个信号是应用进程无法捕捉和忽略的，即 `SIGKILL` 和 `SEGSTOP`，这是为了方便我们能在任何时候结束或停止某个进程。



### 共享内存

共享内存这个通信方式就可以很好着解决拷贝所消耗的时间了。==系统加载一个进程的时候，分配给进程的内存并不是实际物理内存，而是虚拟内存空间。那么我们可以让两个进程各自拿出一块虚拟地址空间来，然后映射到相同的物理内存中==，这样，两个进程虽然有着独立的虚拟内存空间，但有一部分却是映射到相同的物理内存，这就完成了内存共享机制了。就像访问进程自己的空间一样快捷方便，不需要陷入内核态或者系统调用，大大提高了通信的速度，享有**最快**的进程间通信方式之名。但是便捷高效的共享内存通信，**带来新的问题，==多进程竞争同个共享资源会造成数据的错乱==。**

如何解决进程竞争问题？ ==进程互斥==

### 套接字( socket ) 

如果**要与不同主机的进程间通信，那么就需要 Socket 通信了**。Socket 实际上不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信，可根据创建 Socket 的类型不同，分为三种常见的通信方式，==一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式==。



## 线程间通信方法

同个进程下的线程之间都是共享进程的资源，只要是共享变量都可以做到线程间通信，比如全局变量，所以对于线程间关注的不是通信方式，而是关注多线程竞争共享资源的问题，信号量也同样可以在线程间实现互斥与同步：



- 互斥的方式，可保证任意时刻只有一个线程访问共享资源；
- 同步的方式，可保证线程 A 应在线程 B 之前执行；



1. volatile
2. 等待/通知机制
3. join方式
4. threadLocal
  

# 进程同步与进程互斥

## 进程互斥

进程互斥也称为间接制约关系，进程间对临界资源的访问，必须是互斥的执行。指一个进程进入临界区访问临界资源的时候，其他进程只能等待。

```
do {
    entry section;  // 进入区 检查是否可以进入临界区，可以进入，设置访问临界资源的标志，防止其他进程进入
    critical section; // 临界区  访问临界资源的代码
    exit section;    // 退出区  负责解除临界资源访问标志
    reemainder section; // 剩余区  其他处理
} while(true);
```



### 进程互斥的原则

为了实现对临界资源的互斥访问，同时保证系统的整体性能，需要遵循以下的原则：

- 空闲让进：临界区空闲的时候，可以允许一个请求进入临界区的进程立即进入临界区
- 忙则等待：当已有进程进入临界区时，其他试图进入临界区的进程必须等待
- 有限等待：想要访问的进程，应保证能在有限时间内进入临界区（保证不会饥饿）
- 让权等待：当进程不能进入临界区时，应当立即释放处理机，防止进程忙等待

### 四种进程互斥的软件实现

#### 单标志法

![image-20210206145713137](https://gitee.com/super-jimwang/img/raw/master/img/20210206145713.png)

 在进入临界区之前做检查。可能发生的事情就是turn==1，而p0进程一直不进入临界区。不符合**空闲让进原则**



#### 双标志先检查

![image-20210206145806437](https://gitee.com/super-jimwang/img/raw/master/img/20210206145806.png)

通过bool数组记录线程想要进入临界区的意愿

可能出现的问题：flag[0]和flag[1]同时为false，两个线程同时进入了临界区。不符合**忙则等待原则**



#### 双标志后检查

![image-20210206150345015](https://gitee.com/super-jimwang/img/raw/master/img/20210206150345.png)

先加锁，后检查。

可能出现的问题：两边同时加锁，不遵循**空闲让进，有限等待**，可能出现饥饿



#### Peterson算法

![image-20210206150449086](https://gitee.com/super-jimwang/img/raw/master/img/20210206150449.png)

flag用来表示想进临界区的意愿，turn表示谁先进。如果此时flag[1]是true，并且turn==1.说明P1线程想进，并且他可以先进。那么p1就先进，p0线程在while循环

会发生的问题：不遵循**让权等待**，会发生忙则等待。P0不能进入临界区，但是由于要while循环检测，不能放弃cpu



### 进程互斥的硬件实现方式

#### 中断屏蔽

利用“开关中断指令”实现（同原语的思想），在某个进程访问临界区 到 临界区访问结束 都不允许被中断，也就是不能发生进程的切换。

关中断 -->  临界区  -->  开中断



优点：简单高效

缺点：**不适用于多处理机系统**（一个处理机关中断，不会影响其他处理机对临界区的访问）。**只适合于操作系统内核进程，不适用于用户进程**。（开关中断属于特权指令）



#### TestAndSet(TS\TSL指令)

TSL指令由硬件实现，执行过程不允许被中断。

![image-20210206150954517](https://gitee.com/super-jimwang/img/raw/master/img/20210206150954.png)

如果临界区被使用lock的值就是true，old=true，就会一直是true，进程一直在等待。反之，lock是false，就会返回false，停止阻塞，并且在返回之前lock也已经被重新上锁。

**适用于多处理环境。不满足让权等待。**一样的问题，等待中，会一直while循环



#### Swap指令(XCHG指令)

Swap指令由硬件实现，执行过程不允许被中断。

![image-20210206151211192](https://gitee.com/super-jimwang/img/raw/master/img/20210206151211.png)

他有TSL类似，循环等到lock释放的时候

**适用于多处理环境。不满足让权等待。**

## 信号量机制及实现进程同步、互斥

进程互斥的四种软件实现方式和三种硬件方式都不能做到让权等待

可以通过使用信号量机制来解决。

### 数值信号量

![image-20210206151418135](https://gitee.com/super-jimwang/img/raw/master/img/20210206151418.png)

### 记录型信号量

```
//记录型信号量定义
typedef struct {
	int value;   // 剩余资源数
    struct process *L; // 等待队列
} semaphore;
// 进程需要使用资源时，通过wait原语申请
void wait(semaphore S) {
	S.value--;
    if (S.value < 0) {
    	block(S.L); // 如果资源数量不足，就将等待队列里的都放入阻塞态
    }
}
// 进程使用完成资源后，使用signal原语释放
void signal(semaphore S) {
	S.value++;
    if (S.value <= 0) {
    	wakeup(S.L); // 资源又有了，就唤醒
    }
}
```

- 如果剩余的资源数不够，**使用block原语使进程从运行态进入到阻塞态，并把挂到信号量S的等待队列。**
- 释放资源之后，若还有别的进程等待这种资源，则**使用wakeup原语唤醒等待队列中的一个进程**，该进程从阻塞转为就绪态。

实现了让权等待。

### 信号量实现互斥

```
/*信号量机制实现互斥*/
semaphore mutex = 1;  // 初始化信号量，也就是锁

P1() {
    P(mutex); // 使用临界资源，加锁
    /*临界区代码*/
    V(mutex); // 使用完毕，释放锁
}

P2() {
    P(mutex); // 使用临界资源，加锁
    /*临界区代码*/
    V(mutex); // 使用完毕，释放锁
}
```

**互斥信号量mutex，初始值为1**，说明该临界区，同时只能有一个进程访问。

注意：对于不同的临界区资源需要设置不同的互斥信号量。P、V操作必须成对出现。缺少P操作就不能对邻接资源互斥访问，缺少V操作，就会导致资源永远都不会释放，等待进程永不会被唤醒。



### 信号量实现同步

```
*信号量机制实现同步*/
semaphore S = 0;  // 初始化信号量

P1() {
    //代码1
    //代码2
    V(S);
    //代码3
}

P2() {
    P(S);
    //代码4
    //代码5
    //代码6
}
```

如果P2线执行，P需要消耗信号量，而此时是0，因此阻塞等待。P1执行完代码2，执行好V，S++后才会唤醒P2进程。

# 进程调度的时机、切换与过程、方式

## 进程调度的时机

### 需要进行进程调度与切换的情况

1. 当前运行的进程**主动放弃**处理器
   - 如（1.进程正常终止。2.运行过程中发生异常而终止。3.进程主动请求阻塞（如等待I/O））
2. 当前运行的进程**被动放弃**处理器
   - 如（1.分给进程的时间片用完了。2.有更紧急的事要要处理（如I/O中断）。3.有更高优先级的进程加入阻塞队列）



### 不需要进行进程调度与切换的情况

1. 在处理中断的过程中，中断的处理过程复杂，与硬件密切相关，很难做到中断处理过程中进行进程切换。
2. 进程在操作系统内核程序临界区中
3. 在原子操作过程中，原子操作是不可中断的（比如修改PCB中进程状态标识位）



## 进程的切换与过程

**“狭义的进程调度”**：从就绪队列中选一个要运行的进程

**进程切换**：一个进程让出处理机，由另一个进程占用处理机的过程

**广义的进程调度**：包含进程的选择和进程切换两个过程



**==进程切换过程==：**

1. 对原来运行的进程的各种数据进行保存
2. 对新进程各种数据进行恢复

（包括：程序计数器、程序状态字、各种数据寄存器等处理机现场信息，这些信息一般存储在进程控制块PCB中）



注意：**进程的切换是有代价的**，因此过于频繁的进行进程的调度、切换，必然会使整个**系统的效率降低**，使系统大部分时间都花在了进程切换上，真正的执行过程的时间减少。

## 进程调度的方式

**非剥夺调度方式**，又称为**非抢占式式**。即，允许进程主动放弃处理机。在运行过程中即便有更紧迫的任务送达，当前进程依旧会继续拥有处理机，直到进程终止或主动要求进入阻塞态。



实现起来，系统开销比较小但是无法及时处理紧急任务，适合于早起的批处理系统。



**剥夺调度方式**，又称为**抢占式式**。即，当一个进程正在处理机上运行的时候，如果有一个更重要更紧急的进程需要使用处理机，则立即暂停正在进行的进程，将处理机分配给更重要的紧迫的进程。



可以实现处理更加紧急的进程，也可以实现让各个进程按时间片轮流执行的功能（通过时钟中断）。适合于分时系统、实时系统。

# 进程的状态与转换、控制

![image-20210130211813256](https://gitee.com/super-jimwang/img/raw/master/img/20210130211813.png)

运行状态下：CPU和资源都用到了

就绪状态下：资源准备好了，但是还没分到CPU

阻塞状态下：资源和CPU都没有

运行、就绪、阻塞态是进程的三种基本状态

![image-20210130211919241](https://gitee.com/super-jimwang/img/raw/master/img/20210130211919.png)

==**运行态-》阻塞态是一个进程自身作出的主动行为**==

==**阻塞态-〉就绪态是被动行为**==

# 进程的定义、组成、组织方式和特征

## 定义

1. 进程是程序的一次执行
2. 进程是可以和别的计算并行执行
3. 进程是程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位



## 组成

![image-20210130210238471](https://gitee.com/super-jimwang/img/raw/master/img/20210130210238.png)

进程由**PCB、程序段、数据段**组成。

其中PCB是系统为每一个程序分配的一个数据结构，称为进程控制块（PCB），用来描述进程的各种信息（如程序代码的存放位置），操作系统通过PCB来管理进程，因此PCB中包含着操作系统管理进程的各种信息。



**创建进程就是创建进程实体中的PCB，而撤销进程就是删除PCB**

==**注意：PCB是进程存在的唯一标示**==



### PCB

![image-20210130210712584](https://gitee.com/super-jimwang/img/raw/master/img/20210130210712.png)

## 组织方式

操作系统中有成百上千个PCB，进程的组织方式有两种：

- 链接方式：按照进程的状态将PCB分为多个队列，操作系统持有指向各个队列的指针。
- 索引方式：根据进程状态的不同，建立几张索引表，操作系统持有指向各个索引的指针。



## 特征

1. 动态性：进程的实质是程序的一次执行过程，进程是动态产生，动态消亡的。
2. 并发性：任何进程都可以同其他进程一起并发执行。
3. 独立性：进程是一个能独立运行的基本单位，同时也是系统分配资源和调度的独立单位。
4. 异步性：由于进程间的相互制约，使进程具有执行的间断性，即进程按各自独立的、不可预知的速度向前推进。

# 挂起与阻塞

## 阻塞

线程在运行的过程中因为某些原因而发生阻塞，阻塞状态的线程特点是：==**该线程放弃CPU的使用，暂停运行，只有等导致阻塞的原因消除后才恢复，或者被其他线程中断阻塞，抛出异常**==

正在执行的进程暂时无法继续执行，导致进程调度，OS把处理器分配给了其他的就绪进程，那么受阻塞进程就进入了阻塞状态。

## 挂起

挂起进程在操作系统中可以定义为暂时被淘汰出内存的进程，机器的资源是有限的，在资源不足的情况下，操作系统对在内存中的程序进行合理的安排，其中有的进程被暂时调离出内存，当条件允许的时候，会被操作系统再次调回内存，重新进入等待被执行的状态即就绪态



## 相同与不同

### 相同

1. 进程都暂停执行
2. 进程都会释放cpu，涉及到上下文切换

### 不同

1. 虽然都释放cpu，阻塞的进程会一直在内存内，而挂起的会通过中级调度，被置换到外存
2. 发生时机不同：==阻塞一般在进程等待资源（IO资源、信号量等）时发生==；而==挂起是由于用户和系统的需要==，例如，终端用户需要暂停程序研究其执行情况或对其进行修改、OS为了提高内存利用率需要将暂时不能运行的进程（处于就绪或阻塞队列的进程）调出到磁盘 

3. 恢复时机不同：阻塞要在等待的资源得到满足后，才会进入就绪状态。被挂起的进程需要由挂起对象将其主动激活。


# 调度算法

## 调度算法的评价指标

cpu利用率 = 忙碌时间 / 总时间

系统吞吐量 = 总完成作业 / 总时间，单位时间内完成作业数量

周转时间 = 作业完成时间 - 作业到达时间，包含各种等待时间

等待时间 = 进程建立之后等待到被服务的时间之和 + 在外存后备队列等待时间（进行时等待IO不算）

响应时间 = 用户提交请求到首次产生响应的时间

## 调度算法

### 先来先服务FCFS

既可以用于作业调度、也可以用于进程调度

**算法思想：**

从公平的角度考虑，先到达后备队列的顺序，依次调度。**优先选择等待时间最长的作业为其服务**

用于作业调度时，考虑是哪个作业先到达后备队列；用于进程调度时，考虑哪个进程先到达就绪队列。



**是否抢占：**

非抢占式算法



**优缺点：**

优点：公平、算法实现简单

缺点：排在长作业（进程）后面的短作业需要等待很长的时间，带权周转时间很大，对短作业来说用户体验不好。即FCFS算法对长作业有利，对短作业不利。

不会出现饥饿现象。饥饿是指某个进程、作业长期得不到服务。

---

### 短作业优先 SJF

既可以用于作业调度、也可以用于进程调度。

对于进程调度来说称为**短进程优先（SPF）**



**算法思想：**

追求更少的平均等待时间，最少的平均周转时间，最少的平均带权周转时间。所谓“最短”，是指要求服务时间最短。**优先选择执行时间最短的作业为其服务。**

既可以用于作业调度，也可以用于进程调度。用于进程调度时称为短进程优先（shortest process first）



**是否抢占：**

SJF（短作业）和SPF（短进程）都是非抢占式算法。但是也有抢占式的版本--**最短剩余时间优先算法（SRTN）。**在SRTN算法中，每当有进程进入就绪队列改变时就需要调度，如果新到达的进程剩余时间比当前进程更短，则由新进程抢占处理机，当前进程重新回到就绪队列。



**优缺点：**

优点：较短的平均等待时间、平均周转时间

缺点：不公平。对短作业有利，对长作业不利。另外作业、进程的运行时间是由用户提供的，不一定能真正的做到短作业优先。

会出现饥饿现象。如果源源不断的有短作业/进程到来，可能会使长作业/进程长时间的得不到服务，**产生饥饿现象**。如果一直得不到服务，**会饿死**。

---

### 高响应比优先 HRRN

既可以用于作业调度、也可以用于进程调度。



**算法思想：**

综合考虑等待时间和要求服务时间

算法规则：在每次进程调度时，计算响应比 = ==**(等待时间+要求服务时间) / 要求服务时间**==



**是否抢占：**

非抢占式的调度算法。只有当当前进程主动放弃cpu的时候（正常、异常完成，或主动阻塞），才需要进行调度，调度时计算所有就绪进程的响应比，选响应比最高的进程上处理机。



**优缺点：**

优点：综合考虑了等待时间和运行时间，**等待时间相同时，要求服务时间短的优先（SJF优点）；要求服务时间相同时，等待时间长的优先（FCFS优点）。**

缺点：对于长作业来说，随着等待时间越来越久，其响应比也会越来越大，从而避免了长作业饥饿的问题。



不会导致饥饿。

---

### 时间片轮转 RR

上面的三种算法一般适用于早期的批处理系统。

RR只用于进程调度，只有作业放入内存建立了相应的进程之后，才能被分配时间片。



**算法思想：**

时间片轮转调度算法一般用于分时系统。更注重响应时间。公平的轮流的为各个进程服务，让每个进程在一定时间间隔内都可以得到相应。



**算法规则：**

按照进程到达就绪队列的顺序，轮流的让各个进程执行一个时间片。若进程未在一个时间片内执行完，则剥夺处理机，重新进入就绪队列排队。



**是否抢占：**

若进程未在一个时间片时间间隔内完成，将被剥夺处理机使用权，因此时间片轮转算法属于**抢占式算法**。由时钟装置发出时钟中断来通知cpu时间片已到。



**优缺点：**

优点：公平，响应快

缺点：**由于高频率的进程切换，有一定的开销。不能区分任务的紧急程度。**

**如果时间片太大，会使得每个进程都可以在一个时间片内完成，则时间片轮转调度退化为先来先服务调度算法，并且会大大增加进程响应时间。**

**如果时间片太小，进程频繁的切换会导致系统花费大量的时间来处理切换，进程的调度切换是有代价的。从而导致进程执行的时间比例减少。**

不会导致饥饿

---

### 优先级调度算法

既可以用于作业调度也可以用于进程调度。

优先级分为动态优先级和静态优先级。



**算法思想：**

优先处理优先级高的作业、进程。如IO相关的进程优先级更高，系统进程优先级更高。



**是否抢占：**

抢占式、非抢占式都有。

非抢占式在进程主动放弃处理机是进行调度。

抢占式的优先级调度算法：每次调度时选择当前已到达且优先级较高的进程。除了当前进程主动放弃处理机时发生调度之外，当**就绪队列发生改变也会检查是否发生抢占而调度。**



**优缺点：**

优点：用于优先级区分紧急程度、重要程度，适用于实时操作系统。

缺点：若有源源不断的高优先级作业进程到来，可能会导致饥饿。

---

### 多级反馈队列调度算法

![image-20210204152628296](https://gitee.com/super-jimwang/img/raw/master/img/20210204152628.png)

**流程及规则：**

设置多级就绪队列，各级队列优先级从高到低，时间片从小到大。

新进程到达时**优先进入第1级队列**，按照FCFS原则，排队等待时间片分配。若用完时间片进程**未结束**，则进程**进入下一级队列的队尾**。如果此时已经在**最下级**的队列，则**重新放回最下级队列队尾**。

**只有第k级队列为空时，才会为k+1级队头的进程分配时间片。**

被抢占的处理机进程重新放回**原队列队尾**。

随着队列级别增加，时间片分配会越来越大。

只能用于进程调度。



**是否抢占？**

抢占式的算法。在第k级队列的进程运行的过程中，若更上级的队列(1~k-1)中进入了一个新的进程，则由新进程处于优先级更高的队列，因此新进程会抢占处理机，原来运行的进程放入k级队列的队尾。



**优缺点：**

优点：各类型的进程相对公平（FCFS优点）；每个进程到达都可很快的响应（RR优点）；短进程只用较少的时间就可以处理完成（SPF优点）；

可以灵活地对各类进程的偏好程度，比如CPU密集型进程、IO密集型进程（将IO阻塞的进程放到原队列队尾，这样使IO进程处于较高优先级）。

缺点：会发生饥饿。

# 协程
## 为什么需要协程
因为线程直接的切换需要内核中的TCB(Thread Control Block)来改变状态。

需要用户态到内核态的转换。

当设计多线程并发的时候，会涉及到同步锁、线程切换等操作，效率低。

## 协程是什么

比线程更轻量级的存在，一个线程有多个协程。

==最重要的是，协程不是被操作系统内核所管理，而完全是由程序所控制（也就是在用户态执行）。==

协程暂停和线程的阻塞是有本质区别的。协程的暂停完全由程序控制，线程的阻塞状态是由操作系统内核来进行切换。

==协程并没有增加线程数量，只是在线程的基础之上通过分时复用的方式运行多个协程，而且协程的切换在用户态完成，切换的代价比线程从用户态到内核态的代价小很多。==

