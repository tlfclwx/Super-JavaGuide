[toc]

# redis
> redis数据存在哪，是单线程的吗，为什么快

redis数据存在内存中，是单线程的。之所以快是因为它性能瓶颈不是cpu，而是内存和网络。所以多线程并没有必要

> redis除了做缓存还能用来做什么

分布式锁 消息队列等

> redis和memcache的区别

共同点
- 都是基于内存的数据库，都是用来做缓存的
- 都有过期策略
- 性能都很高

不同点
- redis有很多种数据类型，memcache只支持k/v
- redis支持数据的持久化
- redis有灾难恢复机制
- redis在服务器内存使用完之后，可以将不用的数据放到磁盘上
- memcache没有原生的集群
- memcache是多线程，非阻塞IO复用的网络模型。redis是单线程的多路复用模型（同步非阻塞 Reactor）
- Memcache只有惰性删除，redis有惰性删除和定期删除

> 如何查询缓存数据
- 在缓存中搜索，如果有就直接返回
- 缓存中没有，就去数据库中找
- 如果在数据库中找到了，就在缓存中更新，并返回
- 如果数据库也没有，返回空

> redis常见的数据类型

- String
  - 就是k/v对
  - 一般用于计数，存用户的访问次数
- list
  - 链表，是用双向链表实现的
  - 可以操作的就是lpop,lpush,rpop,rpush
  - 可以用来做消息队列
- hash
  - 类似hashmap
  - 内部实现也差不多就是数组+链表
  - 适合用于存储对象
- set
  - set类似于java中的hashset
  - 存放不重复的数据
- sortSet
  - 有序的set
  - 多了一个score权重，根据score进行排序

> redis需要处理哪些事件

两种事件，文件事件和时间事件。文件事件是最主要的

**文件事件**
- 文件事件处理器使用I/O多路复用(multiplexing)程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器；
- 当被监听的套接字准备好执行连接应答(accept)、读取(read)、写入(write)、关闭(close)等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的时间处理器来处理这些事件；

> redis是单线程的，是怎么做到监听大量的客户端链接的

redis通过IO多路复用来监听多个socket，将感兴趣的事件注册到内核中的Reactor中。

> redis为什么不用多线程

- 单线程编程和维护都比较容易
- redis性能瓶颈不是cpu，而是内存和网络
- 多线程会存在死锁、线程上下文切换的问题，可能会影响性能

> redis6.0后为什么引入多线程

引入多线程是为了提高网络IO读写性能

> redis设置过期时间有什么用

因为内存有限

> redis是如何判断数据是否过期

redis有一个过期字典，这个字典的key指向redis数据库中的某个key，值是一个long long类型的证书，表示过期时间

> redis过期删除策略说一下

惰性删除：只会在取出key的时候判断是否过期

定期删除：每隔一段时间抽取一批key执行删除过期key操作

redis采用定期删除+惰性删除

> redis内存淘汰机制讲一下

- volatile-lru:从已设置过期时间的数据集中挑选最久未使用的数据淘汰
- volatile-ttl:从已设置过期时间的数据集中挑选即将过期的数据淘汰
- volatile-random:从已设置过期时间的数据集中任意选择数据淘汰
- allkeys-lru:从所有键值对中挑选最久未使用的数据淘汰
- allkeys-random:从所有键值对中随机挑选淘汰
- no-eviction:不淘汰
- volatile-lfu:从已设置过期时间的数据集中挑选最不经常使用的数据淘汰
- allkeys-lfu:在所有键值对中挑选不经常使用的key删除

> redis持久化机制讲一下

RDB快照，AOF只追加文件

RDB：
通过创建快照来获得存储在内存里面的数据在某个时间点上的副本
快照持久化是redis默认的持久化方式

AOF：
AOF实时性更好，每执行一条更改redis中数据的命令，redis就会将该命令写入磁盘中的AOF文件

> 什么是缓存穿透，以及如何解决

大量请求的key不存在缓存中，并且数据库中也不存在。这种一般是被攻击了

解决：
缓存无效key：在redis中缓存一些无效的key
布隆过滤器：把所有可能的请求值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。如果不存在请求参数错误信息给客户端，存在的话就先去缓存找，然后再去数据库找。

> 讲一下布隆过滤器，布隆过滤器会发生错误吗

布隆过滤器会对元素值使用多个哈希函数进行计算，然后在位数组中，把这些哈希值标为1（注意，是多个哈希结果）

当判断是否存在的时候，会进行以下操作：
- 给定元素进行计算哈希
- 对位数组中对应哈希位置是否都为1，如果都是1，则认为存在。

会发生错误，可能把不存在的认为存在，但是不会把存在的认为不存在。

> 讲一下缓存击穿

这是并发访问同一个数据时，缓存过期了，访问直接落到了数据库中

与缓存雪崩的不同是，这边是并发访问同一个数据，而雪崩是大面积的数据过期

> 讲一下缓存雪崩

缓存在同一时间大面积的失效，后面的请求都直接的落到了数据库上，导致数据库短时间内请求量过大。

一个场景就是：一个热门缓存在某个时间大面积失效，导致对应的请求落到了数据库

> 讲一下缓存雪崩的解决方法

- 采用redis集群，避免单机出问题
- 限流，避免处理大量请求
- 设置不同的失效时间
- 缓存用不失效
- 提前缓存

> 有了删除策略为什么还需要有淘汰策略

因为删除策略的惰性策略是用到才比较是否过期，而定时策略是选一批执行删除。所以还有很多的数据是被漏掉的。

> redis事务期间报错了会全部回滚吗？

看情况。如果是编译期因为语法错误异常，什么都不执行。如果是运行期，那么运行了的语句不回滚。

> redis底层的数据结构说一下

- string
  - 是用一个sds（simple dynamic string）结构体实现的
  ```c
  struct sdshdr{
     //记录buf数组中已使用字节的数量
     //等于 SDS 保存字符串的长度
     int len;
     //记录 buf 数组中未使用字节的数量
     int free;
     //字节数组，用于保存字符串
     char buf[];
  }
  ```
  - 优点
    - 不必担心字符串变更造成的内存溢出问题。会先根据len判断是否会溢出，然后做空间扩展
    - 常数复杂度获取字符串长度，因为记录了len。而C语言自己的字符串要获取长度需要遍历
    - 因为有free，提前分配了一定的空间，可以防止多次重新分配内存。
- 链表list
  - ![](https://gitee.com/super-jimwang/img/raw/master/img/20210314090228.png)
  - Redis的链表在双向链表上扩展了头、尾节点、元素数等属性。
  ```c
  typedef  struct listNode{
       //前置节点
       struct listNode *prev;
       //后置节点
       struct listNode *next;
       //节点的值
       void *value;  
  }listNode
  typedef struct list{
     //表头节点
     listNode *head;
     //表尾节点
     listNode *tail;
     //链表所包含的节点数量
     unsigned long len;
     //节点值复制函数
     void (*dup) (void *ptr);
     //节点值释放函数
     void (*free) (void *ptr);
     //节点值对比函数
     int (*match) (void *ptr,void *key);
  }list;
  ```
  - 优点：
    - 可以直接获得头、尾节点
    - 常数时间就能获得链表长度
    - 双向链表
- hash
  - ![](https://gitee.com/super-jimwang/img/raw/master/img/20210314090300.png)
  ```c
  typedef struct dict {
    // 类型特定函数
    dictType *type;
    // 私有数据
    void *privdata;
    // 哈希表 存了两个用于rehash用
    dictht ht[2];
    // rehash 索引
    // 当 rehash 不在进行时，值为 -1
    int rehashidx; /* rehashing not in progress if rehashidx == -1 */
  } dict;
  typedef struct dictht {
    // 哈希表数组
    dictEntry **table;
    // 哈希表大小
    unsigned long size;
    // 哈希表大小掩码，用于计算索引值
    // 总是等于 size - 1
    unsigned long sizemask;
    // 该哈希表已有节点的数量
    unsigned long used;
  } dictht;
  typedef struct dictEntry {
    // 键
    void *key;
    // 值
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
    } v;
    // 指向下个哈希表节点，形成链表
    struct dictEntry *next;  // 单链表结构
  } dictEntry;
  ```
  - Reids的Hash采用链地址法来处理冲突，然后它没有使用红黑树优化。
  - 哈希表节点采用单链表结构。
  - rehash优化。把一个哈希表中的数据rehash到另一个表中。扩容触发条件：根据负载因子判断
- 跳表
  - ![](https://gitee.com/super-jimwang/img/raw/master/img/20210306215532.png)
  - ①、搜索：从最高层的链表节点开始，如果比当前节点要大和比当前层的下一个节点要小，那么则往下找，也就是和当前层的下一层的节点的下一个节点进行比较，以此类推，一直找到最底层的最后一个节点，如果找到则返回，反之则返回空。
  - ②、插入：首先确定插入的层数，有一种方法是假设抛一枚硬币，如果是正面就累加，直到遇见反面为止，最后记录正面的次数作为插入的层数。当确定插入的层数k后，则需要将新元素插入到从底层到k层。
  - ③、删除：在各个层中找到包含指定值的节点，然后将节点从链表中删除即可，如果删除以后只剩下头尾两个节点，则删除这一层。
- intset整数集合
  - Reids对整数存储专门作了优化，intset就是redis用于保存整数值的集合数据结构。当一个结合中只包含整数元素，redis就会用这个来存储。
  ```c
  typedef struct intset {
 
    // 编码方式
    uint32_t encoding;
 
    // 集合包含的元素数量
    uint32_t length;
 
    // 保存元素的数组
    int8_t contents[];

  } intset;
  ```
  - encoding字段用来说明contents的类型。可以为int16_t, int32_t, int64_t。支持encoding升级，不支持降级
- 压缩列表
  - 压缩列表的原理：压缩列表并不是对数据利用某种算法进行压缩，而是将数据按照一定规则编码在一块连续的内存区域，目的是节省内存。
- 快速链表 quicklist

> redis中的hash如何rehash

为ht[1]分配空间，同时持有两个哈希表(一个空表、一个有数据)。
维持一个技术器rehashidx，初始值0。
每次对字典增删改查，会顺带将ht[0]中的数据迁移到ht[1],rehashidx++(注意：ht[0]中的数据是只减不增的)。
直到rehash操作完成，rehashidx值设为-1。
它的好处：采用分而治之的思想，将庞大的迁移工作量划分到每一次CURD中，避免了服务繁忙。

> rdb的触发时机

1. 自动触发
   - 通过在配置文件中配置 save 900 1表示900秒内有1个key变了就触发
2. 手动触发
   - save命令。会阻塞redis，redis不能处理其他指令，直到rdb完成
   - bgsave命令。后台异步快照操作

> rdb如何实现

bgsave：

父进程fork一个子进程，它们的虚拟内存会指向同一个物理地址，共享内存。这时候父进程会继续处理client请求，进行写时复制操作，如果有新数据要写，那么就会创建一个内存页面的副本，继续修改。而子进程将内存中的内容写入临时RDB文件，快照写入完成后，替换原来的快照文件，然后子进程退出。
![redis2](https://gitee.com/super-jimwang/img/raw/master/img/20210315200954.png)

> aof如何实现

AOF持久化功能的实现可以分为命令追加、文件写入、文件同步三个步骤。

命令追加：

当AOF持久化功能打开时，服务器在执行完一个写命令之后，会以协议格式将被执行的写命令追加到服务器状态的aof_buf缓冲区的末尾。

AOF文件的写入与同步：

每当服务器常规任务函数被执行、 或者事件处理器被执行时， aof.c/flushAppendOnlyFile 函数都会被调用， 这个函数执行以下两个工作：
- WRITE：根据条件，将 aof_buf 中的缓存写入到 AOF 文件。
- SAVE：根据条件，调用 fsync 或 fdatasync 函数，将 AOF 文件保存到磁盘中。

两个步骤都需要根据一定的条件来执行， 而这些条件由 AOF 所使用的保存模式来决定， 以下小节就来介绍 AOF 所使用的三种保存模式， 以及在这些模式下， 步骤 WRITE 和 SAVE 的调用条件。

Redis 目前支持三种 AOF 保存模式，它们分别是：

- AOF_FSYNC_NO ：不保存。
- AOF_FSYNC_EVERYSEC ：每一秒钟保存一次。
- AOF_FSYNC_ALWAYS ：每执行一个命令保存一次。


==不保存==
在这种模式下， 每次调用 flushAppendOnlyFile 函数， WRITE 都会被执行， 但 SAVE 会被略过。
在这种模式下， SAVE 只会在以下任意一种情况中被执行：
Redis 被关闭
AOF 功能被关闭
系统的写缓存被刷新（可能是缓存已经被写满，或者定期保存操作被执行）
这三种情况下的 SAVE 操作都会引起 Redis 主进程阻塞。


==每秒保存一次==
在这种模式中， SAVE 原则上每隔一秒钟就会执行一次， 因为 SAVE 操作是由后台子线程调用的， 所以它不会引起服务器主进程阻塞。
注意， 在上一句的说明里面使用了词语“原则上”， 在实际运行中， 程序在这种模式下对 fsync 或 fdatasync 的调用并不是每秒一次， 它和调用 flushAppendOnlyFile 函数时 Redis 所处的状态有关。
每当 flushAppendOnlyFile 函数被调用时， 可能会出现以下四种情况：
- 子线程正在执行 SAVE ，并且：这个 SAVE 的执行时间未超过 2 秒，那么程序直接返回，并不执行 WRITE 或新的 SAVE 。
- 这个 SAVE 已经执行超过 2 秒，那么程序执行 WRITE ，但不执行新的 SAVE 。注意，因为这时 WRITE 的写入必须等待子线程先完成（旧的） SAVE ，因此这里 WRITE 会比平时阻塞更长时间。
子线程没有在执行 SAVE ，并且：
- 上次成功执行 SAVE 距今不超过 1 秒，那么程序执行 WRITE ，但不执行 SAVE 。
- 上次成功执行 SAVE 距今已经超过 1 秒，那么程序执行 WRITE 和 SAVE 。

可以用流程图表示这四种情况：
![](https://gitee.com/super-jimwang/img/raw/master/img/20210315202433.png)

根据以上说明可以知道， 在“每一秒钟保存一次”模式下， 如果在情况 1 中发生故障停机， 那么用户最多损失小于 2 秒内所产生的所有数据。
如果在情况 2 中发生故障停机， 那么用户损失的数据是可以超过 2 秒的。

==每执行一个命令保存一次==

在这种模式下，每次执行完一个命令之后， WRITE 和 SAVE 都会被执行。
另外，因为 SAVE 是由 Redis 主进程执行的，所以在 SAVE 执行期间，主进程会被阻塞，不能接受命令请求。


> 三种aof模式的对比

![](https://gitee.com/super-jimwang/img/raw/master/img/20210315202741.png)

> 什么是aof重写

因为AOF持久化是通过保存被执行的写命令来记录数据库状态的，所以随着服务器运行时间的流逝，AOF文件中的内容越来越多，文件体积越来越大，如果不加以控制，会对redis服务器甚至宿主计算器造成影响。

考虑这样一个情况， 如果服务器对键 list 执行了以下四条命令：
```
RPUSHlist1234// [1, 2, 3, 4]
RPOPlist// [1, 2, 3]
LPOPlist// [2, 3]
LPUSHlist1// [1, 2, 3]
```
那么当前列表键 list 在数据库中的值就为 [1, 2, 3] 。

如果我们要保存这个列表的当前状态， 并且尽量减少所使用的命令数， 那么最简单的方式不是去 AOF 文件上分析前面执行的四条命令， 而是直接读取 list 键在数据库的当前值， 然后用一条 RPUSH 1 2 3 命令来代替前面的四条命令。

==aof重写操作会遍历数据库==

Redis将AOF重写程序放到子进程里执行，这样做达到两个目的：
- 子进程AOF重写期间，服务器进程可以继续处理命令请求。
- 子进程带有数据库进程的数据副本，使用子进程而不是线程，可以避免使用锁的情况下保证数据安全。

> aof重写的时候如何解决新进来的数据

子进程在进行AOF重写期间，服务器进程还要继续处理命令请求，而新的命令可能对现有的数据进行修改，这会让当前数据库的数据和重写后的AOF文件中的数据不一致。

为了解决这种数据不一致的问题，Redis增加了一个AOF重写缓存，这个缓存在fork出子进程之后开始启用，Redis服务器主进程在执行完写命令之后，会同时将这个写命令追加到AOF缓冲区和AOF重写缓冲区
即子进程在执行AOF重写时，主进程需要执行以下三个工作：
- 执行client发来的命令请求；
- 将写命令追加到现有的AOF文件中；
- 将写命令追加到AOF重写缓存中。

当子进程完成对AOF文件重写之后（==保证aof结束的那一刻，aof文件中的数据跟redis的一致性==），它会向父进程发送一个完成信号，父进程接到该完成信号之后，会调用一个信号处理函数，该函数完成以下工作：

将AOF重写缓存中的内容全部写入到新的AOF文件中；这个时候新的AOF文件所保存的数据库状态和服务器当前的数据库状态一致；
对新的AOF文件进行改名，原子的覆盖原有的AOF文件；完成新旧两个AOF文件的替换。

> aof后台重写的触发条件

- AOF重写可以由用户通过调用BGREWRITEAOF手动触发。
- 服务器在AOF功能开启的情况下，会维持以下三个变量：
  - 记录当前AOF文件大小的变量aof_current_size。
  - 记录最后一次AOF重写之后，AOF文件大小的变量aof_rewrite_base_size。
  - 增长百分比变量aof_rewrite_perc。
- 每次当serverCron（服务器周期性操作函数）函数执行时，它会检查以下条件是否全部满足，如果全部满足的话，就触发自动的AOF重写操作：
  - 没有BGSAVE命令（RDB持久化）/AOF持久化在执行；
  - 没有BGREWRITEAOF在进行；
  - 当前AOF文件大小要大于server.aof_rewrite_min_size（默认为1MB），或者在redis.conf配置了auto-aof-rewrite-min-size大小；
  - 当前AOF文件大小和最后一次重写后的大小之间的比率等于或者等于指定的增长百分比（在配置文件设置了auto-aof-rewrite-percentage参数，不设置默认为100%）

> redis如何实现io多路复用

redis利用epoll来实现IO多路复用，将连接信息和事件放到队列中，依次放到文件事件分派器，事件分派器将事件分发给事件处理器。
![](https://gitee.com/super-jimwang/img/raw/master/img/20210315205933.png)


> 为什么用redis做缓存，而不是mysql自带的缓存功能呢

1、mysql、oracle这些关系数据库自带的缓存都是对热数据进行自动存储及替换，也是用的内存空间
2、redis、memcache这类缓存系统是由开发人员自由选择数据对象，全部采用内存，也有些带持久化到磁盘存储机制

> 布隆过滤器如何更新？

由于布隆过滤器并不能保障100%准确性，所以如果说在可接受范围内，可以不更新，直接添加新的数据的hash位改为1即可。如果要更新，需要清空重建。

比如原来张三，现在叫李四，那么不需要删除张三，直接加上李四就行了。

如果出现了大规模的误判，那么就重建过滤器。