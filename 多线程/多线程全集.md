[toc]

# 多线程
> 并发和并行的区别说一下

并发：同一个时间段内，多个任务在执行（单位时间不一定一起执行）

并行：单位时间内，多个任务同时执行

> 为什么要用多线程，说一下理由，比单线程好在哪

从计算机底层来说：线程间的切换和调度的成本远小于进程。多核cpu意味着多个线程可以并行，减少了线程上下文切换的代价

从发展趋势来看：多线程是高并发的基础

对于单核来说：如果是单核，单线程，如果这个线程需要等待IO，那么此时cpu空闲，IO设备运转。而如果用两线程，一个线程等待IO的时候，另一个线程可以利用空闲的cpu

对于多核：多线程可以在不同核上跑

> 线程的生命周期

- new
  - 线程被构建，还没有使用start()
- runnable
  - 运行状态，操作系统中的就绪和运行都被称为runnable
- blocked
  - 阻塞状态，表示阻塞于锁
- waiting
  - 等待状态，等待其他线程的通知或中断
- time_waiting
  - 超时等待，在指定时间自行返回
- terminated
  - 终止状态，表示当前线程已经执行完毕

> runnable与waiting切换的调用方法 以及 runnable与timed_waiting切换的调用方法

- RUNNABLE -> WAITING
  - Object.wait()
  - Thread.join()
  - LockSupport.park()
- WAITING -> RUNNABLE
  - Object.notify()
  - Object.notifyAll()
  - LockSupport.unpark(Thread)
- RUNNABLE -> TIMED_WAITING
  - Thread.sleep(long)
  - Object.wait(long)
  - Thread.join(long)
  - LockSupport.parkNanos()
  - LockSupport.parkUntil()
- TIMED_WAITING -> RUNNABLE
  - Object.notify()
  - Object.notifyAll()
  - LockSupport.unpark()

> 什么是上下文切换

当前线程cpu时间片用完了，切换到另一个线程之前，会保存当前任务的环境，并加载下一个任务的环境，这个过程叫做切换上下文

> sleep和wait的区别

- sleep不会释放锁，wait会释放锁
- 都会暂停线程的执行
- wait通常用于线程通信，而sleep用于暂停执行
- wait被调用后，线程不会自动苏醒，需要notify。sleep会自动苏醒

> 为什么执行线程调用start方法，而不是run

调用start方法，会启动一个新的线程，并进入就绪态，当分配到了时间片，start会执行准备工作，然后执行run方法。


> 说一下如果让线程顺序执行

1. wait和notify。需要在synchronized中使用，一个线程wait了会让出锁，另一个线程获得锁并notify。
2. join方法，作用是调用线程需等待该join()线程执行完成后，才能继续用下运行。
3. 使用Condition中的await和signal。类似wait和notify
4. 信号量


> 线程T1有三个代码段，线程T2有两个代码段，线程T3必须等待T1执行完第二个代码段，T2执行完第一个代码段之后才能开始，应该怎么做？
```java
public static ReentrantLock lock = new ReentrantLock();
    public static Semaphore c1 = new Semaphore(0);
    public static Semaphore c2 = new Semaphore(0);

    public static void main(String[] args) throws InterruptedException {
        // TODO Auto-generated method stub
        Thread thread1 = new Thread() {
            @Override
            public void run() {
                lock.lock();
                System.out.println("我是线程1");
                c1.release();
                lock.unlock();
                System.out.println("线程1完毕");
            }
        };
        Thread thread2 = new Thread() {
            @Override
            public void run() {
                lock.lock();
                System.out.println("我是线程2");
                c2.release();
                lock.unlock();
                System.out.println("线程2完毕");
            }
        };
        Thread thread3 = new Thread() {
            @Override
            public void run() {
                try {
                    System.out.println("线程3开始");
                    c1.acquire();
                    c2.acquire();
                    System.out.println("条件1被唤醒");
                    System.out.println("条件2被唤醒");
                    lock.lock();
                    System.out.println("我是线程3");
                    lock.unlock();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        };
        /*
         * 通过join方法来确保t1、t2、t3的执行顺序
         * */

        thread3.start();
        thread1.start();
        thread2.start();
    }
```

> synchronized有什么用

可保证被它修饰的方法或代码块在任意时刻只能有一个线程执行

可以保证原子性、有序性和可见性

> synchronized的三种使用方法说一下

1. 修饰实例方法：进入代码块之前要获得当前对象实例的锁
2. 修饰静态方法进入同步代码块之前要获得当前class的锁。class的锁与对象的锁互不影响
3. 修饰代码块：指定加锁对象，进入代码块前要获得给定对象的锁。

> 双重校验锁实现单例模式写一个

```java
public class Singleton {
    private volatile static Singleton instance;

    private Singleton() {}

    public static Singleton getInstance() {
        if(instance==null) {
            synchronized(Singleton.class) {
                if(instance==null) {
                    instance = new Singleton();
                }
            }
        }
        return instance;
    }
}
```
注意synchronized内部还需要检查一次，因为可能会阻塞，其他线程已经new了，然后释放锁，这会再进去的时候，别人已经new好了。另外需要volatile，保证可见性以及有序性。

> synchronized的原理

jvm底层字节码调用monitorenter和monitorexit指令。表示进入了synchronized代码块，和出来了。

> wait和notify的使用要求

只能再synchronized内部使用，因为依赖monitor，synchronized会获取monitor

> Synchronized与reentrantLock的区别

底层
synchronized是jvm实现的，不需要手动的lock和unlock

ReentrantLock是通过API实现的，需要lock和unlock配合使用

可重入
两个都是可重入锁

ReentrantLock有额外的功能
- 等待可中断，中断等待锁的线程，可以放弃等待
- 可实现公平锁，先等待的线程先获得锁
- 可以设置多个条件变量，多个条件都满足了才开始竞争锁
- 可以设置锁超时

> 什么是cas操作

就是compareAndSwap，修改一个值时，先获取当前值，然后做修改的时候，比较当前值是否被修改了，如果没改，才开始做自己的修改

> 讲一下JMM。如何解决缓存不一致问题

线程可以把变量存在本地内存，而不是直接在主存中进行读写。每个线程对应一个本地内存，它是主内存的副本。因此会有数据不一致的问题。

可以通过volatile解决，强制写操作和读操作都从主存来。

==这里的本地内存也就是对应了操作系统中寄存器与主存之间的高速缓存==

![](https://gitee.com/super-jimwang/img/raw/master/img/20210410152139.png)

> synchronized和volatile的区别

- volatile是轻量级的，只能用于变量
- volatile能保证数据可见性，但是不能保证原子性，而synchronized两者都可以
- volatile主要用于解决可见性，synchronized用于解决多线程访问资源的同步问题
- volatile可以禁止指令重排，而synchronized不行，只能保证有序性。因此双重检验的单例模式即使有了synchronized还需要volatile

> synchronized是如何保证有序性的

- 因为synchronized只能一个线程进入，所以代码块内是单线程运行的，因此能保证有序性。
- as-if-serial语义：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变


> 为什么需要cpu高速缓存？和内存的关系是什么？为什么需要cpu高速缓存？

缓存是cpu和内存之间的存储器。速度比内存更快。

缓存用于解决cpu处理速度和内存不匹配的问题，缓存的是内存数据，用于解决磁盘访问太慢了的问题

> cas操作是原子的吗

是的

> 为什么线程的切换比进程的切换开销小

因为线程是进程的子集，所以线程的上下文也是进程上下文的子集，因此保存和取出更快

> ThreadLocal的原理说一下

ThreadLocal可以理解为TreadLocalMap的封装，ThreadLocal中存了ThreadLocalMap，然后根据currentThread获取对应的map，每一个map中都存了键值对，key就是ThreadLocal，不同的线程有不同的ThreadLocal。

看一下ThreadLocal中的set方法，把对象自己作为key存进map

ThreadLocalMap是一个Entry数组。Entry内是一个弱引用key和强引用value
```java
public void set(T value) {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null)
        map.set(this, value);
    else
        createMap(t, value);
}

ThreadLocalMap getMap(Thread t) {
    return t.threadLocals;
}

void createMap(Thread t, T firstValue) {
    t.threadLocals = new ThreadLocalMap(this, firstValue);
}

// 静态内部类
static class ThreadLocalMap {
        static class Entry extends WeakReference<ThreadLocal<?>> {
            /** The value associated with this ThreadLocal. */
            Object value;

            Entry(ThreadLocal<?> k, Object v) {
                super(k);
                value = v;
            }
        }

        ThreadLocalMap(ThreadLocal<?> firstKey, Object firstValue) {
            table = new Entry[INITIAL_CAPACITY];
            int i = firstKey.threadLocalHashCode & (INITIAL_CAPACITY - 1);
            table[i] = new Entry(firstKey, firstValue);
            size = 1;
            setThreshold(INITIAL_CAPACITY);
        }
}
```


ThreadLocal为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本。

> ThreadLocal的key为什么用弱引用

什么是弱引用？
==Key使用强引用：也就是上述说的情况，引用ThreadLocal的对象被回收了，ThreadLocal的引用ThreadLocalMap的Key为强引用并没有被回收，如果不手动回收的话，ThreadLocal将不会回收那么将导致内存泄漏。==
==Key使用弱引用：引用的ThreadLocal的对象被回收了，ThreadLocal的引用ThreadLocalMap的Key为弱引用，如果内存回收，那么将ThreadLocalMap的Key将会被回收，ThreadLocal也将被回收。value在ThreadLocalMap调用get、set、remove的时候就会被清除。==

> 那么在threadLocalMap调用get方法时，发生了gc，弱引用对象threadLocal是否会因为被回收掉，而get不到。

==不会，因为堆中有一个强引用在，只有在不在用threadLocal了，把这个强引用设为null后，ThreadLocalMap中的弱引用才会被回收。（看下一题的图）==

> ThreadLocal的内存泄漏问题

==首先来说，如果把ThreadLocal置为null，那么意味着Heap中的ThreadLocal实例不在有强引用指向，只有弱引用存在，因此GC是可以回收这部分空间的，也就是key是可以回收的，被回收后Entry的key为null。但是value却存在一条从Current Thread过来的强引用链。因此只有当Current Thread销毁时，value才能得到释放。==

==因此，只要这个线程对象被gc回收，就不会出现内存泄露，但在threadLocal设为null和线程结束这段时间内不会被回收的，就发生了我们认为的内存泄露。最要命的是线程对象不被回收的情况，比如使用线程池的时候，线程结束是不会销毁的，再次使用的，就可能出现内存泄露。==

==着重理解这张图==
![](https://gitee.com/super-jimwang/img/raw/master/img/20210314160741.png)

> ThreadLocalMap和HashMap的不同

hash计算方式不同，另外ThreadLocalMap解决冲突的方法是开放地址法。

# AQS和ReentrantLock
AQS使用一个int成员变量来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。

state=0的时候表示锁空闲，为1表示被占用

AQS支持两种同步方式：

　　1.独占式

　　2.共享式

> 同步器的使用

　　1.使用者继承AbstractQueuedSynchronizer并重写指定的方法。（这些重写方法很简单，无非是对于共享资源state的获取和释放）

　　2.将AQS组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。

可重写的方法包括：
protected boolean tryAcquire(int arg) : 独占式获取同步状态，试着获取，成功返回true，反之为false

　　　　protected boolean tryRelease(int arg) ：独占式释放同步状态，等待中的其他线程此时将有机会获取到同步状态；

　　　　protected int tryAcquireShared(int arg) ：共享式获取同步状态，返回值大于等于0，代表获取成功；反之获取失败；

　　　　protected boolean tryReleaseShared(int arg) ：共享式释放同步状态，成功为true，失败为false

　　　　protected boolean isHeldExclusively() ： 是否在独占模式下被线程占用。

> AQS底层原理

AQS内部有一个FIFO的队列（称为CLH队列）。该队列由一个一个的Node结点组成，每个Node结点维护一个prev引用和next引用，分别指向自己的前驱和后继结点。AQS维护两个指针，分别指向队列头部head和尾部tail。

当线程获取资源失败（比如tryAcquire时试图设置state状态失败），会被构造成一个结点加入CLH队列中，同时当前线程会被阻塞在队列中（通过LockSupport.park实现，其实是等待态）。当持有同步状态的线程释放同步状态时，会唤醒后继结点，然后此结点线程继续加入到对同步状态的争夺中。

> AQS实现公平锁和非公平锁不同的地方

公平锁和非公平锁只有两处不同：

1. 非公平锁在调用 lock 后，首先就会调用 CAS 进行一次抢锁，如果这个时候恰巧锁没有被占用，那么直接就获取到锁返回了。
2. 非公平锁在 CAS 失败后，和公平锁一样都会进入到 AQS的acquire 方法，AQS的acquire方法会调用tryAcquire，tryAcquire被ReentrantLock重写（==注意：公平锁和非公平锁的tryAcquire实现不同==），在 tryAcquire 方法中，如果发现锁这个时候被释放了（state == 0），非公平锁会直接 CAS 抢锁，但是公平锁会判断等待队列是否有线程处于等待状态，如果有则不去抢锁，乖乖排到后面。
3. 在进入队列后，阻塞前，两种锁都会判断自己是否是首节点，如果是的话，还会再抢一次锁，又失败了，才会挂起线程

公平锁和非公平锁就这两点区别，前两次 CAS 都不成功，那么后面非公平锁和公平锁是一样的，都要进入到阻塞队列等待唤醒。

==ReentrantLock内有两个内部类，NonFairSync和FairSync。两个都重写了lock方法和tryAcquire方法。非公平的在lock中会抢一次锁再调用acquire。然后在NonFairTryRequire中进入队列后，阻塞前，如果释放了锁还会抢一次，而公平锁的tryRequire中，会同时判断是否释放以及链表中有无节点。==

==ReentrantLock内非公平锁的实现==
```java
final boolean nonfairTryAcquire(int acquires) {
    final Thread current = Thread.currentThread();
    int c = getState();
    if (c == 0) {
      // 进入队列之后，不管是否有前驱，再抢一次。
      // 进入队列的代码在AQS中
      // tryAcquire返回false的话，在AQS中这个线程就会被进入阻塞态了
        if (compareAndSetState(0, acquires)) {
            setExclusiveOwnerThread(current);
            return true;
        }
    }
    else if (current == getExclusiveOwnerThread()) {
        int nextc = c + acquires;
        if (nextc < 0) // overflow
            throw new Error("Maximum lock count exceeded");
        setState(nextc);
        return true;
    }
    return false;
}
static final class NonfairSync extends Sync {
    private static final long serialVersionUID = 7316153563782823691L;

    /**
      * Performs lock.  Try immediate barge, backing up to normal
      * acquire on failure.
      */
    final void lock() {
      // 调用lock的时候就会先抢一次！
        if (compareAndSetState(0, 1))
            setExclusiveOwnerThread(Thread.currentThread());
        else
            acquire(1);
    }

    protected final boolean tryAcquire(int acquires) {
        return nonfairTryAcquire(acquires);
    }
}
```

==公平锁的实现==
```java
static final class FairSync extends Sync {
    private static final long serialVersionUID = -3000897897090466540L;

    final void lock() {
      // 调用lock直接进入acquire！
        acquire(1);
    }

    /**
      * Fair version of tryAcquire.  Don't grant access unless
      * recursive call or no waiters or is first.
      */
    protected final boolean tryAcquire(int acquires) {
        final Thread current = Thread.currentThread();
        int c = getState();
        if (c == 0) {
          // 这里的第一个判断非公平锁没有，就是判断队列中有无前驱
            if (!hasQueuedPredecessors() &&
                compareAndSetState(0, acquires)) {
                setExclusiveOwnerThread(current);
                return true;
            }
        }
        else if (current == getExclusiveOwnerThread()) {
            int nextc = c + acquires;
            if (nextc < 0)
                throw new Error("Maximum lock count exceeded");
            setState(nextc);
            return true;
        }
        return false;
    }
}
```

> 讲一下基于AQS，reentrantlock的几个特征

- 可重入
  - 如果当前线程等于owner线程，则发生锁重入，把state++。释放的时候status--。如果status=0才会释放锁。
- 公平锁
  - 非公平锁：lock中抢一个，tryAcquire中抢一次，然后进入阻塞跟公平锁一样，按顺序被唤醒
  - 公平锁：检查AQS队列中是否有前驱节点，没有才去竞争
- 条件变量
  - 每个条件变量其实对应着一个等待队列，其实现类是ConditionObject
  - 开始Thread-0持有锁，调用await，进入conditionObject的addConditionWaiter流程，把自己加入到ConditionObject的等待队列中。然后释放锁，唤醒CLH队列的下一个节点
  - 调用signal后，将节点从ConditionObject队列删除，加入到CLH尾部

> reentrantlock的抢占的锁是什么

就是一个volatile int state。先判断state是否为0，为0表示没被占用，那么就用cas去抢。如果当前线程就是state抢占线程，那么state+1，重入。

```java
protected final boolean tryAcquire(int acquires) {
    final Thread current = Thread.currentThread();
    int c = getState();
    if (c == 0) {
        if (!hasQueuedPredecessors() &&
            compareAndSetState(0, acquires)) {
              // 这一个方法就是抢锁
            setExclusiveOwnerThread(current);
            return true;
        }
    }
    // 重入
    else if (current == getExclusiveOwnerThread()) {
        int nextc = c + acquires;
        if (nextc < 0)
            throw new Error("Maximum lock count exceeded");
        setState(nextc);
        return true;
    }
    return false;
}
```

# 线程池

> 线程池的好处

- 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗
- 提高响应速度。当任务到达时，任务可以不需要等到线程创建就立即执行
- 提高线程的可管理性。如果无限创建线程会造成系统资源的浪费，还会降低系统的稳定性，线程池可以统一分配，调优和监控

> Executor架构的结构讲一下，三个主要组成部分

1. 任务(Runnable/Callable)
   1. 执行任务需要实现的Runnable接口或Callable接口
2. 任务的执行(Executor)
3. 异步计算结果(Feature)
   1. Future接口以及Future接口的实现类提交给ThreadPoolExecutor或ScheduledThreedPoolExecutor执行。（注意只有调用submit方法才会有返回值FeatureTask对象）

> Executor的使用流程讲一下

1. 主线程首先要创建实现Runnable或者Callable接口的任务对象
2. 把创建完成实现的任务对象接口交给ExecutorService执行。
   1. ExecutorService.execute(runnable)或者ExecutorService.submit(runnable)
3. 如果是用submit执行，会有一个featuretask对象返回结果
4. 只线程通过FeatureTask.get()等待任务执行完成，并获取结果

> ThreadPoolExecutor类有哪些可设置的参数

- corePoolSize：线程池的核心线程数量
- maximumPoolSize：线程池的最大线程数
- keepAliveTime：非核心线程空闲存活的时间，超过这个时间就会销毁
- unit：时间单位
- workQueue：任务队列，存储等待执行的任务
- threadFactory：线程工程，创建线程
- handler：拒绝策略，

> 拒绝策略什么时候用，有哪些拒绝策略

当同时运行的线程数已经到达了最大线程数，并且任务队列也满了，那么就会使用拒绝策略。

- ThreadPoolExecutor.AbortPolicy：抛出异常来拒绝新任务的处理
- ThreadPoolExecutor.CallerRunsPolicy：调用执行自己的线程运行任务，也就是直接在调用execute方法的线程中运行run
- ThreadPoolExecutor.DiscardPolicy：不处理新任务，直接丢弃
- ThreadPoolExecutor.DiscardOldestPolicy：丢弃最早未处理的任务请求

> 线程池的运行原理

- 提交任务
- 核心线程是否已满
  - 如果不满就创建线程
  - 如果满了，就进入下一步判断
- 等待队列是否已满
  - 如果不满就进入等待队列
  - 如果满了，就进入下一步判断
- 线程池是否已满
  - 如果不满就创建非核心线程
  - 如果满了，就进入下一步
- 使用拒绝策略

> Runnable和Callable的区别

Runnable接口不会返回结果或抛出异常，但是Callable可以返回结果，抛出异常

> execute和submit的区别

- execute用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否
- submit方法用于提交需要返回值的任务，线程池会返回一个Future类型的对象，通过这个对象可以判断任务是否执行成功

> shutdown和shutdownNow的区别

- shutdown()：关闭线程池，线程池状态变为shutdown，不再接受新任务，但是队列里的任务需要全部执行完
- shutdownNow()：关闭线程池，线程池状态变为stop，线程池会终止当前正在执行的任务，并停止处理排队的任务，并返回等待执行的list

> isTerminated和isShutdown的区别
- isShutdown 当调用shutdown，方法返回true
- isTerminated：当调用shutdown后，并且所有任务执行完成后，方法返回true

> 讲一下几种常见的线程池

FixedThreadPool:线程数固定，也就是核心线程数就是线程池的数量，没有非核心线程。
- 使用无界队列，maximumPoolSize参数无效，keepAliveTime参数无效。
- 不会拒绝任务，因此可能会导致OOM

SingleThreadPool：单线程线程池。
- 使用无界队列，会有OOM问题

CachedThreadPool：corePoolSize=0,maximumPoolSize为MAX_VALUE。会不断的创建线程
- 可能会创建大量的线程，导致OOM

ScheduledThreadPoolExecutor：
- 用来执行定时任务
- 对队列中的任务排序，选所需时间短的先执行，如果相同，选先加入的执行

> 线程池大小越大越好，还是越小越好

都不行，如果太小，可能队列会满，出现无法处理的情况，或者大量任务堆积，而产生OOM

如果太大，大量线程同时争取CPU资源，导致频繁的上下文切换，影戏那个执行效率

> 如果选择线程池大小

- **CPU 密集型任务(N+1)：** 这种任务消耗的主要是 CPU 资源，可以将线程数设置为 N（CPU 核心数）+1，比 CPU 核心数多出来的一个线程是为了防止线程偶发的缺页中断，或者其它原因导致的任务暂停而带来的影响。一旦任务暂停，CPU 就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用 CPU 的空闲时间。
- **I/O 密集型任务(2N)：** 这种任务应用起来，系统会用大部分的时间来处理 I/O 交互，而线程在处理 I/O 的时间段内不会占用 CPU 来处理，这时就可以将 CPU 交出给其它线程使用。因此在 I/O 密集型任务的应用中，我们可以多配置一些线程，具体的计算方法是 2N。

# 锁

> 说一下synchronized的优化，锁的升级路线

引入了多个锁，无锁->偏向锁->轻量级锁->重量级锁

还有自旋锁

偏向锁：只有一个线程用对象锁的时候
轻量级锁：多个线程使用，但是不会发生竞争，在不同时候使用
重量级锁：多个线程发生竞争

> 讲一下偏向锁是怎么回事，获取锁的过程

主要用在没有多线程竞争的前提下，减少使用操作系统互斥量的性能消耗。无需CAS

当一个线程访问同步块并获取锁时，会在锁对象的对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程进入和退出同步块时，都不需要CAS操作。

如果MarkWord里存的线程ID不是当前线程的ID。测试以下MarkWord中偏向锁的表标示是否为1，如果没有，则使用CAS竞争锁，如果设置了，就用CAS将偏向指向自己。（升级为轻量级锁）

> 讲一下偏向锁为什么会被撤销，怎么撤销

1. 发生竞争，多个线程使用的时候
2. 调用.hashcode的时候，因为对象头用来存hashcode了，没地方存偏向信息

首先会暂停持有偏向锁的进程，然后检查持有偏向锁的线程是否存活，如果不处于活动状态，则将锁对象的对象头设置为无锁状态；如果线程存活，则将对象的对象头中MarkWord和栈中的锁记录恢复，然后要么重新指向别的线程，要么恢复到无锁状态。然后唤醒暂停的线程（释放偏向锁的线程）

> 讲一下轻量级锁是怎么加锁的

拷贝对象头中的Mark Word复制到锁记录（Lock Record）中

==拷贝成功后，虚拟机将使用CAS操作尝试将锁对象的Mark Word更新为指向Lock Record的指针，并将线程栈帧中的Lock Record里的owner指针指向Object的 Mark Word。==

如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，即表示此对象处于轻量级锁定状态

如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行。否则说明多个线程竞争锁，轻量级锁就要膨胀为重量级锁，锁标志的状态值变为“10”，Mark Word中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也要进入阻塞状态。



![image-20200528140721214](https://gitee.com/super-jimwang/img/raw/master/img/20210410164156.png)

![image-20200528140916607](https://gitee.com/super-jimwang/img/raw/master/img/20210410164109.png)

![image-20200528140928930](https://gitee.com/super-jimwang/img/raw/master/img/20210410164118.png)


> 讲一下锁膨胀

在尝试加轻量级锁的过程中，CAS操作无法成功，这时一种情况就是有其他线程为此对象加上了轻量级锁（有竞争），这时需要进行锁膨胀，将轻量级锁变为重量级锁。

==对象的mark word不再指向lock record，而是指向monitor，另外monitor中的owner指向该线程的lock record==
![image-20200528142540567](https://gitee.com/super-jimwang/img/raw/master/img/20210308194253.png)


> 自旋锁是什么，为什么要用它

自旋锁就是让线程执行一个忙循环，而不进入挂起状态。

因为一般线程持有锁的时间都不是太长，所以仅仅为了这点时间而区挂起线程/恢复线程需要消耗资源（用户态切换到内核态）

> 自旋锁会一直循环下去吗？为什么会这样

不会，默认的次数是10次。如果一直循环下去会占用cpu

> 重量级锁怎么加锁

![](https://gitee.com/super-jimwang/img/raw/master/img/20210302144618.png)
当多个线程同时访问一段同步代码时，首先会进入 Entry Set 竞争获取对象的monitor（锁）

当线程A获取到对象的monitor 后进入 The Owner 区域并把monitor中的owner变量设置为当前线程，同时monitor中的计数器count加1

若线程调用 wait() 方法，将释放当前持有的monitor，owner变量恢复为null，count自减1，同时该线程进入 WaitSet集合中等待被唤醒

若线程调用 notify()/notifyAll() 方式时，将释放当前持有的monitor并复位变量，同时唤醒 WaitSet 中的等待线程（notify随机通知一个线程，notifyAll通知所有线程）重新竞争monitor

若线程执行完毕也将释放monitor并复位变量，以便其他线程获取monitor

> 为什么重量级锁性能差

监视器锁依赖底层操作系统的mutex lock互斥锁实现的。他需要唤醒和阻塞线程，这需要用户态切换到内核态，所以成本较高。

> volatile如何保证可见性和有序性？

可见性

写屏障能够保证该屏障之前的，对共享变量的变动存到主存中

读屏障能够保证该屏障之后的变量，都是主存中读取过来的。


有序性
- 写屏障会确保指令重排序时，不会将写屏障之前的代码排在写屏障之后
- 读屏障会确保重排序时，不会将读屏障之后的代码排在读屏障之前
> Synchronized如何保证可见性

JMM中关于synchronized有如下规定，线程加锁时，必须清空工作内存中共享变量的值，从而使用共享变量时需要从主内存重新读取；线程在解锁时，需要把工作内存中最新的共享变量的值写入到主存，以此来保证共享变量的可见性

> Synchronized如何保证有序性

由于被Synchronzied修饰的代码块同一时间只能一个线程访问，单线程是有序执行的。所以可以保证有序性。as-if-serial语义，单线程不管怎么样重排，其执行结果不变

> 双重检验的单例模式有了synchronized，为什么还需要volatile

因为synchronized只能保证有序性，而==不能保证指令重排。==

new对象的过程：
- new对象
- 初始化
- 引用指向对象

如果重排了，还未初始化的对象被引用了，而另一个线程过来直接拿走了这个单例对象去使用就会用问题。而volatile可以保证不被指令重排序。保证new对象的三步全部执行完了之后，后面的指令才能执行。

> volatile如何保证不被指令重排序

volatile写之前有一个storestore屏障，禁止之前的普通写与valatile写重排序。volatile写之后有一个storeload屏障，防止volatile写与之后可能的volatile写/读重排序

volatile读之后有一个loadload屏障，防止之后的普通读与volatile读指令重排。在loadload屏障后有一个loadstore屏障，防止之后的普通写与volatile读屏障重排。

![](https://gitee.com/super-jimwang/img/raw/master/img/20210309204249.png)

> volatile如何同步数据？多处理器的总线嗅探是什么？

1.当写一个volatile变量时，JMM（java共享内存模型）会把该线程对应的本地内存中的共享变量值刷新到主内存；

2.当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效，线程接下来从主内存中读取共享变量。

在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己的缓存值是不是过期了，如果处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据库读到处理器缓存中。

处理器使用嗅探技术保证它的内部缓存，系统内存和其他处理器的缓存在总线上保持一致